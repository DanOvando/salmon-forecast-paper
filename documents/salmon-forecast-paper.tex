% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=Blue,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{setspace}\doublespacing
\usepackage{lineno}\linenumbers
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\author{}
\date{\vspace{-2.5em}}

\begin{document}

\newpage

\hypertarget{title-page}{%
\section*{Title Page}\label{title-page}}
\addcontentsline{toc}{section}{Title Page}

\hypertarget{title}{%
\subsection*{Title}\label{title}}
\addcontentsline{toc}{subsection}{Title}

Improving Forecasts of Sockeye Salmon (\emph{Oncorhynchus nerka}) with Modern Computational Tools.

\hypertarget{author-list}{%
\subsection*{Author List}\label{author-list}}
\addcontentsline{toc}{subsection}{Author List}

Daniel Ovando\textsuperscript{a}*, Curry Cunningham\textsuperscript{b},Peter Kuriyama\textsuperscript{c},Christopher Boatright\textsuperscript{a}, Ray Hilborn \textsuperscript{a,d}

\textsuperscript{a} School of Aquatic and Fishery Sciences, University of Washington Box 355030 Seattle WA 98195

\textsuperscript{b}College of Fisheries and Ocean Sciences University of Alaska Fairbanks 17101 Point Lena Loop Road Juneau, AK 99801

\textsuperscript{c}NOAA Fisheries Southwest Fisheries Science Center 8901 La Jolla Shores Dr, La Jolla, CA 92037

\textsuperscript{d}Center for Sustaining Seafood, University of Washington Box 355030 Seattle WA 98195

\hypertarget{corresponding-author}{%
\subsection*{Corresponding Author}\label{corresponding-author}}
\addcontentsline{toc}{subsection}{Corresponding Author}

*Correspondence should be addressed to Daniel Ovando at \href{mailto:danovan@uw.edu}{\nolinkurl{danovan@uw.edu}}

\newpage

\hypertarget{abstract}{%
\subsection*{Abstract}\label{abstract}}
\addcontentsline{toc}{subsection}{Abstract}

Accurate forecasts of sockeye salmon (\emph{Oncorhynchus nerka}) in Bristol Bay, Alaska, play an important role in management and harvesting decisions for this culturally and ecologically vital species. We used a suite of modern computational tools to assess the frontiers in forecast accuracy of Bristol Bay sockeye salmon possible given currently-available data. In retrospective performance testing individual models were capable of reducing pre-season forecast error at the river system level by on average 15\% relative to a benchmark model. We utilized an ensemble modeling approach to produce pre-season forecasts based on historic performance of individual models. This ensemble model reduced river system level forecast error by 13\% on average in 5 of the 7 evaluated river systems, though it increased forecast error by 39\% on average in the remaining 2 systems. We found potential for modest improvements in forecast accuracy across a variety of scales. However all tested models failed to accurately predict certain periods in the abundance timeseries, indicating that further forecast improvements depend on novel data rather than more flexible models.

\hypertarget{keywords}{%
\subsection*{Keywords}\label{keywords}}
\addcontentsline{toc}{subsection}{Keywords}

Alaska, Salmon,Machine learning,Empirical Dynamic Modeling, Dynamic Linear Models, Predictive Modeling, Ecological Forecasting

\newpage

\hypertarget{introduction}{%
\section*{Introduction}\label{introduction}}
\addcontentsline{toc}{section}{Introduction}

Animal populations exhibit complex dynamics driven by interactions with many aspects of their ecosystem. Predicting the outcomes of these dynamics is a critical task of natural resource management; Forecasts of future abundance are often used to set fisheries regulations, vessel operators may make decisions about alternative fisheries based on predicted abundance, and industries and communities use forecasts to inform long-term and short-term investment plans in staffing and production capacity. The past two decades have seen explosive progress in the ability of modern ``computer age'' (Efron and Hastie 2016) tools to improve prediction, revolutionizing fields such as financial modeling, weather forecasting, and medicine. However, these methods remain relatively unused in ecological forecasting, particularly in an applied setting (Peters et al. 2014). We use the ecologically and economically critical sockeye salmon (\emph{Oncorhynchus nerka}) populations of Bristol Bay, Alaska to demonstrate the use of modern computation tools in applied predictive modeling, and show how they can be used to identify frontiers in forecast accuracy given currently available data.

The commercial salmon fishery in Bristol Bay, Alaska is the single largest sockeye salmon fishery in the world (Steiner et al. 2011). The estimated wholesale value of the Bristol Bay commercial sockeye harvest was \$390 million USD in 2010, providing approximately one-sixth of the total value of all United States seafood exports (Knapp et al. 2013). The value of the Bristol Bay fishery has continued to grow, reaching \$508 million in 2017 (McDowell Group 2018). Salmon returning to Bristol Bay also provide vital food security for subsistence-dependent Alaskan communities, and are critical vectors of marine-derived nutrients that support vibrant freshwater habitats (Naiman et al. 2002; Schindler et al. 2003). Sustainable management of the Bristol Bay salmon fishery depends in part on the accuracy of preseason forecasts for salmon abundance, which inform development and implementation of inseason harvest strategies and successful operation of subsistence and commercial fisheries. Preseason forecasts are also important for planning by the processing industry, as a basis for identifying the appropriate level of supplies, equipment, and personnel necessary to process the annual harvest. As such, the accuracy of salmon forecasts have a direct influence on the profitability and efficiency of the salmon industry as a whole.

The Fisheries Research Institute (FRI) at the University of Washington and the Alaska Department of Fish and Game (ADFG) have been providing preseason forecasts for the annual abundance of sockeye salmon returning to the major river systems and fishing districts of Bristol Bay since at least 1967 (Cunningham pers. comm.). While the exact statistical methods used for FRI and ADFG forecasts have evolved over time, throughout their history they have primarily been based on the relationship between the abundance of successive age classes of salmon returning in different years. While these traditional forecast methods have been useful in guiding decisions by fishers, processors, and managers alike, improvements in the accuracy and precision of preseason forecasts would represent a valuable advance.

Sockeye salmon are semelparous, born in freshwater where they spend the first one or more years of their lives. Eventually, these fish migrate to the ocean, where they live the remainder of their lives until returning to their natal river systems to spawn and then die. Sockeye salmon exhibit life history variation in the number of years they spend in these freshwater and oceanic phases, representing distinct ``age groups.'' Following conventions in the salmon literature, we denote age groups here by the format ``years spent in freshwater.years spent in the ocean.'' For example, a fish in the 1.2 age group spent one winter post-hatching in freshwater and migrating to sea two years after it was spawned, and two winters in the ocean before returning to freshwater to spawn. The Bristol Bay sockeye salmon fishery is primarily made up of salmon from seven different river systems, each of which is managed as a separate stock (Fig.\ref{fig:returns}).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/returns-1.pdf}
\caption{\label{fig:returns}Annual total abundance of returning sockeye salmon (\emph{Oncorhynchus nerka}) to Bristol Bay, Alaska (A), by river system (B), and by age group (C). Numbers in millions of salmon. Age group is formatted by `years spent in freshwater.'`years spent in ocean'. Map adapted from Cunningham et al. (2019).}
\end{figure}

Why might we expect modern computational tools to be well-suited to the task of salmon forecasting? Methods such as machine learning excel at identifying and exploiting potentially complex correlations between variables in a system. Conversely, ``traditional'' parametric statistical methods often restrict themselves to simplified (e.g.~linear) and often non-dynamic representations of natural systems, both for analytical tractability and to facilitate heuristic understanding of underlying processes. Typically, these parametric statistical methods are concerned with explicitly estimating and interpreting model parameters rather than solely forecasting responses, such as population size (Beyan and Browman 2020; Malde et al. 2020). We would expect modern computational tools to show substantial improvement in predictive power when the ``true'' underlying system linking observed variables and outcomes differs dramatically from the simplified representations of the system approximated by conventional statistical approaches. In the case of salmon, we know that inter-annual variation in run sizes is affected by a wide range of ecosystem variables, including spawning success, river conditions, oceanic predator and prey abundance, and competition with other salmonids (Connors et al. 2020). By reducing the potential for predictive model misspecification, modern computation tools that essentially seek to ``learn'' the best model structure for the sole purpose of maximizing out-of-sample predictive performance can provide a test of the predictive information content of the available data themselves.

Rather than incorporate factors such as environmental drivers directly, salmon forecasting has traditionally relied on cohort or ``sibling'' regression methods, in which the return abundance of an older age class is predicted by the abundance of younger age classes, returning in prior years but originating from the same river system and brood year. For example, the return abundance of four-year old fish are predicted by the returns of three-year old fish observed in the previous season. There are good reasons for this practice: trends in sibling abundance integrate across many environmental factors affecting salmon survival and returns. If a particular cohort suffers from poor environmental conditions, increased competition with conspecifics, or a greater abundance of predators, the demographic impacts of these changes will be reflected in the return abundance of younger age classes from the same cohort (i.e.~originating from the same brood year) that experienced similar environmental conditions or resource availability, and by extension survival, as juveniles. However, the sibling regression method does have shortcomings, most notably the underlying assumption of consistency in the relationship between the abundance of different age classes and stability in the maturation schedule (i.e.~the probability of salmon maturing and returning to freshwater to spawn after a given number of years in the ocean). For example, if environmental conditions cause members of a cohort of salmon to spend more time at sea than in previous years, a sibling regression might under-predict the number of future returns. In addition, sibling regression requires accurate observations of the return abundance for younger sibling age classes, limiting the performance of these models in predicting returns of younger salmon for which few or no siblings (i.e.~returning younger age classes) have yet been observed.

We hypothesize that directly incorporating data on candidate potentially time-varying factors influencing and correlated with salmon return size, rather than relying on sibling returns alone, may help improve forecast performance given the intricate dynamics of salmon populations. However, these variables are likely to have complex, non-linear, and non-stationary effects on salmon populations, potentially obscuring their value from conventional parametric statistical approaches, with user-defined parameters, structures, and error distributions. In order to explore this possibility, we used a suite of six methods together with a panel of data on salmon populations and environmental conditions in Bristol Bay, Alaska to explore what if any improvements in forecast skill could be achieved. These models included two machine learning methods, a random forest (rand\_forest), (Breiman 2001; Wright and Ziegler 2017) and a boosted regression tree, boost\_tree, (Chen et al. 2020), empirical dynamic models (edm) (Sugihara and May 1990; Ye et al. 2020; Munch et al. 2020), and dynamic linear models (dlm)(Pole et al. 1994; Petris et al. 2009). We also included a lag-1 model, as a performance benchmark, in which the predicted returns for a given age group and river system in a year are equal to the observed returns for that that age group in that river system in the prior year. Our goal here was not to establish whether one type of model performs inherently better than others, but to evaluate how use of different computer age models and data types can collectively improve forecast ability and identify frontiers in forecast ability given available data. We also evaluated the performance of a model ensemble which weights predictions from individual ensemble members (alternative predictive model types) based on recent performance, and compare this with observed performance from the Fisheries Research Institute (FRI) forecast, a benchmark forecast that utilizes a qualitative ensemble approach based on evaluation of recent performance for alternative models within the ensemble.

\hypertarget{materials-and-methods}{%
\section*{Materials and methods}\label{materials-and-methods}}
\addcontentsline{toc}{section}{Materials and methods}

All code and data needed to fully replicate our results are publicly available at \url{https://github.com/DanOvando/salmon-forecast-paper/}. We describe critical details of each our main methods here.

The general structure of our methods are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Individual models for each river system and age group were fit to historical data
\item
  Retrospective performance of individual model was assessed using 1-step ahead predictions (e.g.~model fit to data through 1999 and used to predict return abundance in 2000) over the period 2000-2019
\item
  Comparison of performance from individual models types against a benchmark ``lag-1'' prediction model in which the forecast for next year is simply the observed returns in the previous year
\item
  Individual models were aggregated into a statistical ensemble model based on their historic performance against the lag-1 benchmark
\item
  The statistical ensemble model was then compared to a more qualitatively constructed ensemble model, in which researchers manually select individual models from an evolving suite of methods based on recent (20-year) performance. This is the method historically used to generate Bristol Bay salmon forecasts, although the individual prediction models within the selection suite have changed over time. As such this method provides a \emph{status quo} benchmark to which individual models and statistical ensembles may be compared.
\end{enumerate}

\hypertarget{machine-learning-models}{%
\subsection*{Machine Learning Models}\label{machine-learning-models}}
\addcontentsline{toc}{subsection}{Machine Learning Models}

We evaluated two different machine learning models: a random forest (rand\_forest, implemented through the \texttt{ranger} package (Wright and Ziegler 2017) in R (R Core Team 2020)), and boosted regression trees, boost\_tree, through the \texttt{xgboost} package (Chen et al. 2020). A recurrent neural network implemented through \texttt{tensorflow} (Allaire and Tang 2020) through the \texttt{keras} interface (Allaire and Chollet 2020) was also tested but was found to perform poorly relative to the other methods and to be extremely computationally intensive, and as such was not included in the main analysis. Random forests are ensembles of regression trees, which make predictions by selecting nested splits of variables and mapping the mean level of the dependent variable at the terminal nodes of each tree. Boosted regression trees are similar to random forests, but have mechanisms in place that actively update the model to address data points that the model is struggling to fit (Elith et al. 2008). For all machine learning methods, within a model fit the model selects splits/transformations/coefficients to minimize the root mean squared error (RMSE) of predictions for data withheld from the fitting process by the algorithm.

Each of the machine learning methods had access to a variety of population and environmental data. We fit versions of each model separately for each age group in each major river system. Environmental datasets were queried from the NOAA ERDDAP portal using the rerddap package in R (Chamberlain 2019). Included environmental variables include sea surface temperature, sea level pressure, wind stress, and the Pacific Decadal Oscillation index. For each environmental variable, we use mean or median values within the Bristol Bay region across the months of May to August during the year in which the cohort being forecasted entered the ocean. We also included as candidate covariates natural origin returns of pink (\emph{Oncorhynchus gorbuscha}) and chum (\emph{Oncorhynchus keta}) across a range of North Pacific stocks, pulled from Ruggerone and Irvine (2018) (Table.\ref{tab:dat}).

When fitting models at the level of age groups by river system, data were first split into training and testing sets. We then split each of the training sets for performance testing (e.g.~all data before the year 2000 if the year 2001 is to be forecasted) into a series of analysis and assessment splits for tuning purposes. Given the timeseries nature of the data, we generated these analysis and assessment splits in a rolling manner: for the first split, we used the first 70\% of the training year to fit a model, and the remaining 30\% to evaluate the performance of that model, followed by the first 75\% and 25\%, etc. These analysis and assessment splits were used to tune nuisance parameters common to all machine learning models, for example the minimum node size of fitted trees. We fit each of our assessment splits across a grid of potential parameter values, and selected the set of tuning parameters that minimized the RMSE of the predictions on the assessment splits (see computational environment available at \url{https://github.com/DanOvando/salmon-forecast-paper/} for detailed steps in this process).

Once the optimal set of tuning parameters for each training set were selected, we then fit the final model using all the training data with those tuned parameters, and used that model to predict the returns in the testing set. All relevant data transformations were prepared only on training / analysis splits (e.g.~means and standard deviations for centering and scaling) and then applied to testing / assessment splits.

\begin{table}

\caption{\label{tab:dat}Environmental and salmonid datasets available to machine learning models.}
\centering
\begin{tabu} to \linewidth {>{\raggedright}X>{\raggedright}X>{\raggedright}X}
\toprule
Name & Description & Source\\
\midrule
Pacific Decadal Oscillation & Mean PDO index between May-August in year cohort entered ocean. & JISAO\\
Sea Level Pressure & Median Bristol Bay SLP between May-August in year cohort entered ocean. & ERDDAP ICOADS\\
Sea Surface Temperature & Median Bristol Bay SST between May-August in year cohort entered ocean. & ERDDAP HadISST\\
Wind Stress & Median Bristol Bay wind stress between May-August in year cohort entered ocean. & ERDDAP ICOADS\\
Pink and chum abundance & Natural origin returns of pink and chum salmon & Ruggerone and Irvine (2018)\\
\bottomrule
\end{tabu}
\end{table}

\hypertarget{dynamic-linear-models}{%
\subsection*{Dynamic Linear Models}\label{dynamic-linear-models}}
\addcontentsline{toc}{subsection}{Dynamic Linear Models}

To date methods for forecasting sockeye salmon abundance in Bristol Bay and throughout Alaska, have relied on the relationship between the abundance of different age classes from the same cohort, or originating from the same brood year, but returning to breed in subsequent years at different ocean ages. These ``sibling'' or cohort regression models leverage the fact that salmon spawned in the same brood year and migrating to sea in the same year exhibit similar patterns in survival, based upon their shared exposure to the same physical environmental conditions, prey resource availability, and predator field, as juveniles and at ocean entry. As such, if members of a cohort returning after 2 years in the ocean are observed in higher-than-average abundance, then we may also expect above-average abundance of their 3-ocean ``siblings'' (other members of the cohort) to return the next year.

Foundational to the predictability of sibling relationships is the assumption that the ratio of returns by age class remains stable across time. In a context of a linear model, for example, we can model returns as \(\hat{R^{1.3}_t} = \alpha + \beta{R^{1.2}_{t-1}}\) where \(\hat{R^{1.3}_t}\) is the predicted return abundance of the older (1.3) age class and \(R^{1.2}_{t-1}\) is the observed abundance of the same cohort returning in the prior year after one fewer years in the ocean (i.e.~age group 1.2). Under a classic sibling regression the assumption is that the estimated parameters \(\alpha\) and \(\beta\) remain constant across time. However, there are multiple conditions under which both the average return abundance of a particular age class or the ratio of abundances among age classes might change over time. For example, if the average maturation schedule (i.e.~the probability that an individual will mature after 2 vs.~3 years in the ocean) changes in response to natural or anthropogenic selection, the assumption of a stationary parameter is violated. Alternatively, if average marine mortality experienced by salmon changes as a result of large-scale climate, ecosystem, or trophic shifts, this should be reflected by changes in both parameters of the regression model.

To better represent the dynamic nature of sibling or cohort relationships over time and improve predictive performance, we implement dynamic linear models (DLMs). DLMs are a class of regression models where the values of regression coefficients are permitted to evolve over time, rather than remain static (Pole et al. 1994; Petris et al. 2009). DLMs were fit to available data using a single predictor age class (one fewer year in the ocean, returning the prior year), and allowing for evolution of both the slope and intercept parameters over time, as:

\[\hat{R^{1.3}_t} = \alpha_t + \beta_t{R^{1.2}_{t-1}} + \epsilon_t\]

Both regression parameters are described by a random walk (i.e.~\(\alpha_t \sim Normal(\alpha_{t-1},\sigma^2_{\alpha})\) and \(\beta_t \sim Normal(\beta_{t-1},\sigma^2_{\beta})\)), and errors were assumed normally-distributed (\(\epsilon_t \sim Normal(0,\sigma^2_{\epsilon})\)). DLMs were implemented using the Multivariate Autoregressive State-Space Modelling (MARSS) package (version 3.10.12) in R (Holmes et al. 2012; Holmes et al. 2020). The full timeseries (brood year 1963 forward) of age and river system specific abundances reconstructed by Cunningham et al. (2019) were for model fitting. For example, to predict the abundance of the 1.2 age class returning to the Wood River system in 2010, the DLM model was fit to available data 1963-2009, with the 1.1 age class in prior years assumed a priori to be most informative the predictor sibling

\hypertarget{empirical-dynamic-modeling}{%
\subsection*{Empirical Dynamic Modeling}\label{empirical-dynamic-modeling}}
\addcontentsline{toc}{subsection}{Empirical Dynamic Modeling}

Empirical dynamic modeling (EDM) is a nonparametric approach to characterize ecological dynamics and generate forecasts. The approach is predicated on Takens' theorem, which states that a single time series and a number of lags (dimension; E) are representative of overall system dynamics (Takens 1981; Sugihara and May 1990). Applications of EDM have identified causal relationships in ecological systems (Sugihara et al. 2012) and improved forecast skill in Fraser River sockeye salmon (Ye et al. 2015). See Munch et al. (2020) and Chang et al. (2017) for more general overviews of EDM. We used the software package rEDM (Park et al. 2021) for analysis.

We focused on multiview embedding (Ye and Sugihara 2016) to predict Bristol Bay sockeye returns. We predicted out-of-sample river and age-class-specific returns for 2000-2019. The idea behind multiview embedding is that there are potentially many valid reconstructions of system dynamics, and evaluating possible different combinations may improve performance. The top Multiview embedding was identified with river-specific data with a maximum E=2. Multiview embedding selects models based on the within-sample fits. So to predict say Kvichak 2.2 returns in the year 2000, we subset data through 1999 for Kvicahk 1.2, 1.3, 2.3, and 2.2, then selected the multiview embedding that had the highest within-sample predictive skill. We evaluated embeddings with maximum dimensions up to E=4, although this increase did not consistently result in improved within-sample predictive skill, perhaps due to noise in the data.

We present results from multiview embedding but we also evaluated additional EDM approaches. These included multivariate simplex, multivariate sequentially locally weighted global linear maps (s-map), and composite libraries for prediction to the salmon return data. These methods require identifying the dimensionality (E) of a time series and constructing an attractor (a time series and its E-lagged coordinates). Leave-one-out prediction identifies the best E of a time series. We used E values ranging from 1 to 10, found the E-nearest neighbors (based on Euclidean distance) from the observation of interest, and calculated a predicted value by averaging the E-nearest neighbors. The best E had the highest correlation between observed and predicted values. S-maps is an extension of simplex that has the addition of a weighting parameter (theta) which modifies the strength of nearest neighbor weighting (theta=0 weights nearest neighbors equally; theta\textgreater0 stronger weighting of nearest neighbors) (Sugihara et al. 1994).

\hypertarget{performance-metrics}{%
\subsection*{Performance Metrics}\label{performance-metrics}}
\addcontentsline{toc}{subsection}{Performance Metrics}

We do not conduct formal statistical tests of model fit or performance. Parameters of conventional statistical models might be assessed in terms of statistical significance, and models compared via some form of information criterion. However, neither the machine learning or the empirical dynamic modeling methods have formal estimates of uncertainty or likelihoods, and as such do not produce measures of statistical significance around individual forecasts, and cannot be compared using information criteria such as AIC (Akaike 1974) scores. Accordingly, we judge model performance by the point estimates of SRMSE produced by each model across the retrospective horizon 1990-2019. SRMSE measures the performance of each model relative to a lag-1 model, a conventional benchmark model for timeseries modeling (Hyndman and Koehler 2006; Ward et al. 2014)

RMSE is calculated as

\[RMSE_m = \sqrt{\frac{1}{I}\sum\limits_{i = 1}^I(y_{i} - f_{i,m})^2}\]

where \emph{i} represents an observation of numbers of returning salmon \emph{y} and the forecast for those numbers \emph{f} by a given model \emph{m}. In the manner of mean absolute scaled error (MASE, (Hyndman and Koehler 2006)), we scale each models RMSE for a given resolution by the RMSE of a lag-1 model for the same resolution (for example at the river system level).

\[RMSE_{l1} = \sqrt{\frac{1}{I}\sum\limits_{i = 1}^I(y_{i} - y_{i,l1})^2}\]

and SRMSE for model \emph{m} is then

\[SRMSE_m = \frac{RMSE_m}{RMSE_{l1}}\]

MASE is commonly used to judge the accuracy of predictions derived from time series models, since it compares the error of a given model to the error expected by a simple model in which the predictions in a given time step are equal to the observed values in the last time step (a lag-1 model). We use SRMSE instead of MASE to reflect the use of the forecast. MASE considers an error of ten to be twice as bad as an error of five. In the context of salmon forecasting, our primary objective is to avoid massively over or under estimating the pre-season forecast. SRMSE penalizes large errors more than small errors, helping select models that avoid the kinds of large errors that are most problematic for the task of managing salmon populations.

A SRMSE of one means that a model has predictive performance equal to that of the lag-1 model. A SRMSE greater than one indicates that a given model performs worse than the lag-1 benchmark, a SRMSE less than one that a model performs better than the lag-1 benchmark (Hyndman and Koehler 2006).

\hypertarget{testing-regime}{%
\subsection*{Testing Regime}\label{testing-regime}}
\addcontentsline{toc}{subsection}{Testing Regime}

All models were compared based upon one-step-ahead forecast skill, defined by SRMSE. Each of the evaluated models generate forecasts at the resolution of age group and river system in a given year. Forecasts for a given year are produced by a model trained on all years after 1963 and prior to the year for which a forecast is desired. This is performed in a rolling fashion, such that for example forecasts for the year 2018 are produced by a model trained on data from 1963 to 2017, the 2019 forecast by a model trained on data from 1963 to 2018, and so on. One-step-ahead performance skill was preferred over simple leave-one-out cross validation because it better aligns with the context of preseason forecasting (i.e.~data in hand through the current year are used to predict the next), and should be expected to more appropriately reflect true forecast uncertainty in the presence of periodic regime shifts in salmon production and the potential for unmodeled autocorrelation. Each method has its own ways of tuning and validating the model, but all such steps are performed using only the training data: all data for the forecast year are held out until the final prediction.

Predictive performance of candidate models was calculated by generating 1-year ahead forecasts for each target river system by age class combination, as a rolling window from the year 2000 to 2019. This method for quantifying forecast performance is most applicable to the context of this ecological forecasting problem as each candidate model is trained on data up to, but not including, the prediction year. Even though each model predicts at the resolution of age group and river system, we generally compare model performance at coarser resolutions (for example river system across all age groups). In those cases, we first aggregate the total returns at the resolution in question (e.g.~sum all observed and forecast returns across all age groups for a given river system), and then calculate SRMSE based on those aggregated data.

\hypertarget{ensemble-models}{%
\subsection*{Ensemble Models}\label{ensemble-models}}
\addcontentsline{toc}{subsection}{Ensemble Models}

The chosen testing regime allowed us to compare the retrospective predictive power, defined by SRMSE, of individual models at a variety of spatial resolutions. However, scientists must make a decision each year as to which models to use for particular forecasts, and there is no guarantee that past model performance will predict future model performance. A substantial body of literature suggests that creating ``ensemble'' models that weigh individual models to create a single composite prediction can outperform any one individual model (Dietterich 2000; Ara'ujo and New 2007; Anderson et al. 2017b). To assess the ability of this idea to assist in annual model selection and weighting we compared two different ensemble models: a purely statistical ensemble constructed by a random forest, and a mixed-methods ensemble model published as the Fisheries Research Institute (FRI) forecasts.

The random forest ensemble model was updated each year by evaluating the performance of different models in the past and creating a prediction for the current time step based on the performance of component models (the ensemble members) in the prior time steps. For the random forest ensemble, we predicted the total returns by river system as a function of the predictions by river system and age group from each individual candidate model type. A conventional ensemble might be constructed by taking an AIC weighted mean of forecasts of each of the candidate models for a particular river system. By constructing an explicit ``model-of-models'' ensemble through a random forest, we allow the choice of model weighting to vary depending on the performance of different models in different river systems and time periods (Anderson et al. 2017b).

The FRI forecast is a mixed-methods manually constructed ensemble model, which has used various methods throughout the years to arrive at pre-season forecasts for each river system based on the recent performance of different candidate models. The FRI forecast for a specific stock by age class combination was traditionally constructed by AIC-weighting across candidate linear sibling models. Candidate linear models predict returns of the target age class using returns of one or two younger age classes seen in prior years as predictors. These candidate predictive models were fit on two alternative time series, 1963 onward and 1980 onward, to account for broad-scale shifts in average Bristol Bay salmon population productivity following the shift in the Pacific Decadal Oscillation (PDO) in the late 1970's. Natural-scale and log-transformed transformations were both fit for all models. Since 2013 the FRI forecast ensemble has been constructed by comparing the performance of the linear and log-linear AIC-weighted sibling models, random forest models, dynamic linear sibling models, boosted regression trees, and simple autoregressive integrated moving average (ARIMA) time series models, and selecting the model with the lowest residual error in predictions for the target stock-age group across the most recent 20-year time horizon.

The FRI forecast is a mixed-methods manually constructed ensemble model, which has used various methods throughout the years to arrive at pre-season forecasts for each river system based on the recent performance of different candidate models. The FRI forecast for a specific river by age class combination was traditionally constructed by AIC-weighting across candidate linear sibling regression models. Candidate linear models predict returns of the target age class using returns of one or two younger age classes seen in prior years as predictors, but unlike the DLM model explored here, assume regression coefficients are time-invariant. These candidate predictive models were fit on two alternative time series, 1963 onward and 1980 onward, to account for broad-scale shifts in average Bristol Bay salmon population productivity following the shift in the Pacific Decadal Oscillation (PDO) in the late 1970's. Natural-scale and log-transformed transformations were both fit for all models. Since 2013 the FRI forecast ensemble has been constructed by comparing the performance of the linear and log-linear AIC-weighted sibling models, random forest models, dynamic linear sibling models, boosted regression trees, and simple autoregressive integrated moving average (ARIMA) time series models, and selecting the model with the lowest residual error in predictions for the target stock-age group across the most recent 20-year time horizon. All models in the historical FRI ensemble used only data from within a single river system, but across multiple age classes, to generate predictions (i.e.~age-specific timeseries of Nushagak River returns were never used to forecast Wood River returns despite their spatial proximity).

The FRI ensemble forecast values were pulled from the historic pre-season forecasts as published. For the random forest ensemble, we follow a similar routine to that employed for the individual (i.e.~river- and age-specific) boosted regression tree model. We compiled the pre-season forecasts by river system and age group for each of the candidate models going back to 1991. The ensemble sought to predict the observed total returns by river system using the returns by river system and age class produced by each of the candidate models (BRT, RF, DLM, EDM). For the years 2000 to 2019, we performed a series of rolling model fits, where individual forecasts and observed returns before the testing year was held out for training (and analysis and assessment splitting and model tuning), and then used fit the ensemble model, which was then evaluated on the testing year. The held-out one-year-ahead predictions of the ensemble model in each time step were then compiled to create the historic series of ensemble forecasts at the river system level.

\hypertarget{results}{%
\section*{Results}\label{results}}
\addcontentsline{toc}{section}{Results}

\hypertarget{individual-model-forecasts}{%
\subsection*{Individual Model Forecasts}\label{individual-model-forecasts}}
\addcontentsline{toc}{subsection}{Individual Model Forecasts}

\hypertarget{river-system-forecasts}{%
\subsubsection*{River System Forecasts}\label{river-system-forecasts}}
\addcontentsline{toc}{subsubsection}{River System Forecasts}

Management of Bristol Bay sockeye salmon operates at the river system level, with inseason fishery managers regulating allowable fishing effort on a daily basis to meet annual escapement goals for each river (Fried and Hilborn 1988; Cunningham et al. 2019). For each river system, we selected the individual model with the lowest SRMSE over the years 2000 to 2019 as the model of choice for that river system. On average the best-performing method reduced the SRMSE in pre-season run forecasts at the river system level by 15\%, with a minimum improvement of 2\% and a maximum of 28\%, relative to the performance of the historic published pre-season FRI forecasts.

River systems varied in both the lowest SRMSE achieved and in the model that produced the best performance. At least one model was able to out-perform or equal a simple lag-1 benchmark model in each of the river systems except for the Nushagak, with the dlm model achieving a SRMSE of 0.69 at the top end in the Kvichak river system, and the rand\_forest model providing only marginal improvement over a lag-1 model with a SRMSE of 1 in the Nushagak river system. The dlm, boost\_tree, and rand\_forest models were selected as the best performing candidate in at least one river system (Fig.\ref{fig:sys-forecast}).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/sys-forecast-1.pdf}
\caption{\label{fig:sys-forecast}Observed (grey ribbons) and predicted (points) numbers of returning sockeye salmon to primary sockeye-producing river systems in Bristol Bay, Alaska. The color of the points corresponds to the best performing model in terms of scaled root mean squared error (SRMSE), point transparency reflects the SRMSE of the best performing model, noted in the top left corner of each panel.}
\end{figure}

\hypertarget{age-group-forecasts}{%
\subsubsection*{Age Group Forecasts}\label{age-group-forecasts}}
\addcontentsline{toc}{subsubsection}{Age Group Forecasts}

While total river system returns are the primary metric of interest to the Bristol Bay sockeye fishery, the age composition of the returns are also important given their influence of the average size and therefore price for each salmon harvested, and options for processed product forms. As such we also examined the ability of our tested models to generate predictions at the age group level. In retrospect different models performed best for each of the four age groups considered, and at least one model was able to improve substantially on a lag-1 model in all age groups (Fig.\ref{fig:age-forecast}).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/age-forecast-1.pdf}
\caption{\label{fig:age-forecast}Observed (grey ribbons) and predicted (points) numbers of sockeye salmon within each age group returning to Bristol Bay, Alaska. Age group refers to `years spent in freshwater'\_`years spent in ocean.' Color corresponds to the best performing model in terms of scaled root mean squared error (SRMSE), transparency reflects the SRMSE of the best performing model, noted in the top left corner of each panel.}
\end{figure}

\hypertarget{ensemble-forecasts}{%
\subsection*{Ensemble Forecasts}\label{ensemble-forecasts}}
\addcontentsline{toc}{subsection}{Ensemble Forecasts}

In theory the individual models tested here were capable of improving pre-season forecast accuracy over the years 2000-2019 when viewed retrospectively. However, scientists must make annual decisions as to which models to use and how to weigh their predictions. To approximate this process we selected the top performing (in terms of SRMSE) rolling ensemble model (either the FRI or the random forest model-of-models ensemble) for each of the main river systems. In 5 of the 7 evaluated river systems the random forest ensemble produced the preferred ensemble, improving on the FRI forecast by on average 13\% , with the FRI forecasts being preferable of the two ensembles in the remaining 2 river systems, outperforming the random forest ensemble by 39\% .

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/ensemble-forecast-1.pdf}
\caption{\label{fig:ensemble-forecast}Performance of candidate ensemble models. Shape of points indicates which ensemble model had the lowest scaled root mean squared error (SRMSE). FRI refers to the published forecasts by the Fisheries Research Institute. The random forest ensemble is an ensemble model constructed by random forest made out of candidate model forecasts. The forecast from the best performing ensemble is plotted and denoted by point shape. Color of points shows the percent improvement of the ensemble model relative to the published FRI forecast.}
\end{figure}

\hypertarget{frontiers-in-performance}{%
\subsection*{Frontiers in Performance}\label{frontiers-in-performance}}
\addcontentsline{toc}{subsection}{Frontiers in Performance}

The underlying assumption of such an ensemble strategy is that the information needed for an accurate forecast is present in the data, and the key is finding the combination of individual models that are best able to identify and leverage that information. However, no model can find information that simply is not present, or succeed if it is based upon data that is subject to overwhelming observation or process error. Examining trends in the annual residuals by model and river system shows clear patterns. In some years and river systems, all models perform similarly well, indicating that the information needed for a good forecast was present and detectable by each of the models (e.g.~Nushagak before 2015). In other years, only particular models performed well, while others struggled, indicating that information needed for a robust forecast was present but only some models were able to accurately identify the underlying relationship, highlighting the value of ensemble methods (e.g.~Naknek between 2005 and 2010). However, in other years and river systems all models struggled, for example the Wood River in 2018 and the Kvichak River in 2014. This provides evidence that the information needed to generate a robust forecast in those years was simply not present in the data that were available at the time (Fig.\ref{fig:resids}).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/resids-1.pdf}
\caption{\label{fig:resids}Centered and scaled annual residuals (forecast returns minus observed returns) by river system and model over time. Grey bands indicate areas more than one standard deviation from the mean residuals for a given system. Years in which all the lines are within a grey band indicate periods where all the models struggled to provide reasonable forecasts.}
\end{figure}

Our residual analysis suggests that in some instances we simply may need to collect different data for inclusion in the forecast model if we hope to improve forecasts. For example, none of our models were able to predict the massive spike in returns of the 1.2 age class to the Wood river system in recent years (Fig.\ref{fig:resids}), indicating that a signal of the process resulting in an increase in salmon survival was not among the suite of predictors explored. We can use the results of our most recent estimated boost\_tree model to examine the relative importance of different included data streams in improving forecast skill (Fig.\ref{fig:imp-plot}). While these importance scores cannot be interpreted in the same manner as regression coefficients, they give us a sense of where we might look for new data to inform prediction. Across all river systems, prior returns in that system were an important predictor (and in many systems past returns in other river systems were also a useful predictor).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/imp-plot-1.pdf}
\caption{\label{fig:imp-plot}Mean variable importance across all river systems of variables with importance scores greater than 0.075.}
\end{figure}

\hypertarget{discussion}{%
\section*{Discussion}\label{discussion}}
\addcontentsline{toc}{section}{Discussion}

While our tested methods made meaningful improvements in forecast accuracy in many cases, no one model type stood out as a clear winner, highlighting the need for multi-model inference in ecological forecasting.

Viewed in retrospect individual models tested here were able to make substantial improvements in forecast accuracy (Fig.\ref{fig:sys-forecast}-\ref{fig:age-forecast}). However, the best retrospective model over the years 2000-2019 varied widely by age group and system, presenting a challenge for decision makers charged with picking which model to use for a particular forecast. Ensemble models such as the random forest ensemble (i.e.~a ``model-of-models'') constructed here can help users separate out the signal from the noise in historic model performance, which in this case resulted in modest improvements in forecast still in the majority of river systems evaluated in this study.

Using multiple types of highly flexible modern computational tools can provide insight into whether historic limits to forecast skill were likely due to limitations in the information content of the available data, or from simply not finding the best model to apply to the data at hand. While we were able to improve forecast skill of Bristol Bay sockeye salmon in some instances, in particular years and systems all tested models performed poorly. These events may reflect changes in the effect of currently observed data, i.e.~a violation of the assumption that the past correlation between a variable and salmon returns will apply in the future, or may be indicative of an effect of the underling effect of an unobserved variable. The former case may be resolved by simply giving the model more years on which to train, or through explicit techniques for modeling outlier events in the manner of Anderson et al. (2017a). The later case can only be resolved through the inclusion of new data that contains information on the previously omitted process.

That forecasts for individual river systems can be improved by treating historic returns in other river systems as predictors, as evidenced by the machine learning models is an important finding. The historically used parametric salmon forecast methods have largely focused on relationships among age classes within single river systems in isolation. While perhaps not surprising given the juvenile salmon from multiple river systems enter the same area of the eastern Bering Sea during approximately the same season and likely experience similar survival conditions at ocean entry, this result suggests that sharing age-specific return abundance information among salmon stocks and river systems within Bristol Bay can inform and improve predictive performance.

In addition to the return abundance of salmon from the home and neighboring river systems, we found that oceanographic variables including mean sea surface temperature and sea surface air pressure throughout the spatial and temporal range of the oceanic phase of these salmon were informative predictors for some river systems. In addition, as reported by Connors et al. (2020), in some instances the abundance of other salmon species (chum salmon, \emph{Oncorhynchus keta}, in western Kamchatka and northern British Columbia, pink salmon, \emph{Oncorhynchus gorbuscha}, in Prince William sound) proved important predictors of Bristol Bay salmon return abundance (Fig.\ref{fig:imp-plot}). Improved data on at-sea conditions and interspecies competitors may facilitate improved forecasts in the future.

Traditional preseason forecast methods for sockeye salmon returning to Bristol Bay and throughout Alaska have often assumed that relationships among age classes are static over time. However, there is increasing recognition of time-varying relationships between Alaskan salmon production and sea surface temperature (Litzow et al. 2018), and large-scale oceanographic processes including the Pacific Decadal Oscillation (Litzow et al. 2020b, 2020a). Given evidence for the dynamic nature of salmon-climate relationships, it should not be surprising that salmon abundance forecast relationships should also exhibit temporal variability. While not informed by environmental data and only leveraging information from a single river system, the DLM approach was found to exhibit superior performance in several river systems and the 2.2 age class. It seems reasonable that the flexible nature of the DLM approach to capture time-varying dynamics in both average abundance and the ratio among age classes permits an indirect accounting for the dynamic salmon-environment processes that are increasingly recognized.

Forecast methods historically employed by the Fisheries Research Institute involved evaluation of a suite of alternative forecast models in each year, and selection of a preferred model and data time series on which to train the model (i.e.~1963 onward or after the observed shift in the Pacific Decadal Oscillation in 1980), for each salmon stock by age class combination based on forecast bias and precision over the recent 20-year period. While the FRI forecast has always been primarily based on the relationship between the abundance of age classes from the same cohort among successive years, the suite of forecast models explored as part of the FRI forecast has evolved over time. In recent years new methods have been added to the forecast model suite including autoregressive integrated moving average (ARIMA) models, boosted regression trees, Bayesian indicator variable methods, and dynamic linear models. The manual model selection process at the heart of the FRI ensemble approach has proven effective over time at identifying candidate models for forecast groups (stock-by-age) that best leverage patterns within individual time series (i.e.~ARIMA, DLM), weighting candidate predictor age classes (i.e.~Bayesian indicator variable methods), and non-linear relationships between the return abundance of age classes for a stock in prior years (i.e.~boosted regression trees). However, despite the observed value in comparing performance of alternative forecast model types inherent in the FRI forecasting approach, significant forecast errors have occurred. The range of models explored only leveraged data for sibling age classes of the same stock, and the potential for human error in the manual model selection process cannot be overlooked and present opportunity for improvement with automated ensemble approaches such as the Random Forest ensemble explored here.

We demonstrate here how modern computational modeling tools approaches can provide improvements in ecological forecasting. Ward et al. (2014) also explored the use of models similar to those used here in the context of ecological forecasting of time-series data from natural populations. They however found that the sorts of modern computational tools explored here generally performed worse than simple autoregressive models, while being substantially more computationally intensive. In contrast we found that our lag-1 benchmark model was always outperformed or equaled by one or more of our models across every resolution we evaluated. What might explain this difference? Ward et al. (2014) specifically designed their study around making predictions of future population size solely based on historic population size, while the forecast methods we explore here were informed by the abundance of multiple salmon age classes or stocks, and in some cases by environmental conditions and the abundance of other salmon species.

We would only expect the types of models employed here to provide an improvement over simpler methods if there are substantial complexities in the relationship between past and future abundance that simpler models miss (i.e.~the simpler models are misspecified). The results of Ward et al. (2014) suggest simpler models may indeed be preferable when only historic timeseries of individual stocks are available as a data source, and additional informative predictors (such as environmental data or nearby related systems) are not available. Similarly, application of computer age methods are often data intensive, and our current application is for the Bristol Bay sockeye salmon system which stands as an outlier in terms of both the quality and duration (1963) of data available on which to base predictions. More limited time series of reconstructed return abundance are often available in other regions and for other salmon species. It is possible that when constrained to forecasting salmon abundance for stocks with limited numbers of annual observations for training, testing and tuning, simpler models may indeed provide more robust prediction.

The machine learning methods explored here have access to much more data than the historic returns alone though, including environmental conditions and abundance of other salmonids. In addition, the machine learning methods used here are able to leverage correlations in returns across multiple age groups and river systems (Fig.\ref{fig:imp-plot}). While we have access to over 50 years of data, longer than some of the series reported in Ward et al. (2014), our sample sizes are still minute compared to the sample sizes in most applications of machine learning methods, indicating that these methods can still be used with the relatively small sample sizes often encountered in forecasting the population dynamics of harvested species. The results of Ward et al. (2014) suggest that more complex models may provide little benefit when the only data available are historic trends in the population being forecasted. We find though that modern computational forecasting tools can provide meaningful improvements when given additional covariates and/or structure.

\hypertarget{conclusion}{%
\section*{Conclusion}\label{conclusion}}
\addcontentsline{toc}{section}{Conclusion}

The field of ecology is generally concerned with developing theories and evidence for why ecosystems are structured and behave the ways they do. This pursuit of heuristic understanding can lead to construction of interpretable models that provide insight about system dynamics, but limited predictive power. However, for specific application in areas such as preseason salmon abundance forecasts the objective is solely to obtain accurate and precise predictions, one year into the future. We designed and optimized our models solely around predictive power, and while some methods such as empirical dynamic modeling and dynamic linear models can provide both insight and predictive skill, the machine learning methods tested here (boosted regression tree and random forests) are focused on prediction alone, with limited scope to improve ecological insight. In the case of natural resources management that often depends on making decisions today based on predictions about the future, prediction-focused methods such as those presented here can present substantial opportunity. Here we show that incorporating multiple predictive models into a statistical ensemble was able to provide some meaningful improvements in the pre-season forecast accuracy of Bristol Bay sockeye salmon.

Accurate forecasts are a crucial part of natural resource management, a task made increasingly challenging by climate change. Our gains in forecast accuracy for the economically and ecologically critical Bristol Bay sockeye salmon fishery demonstrate the ability of modern computational tools to make meaningful improvements in short-term predictive ability for the abundance of natural populations faced with a rapidly changing environment. By combining multiple modern computational tools we are able to identify likely frontiers in forecast performance given currently available data. However, even for this relatively robust dataset we were fundamentally unable to predict the returns of particular river systems and age classes in certain years. The collective failure of multiple methods in specific time steps and locations helps clarify instances in which the only likely path to meaningful forecast improvement is collection of additional data, while also highlighting the potentially irreducible impact of observation error on the limits of forecast performance. It is critical that we allocate resources to both the advancement of predictive modeling methods in ecology, and to the hard work of collecting the data from the natural world that are the foundation of any successful forecasting efforts.

\hypertarget{author-contribution-statement}{%
\section*{Author contribution statement}\label{author-contribution-statement}}
\addcontentsline{toc}{section}{Author contribution statement}

D.O., C.C., and P.K. conducted the analyses. All authors contributed to the development of the manuscript.

\hypertarget{funding-statement}{%
\section*{Funding statement}\label{funding-statement}}
\addcontentsline{toc}{section}{Funding statement}

Funding for this study was provided by the Bristol Bay Regional Seafood Development Association, by the Bristol Bay Seafood Processors, and by Douglas and Joyce McCallum.

\hypertarget{data-availability-statement}{%
\section*{Data availability statement}\label{data-availability-statement}}
\addcontentsline{toc}{section}{Data availability statement}

All data, code, and package dependencies needed to fully reproduce our results are publicly available at www.github.com/danovando/salmon-forecast-paper.

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-akaike1974}{}%
Akaike, H. 1974. A new look at the statistical model identification. IEEE Transactions on Automatic Control \textbf{19}(6): 716--723. doi:\href{https://doi.org/10.1109/TAC.1974.1100705}{10.1109/TAC.1974.1100705}.

\leavevmode\hypertarget{ref-allaire2020a}{}%
Allaire, J., and Chollet, F. 2020. Keras: R interface to 'keras'. Available from \url{https://CRAN.R-project.org/package=keras}.

\leavevmode\hypertarget{ref-allaire2020}{}%
Allaire, J., and Tang, Y. 2020. Tensorflow: R interface to 'TensorFlow'. Available from \url{https://CRAN.R-project.org/package=tensorflow}.

\leavevmode\hypertarget{ref-anderson2017c}{}%
Anderson, S.C., Branch, T.A., Cooper, A.B., and Dulvy, N.K. 2017a. Black-swan events in animal populations. Proceedings of the National Academy of Sciences \textbf{114}(12): 3252--3257. {National Academy of Sciences}. doi:\href{https://doi.org/10.1073/pnas.1611525114}{10.1073/pnas.1611525114}.

\leavevmode\hypertarget{ref-anderson2017a}{}%
Anderson, S.C., Cooper, A.B., Jensen, O.P., Minto, C., Thorson, J.T., Walsh, J.C., Afflerbach, J., Dickey-Collas, M., Kleisner, K.M., Longo, C., Osio, G.C., Ovando, D., Mosqueira, I., Rosenberg, A.A., and Selig, E.R. 2017b. Improving estimates of population status and trend with superensemble models. Fish and Fisheries \textbf{18}(4): 732--741. doi:\href{https://doi.org/10.1111/faf.12200}{10.1111/faf.12200}.

\leavevmode\hypertarget{ref-araujo2007}{}%
Ara'ujo, M.B., and New, M. 2007. Ensemble forecasting of species distributions. Trends in Ecology \& Evolution \textbf{22}(1): 42--47. doi:\href{https://doi.org/10.1016/j.tree.2006.09.010}{10.1016/j.tree.2006.09.010}.

\leavevmode\hypertarget{ref-beyan2020}{}%
Beyan, C., and Browman, H.I. 2020. Setting the stage for the machine intelligence era in marine science. ICES Journal of Marine Science \textbf{77}(4): 1267--1273. {Oxford Academic}. doi:\href{https://doi.org/10.1093/icesjms/fsaa084}{10.1093/icesjms/fsaa084}.

\leavevmode\hypertarget{ref-breiman2001}{}%
Breiman, L. 2001. Random {Forests}. Machine Learning \textbf{45}(1): 5--32. doi:\href{https://doi.org/10.1023/A:1010933404324}{10.1023/A:1010933404324}.

\leavevmode\hypertarget{ref-chamberlain2019}{}%
Chamberlain, S. 2019. Rerddap: General purpose client for 'ERDDAP' servers. Available from \url{https://CRAN.R-project.org/package=rerddap}.

\leavevmode\hypertarget{ref-chang2017}{}%
Chang, C.-W., Ushio, M., and Hsieh, C. 2017. Empirical dynamic modeling for beginners. Ecological Research \textbf{32}(6): 785--796. doi:\href{https://doi.org/10.1007/s11284-017-1469-9}{10.1007/s11284-017-1469-9}.

\leavevmode\hypertarget{ref-chen2020}{}%
Chen, T., He, T., Benesty, M., Khotilovich, V., Tang, Y., Cho, H., Chen, K., Mitchell, R., Cano, I., Zhou, T., Li, M., Xie, J., Lin, M., Geng, Y., and Li, Y. 2020. Xgboost: Extreme gradient boosting. Available from \url{https://CRAN.R-project.org/package=xgboost}.

\leavevmode\hypertarget{ref-connors2020}{}%
Connors, B., Malick, M.J., Ruggerone, G.T., Rand, P., Adkison, M., Irvine, J.R., Campbell, R., and Gorman, K. 2020. Climate and competition influence sockeye salmon population dynamics across the {Northeast Pacific Ocean}. Canadian Journal of Fisheries and Aquatic Sciences. {NRC Research Press 1840 Woodward Drive, Suite 1, Ottawa, ON K2C 0P7}. doi:\href{https://doi.org/10.1139/cjfas-2019-0422}{10.1139/cjfas-2019-0422}.

\leavevmode\hypertarget{ref-cunningham2019}{}%
Cunningham, C.J., Anderson, C.M., Wang, J.Y.-L., Link, M., and Hilborn, R. 2019. A management strategy evaluation of the commercial sockeye salmon fishery in {Bristol Bay}, {Alaska}. Canadian Journal of Fisheries and Aquatic Sciences \textbf{76}(9): 1669--1683. doi:\href{https://doi.org/10.1139/cjfas-2018-0133}{10.1139/cjfas-2018-0133}.

\leavevmode\hypertarget{ref-Dietterich2000}{}%
Dietterich, T.G. 2000. Ensemble {Methods} in {Machine Learning}. \emph{In} Multiple {Classifier Systems}. {Springer, Berlin, Heidelberg}. pp. 1--15. doi:\href{https://doi.org/10.1007/3-540-45014-9_1}{10.1007/3-540-45014-9\_1}.

\leavevmode\hypertarget{ref-efron2016}{}%
Efron, B., and Hastie, T. 2016. Computer age statistical inference: Algorithms, evidence, and data science. {Cambridge University Press}, {New York, NY}.

\leavevmode\hypertarget{ref-elith2008}{}%
Elith, J., Leathwick, J.R., and Hastie, T. 2008. A working guide to boosted regression trees. Journal of Animal Ecology \textbf{77}(4): 802--813. doi:\href{https://doi.org/10.1111/j.1365-2656.2008.01390.x}{10.1111/j.1365-2656.2008.01390.x}.

\leavevmode\hypertarget{ref-fried1988}{}%
Fried, S.M., and Hilborn, R. 1988. Inseason {Forecasting} of {Bristol Bay}, {Alaska}, {Sockeye Salmon} ({Oncorhynchus} nerka) {Abundance Using Bayesian Probability Theory}. Canadian Journal of Fisheries and Aquatic Sciences \textbf{45}(5): 850--855. doi:\href{https://doi.org/10.1139/f88-103}{10.1139/f88-103}.

\leavevmode\hypertarget{ref-holmes2012}{}%
Holmes, E.E., Ward, E.J., and Wills, K. 2012. MARSS: Multivariate autoregressive state-space models for analyzing time-series data. The R Journal \textbf{4}(1): 30.

\leavevmode\hypertarget{ref-holmes2020}{}%
Holmes, E., Ward, E., Scheuerell, M., and Wills, K. 2020. MARSS: Multivariate autoregressive state-space modeling. Available from \url{https://CRAN.R-project.org/package=MARSS}.

\leavevmode\hypertarget{ref-hyndman2006}{}%
Hyndman, R.J., and Koehler, A.B. 2006. Another look at measures of forecast accuracy. International Journal of Forecasting \textbf{22}(4): 679--688. doi:\href{https://doi.org/10.1016/j.ijforecast.2006.03.001}{10.1016/j.ijforecast.2006.03.001}.

\leavevmode\hypertarget{ref-knapp2013}{}%
Knapp, G., Mouhcine, G., and Goldsmith, S. 2013. The {Economic Importance} of {theBristol Bay Salmon Industry}. {Institute of Social and Economic Research}, {University of Alaska Anchorage}.

\leavevmode\hypertarget{ref-litzow2018}{}%
Litzow, M.A., Ciannelli, L., Puerta, P., Wettstein, J.J., Rykaczewski, R.R., and Opiekun, M. 2018. Non-stationary climate{}salmon relationships in the {Gulf} of {Alaska}. Proceedings of the Royal Society B: Biological Sciences \textbf{285}(1890): 20181855. {Royal Society}. doi:\href{https://doi.org/10.1098/rspb.2018.1855}{10.1098/rspb.2018.1855}.

\leavevmode\hypertarget{ref-litzow2020a}{}%
Litzow, M.A., Hunsicker, M.E., Bond, N.A., Burke, B.J., Cunningham, C.J., Gosselin, J.L., Norton, E.L., Ward, E.J., and Zador, S.G. 2020a. The changing physical and ecological meanings of {North Pacific Ocean} climate indices. Proceedings of the National Academy of Sciences \textbf{117}(14): 7665--7671. {National Academy of Sciences}. doi:\href{https://doi.org/10.1073/pnas.1921266117}{10.1073/pnas.1921266117}.

\leavevmode\hypertarget{ref-litzow2020}{}%
Litzow, M.A., Malick, M.J., Bond, N.A., Cunningham, C.J., Gosselin, J.L., and Ward, E.J. 2020b. Quantifying a {Novel Climate Through Changes} in {PDO}-{Climate} and {PDO}-{Salmon Relationships}. Geophysical Research Letters \textbf{47}(16): e2020GL087972. doi:\href{https://doi.org/10.1029/2020GL087972}{10.1029/2020GL087972}.

\leavevmode\hypertarget{ref-malde2020}{}%
Malde, K., Handegard, N.O., Eikvil, L., and Salberg, A.-B. 2020. Machine intelligence and the data-driven future of marine science. ICES Journal of Marine Science \textbf{77}(4): 1274--1285. {Oxford Academic}. doi:\href{https://doi.org/10.1093/icesjms/fsz057}{10.1093/icesjms/fsz057}.

\leavevmode\hypertarget{ref-mcdowellgroup2018}{}%
McDowell Group. 2018. Bristol {Bay Sockeye Market Report}.

\leavevmode\hypertarget{ref-munch2020}{}%
Munch, S.B., Brias, A., Sugihara, G., and Rogers, T.L. 2020. Frequently asked questions about nonlinear dynamics and empirical dynamic modelling. ICES Journal of Marine Science \textbf{77}(4): 1463--1479. {Oxford Academic}. doi:\href{https://doi.org/10.1093/icesjms/fsz209}{10.1093/icesjms/fsz209}.

\leavevmode\hypertarget{ref-naiman2002}{}%
Naiman, R.J., Bilby, R.E., Schindler, D.E., and Helfield, J.M. 2002. Pacific {Salmon}, {Nutrients}, and the {Dynamics} of {Freshwater} and {Riparian Ecosystems}. Ecosystems \textbf{5}(4): 399--417. doi:\href{https://doi.org/10.1007/s10021-001-0083-3}{10.1007/s10021-001-0083-3}.

\leavevmode\hypertarget{ref-park2020}{}%
Park, J., Smith, C., Sugihara, G., and Deyle, E. 2021. rEDM: Empirical dynamic modeling ('EDM'). Available from \url{https://CRAN.R-project.org/package=rEDM}.

\leavevmode\hypertarget{ref-peters2014}{}%
Peters, D.P.C., Havstad, K.M., Cushing, J., Tweedie, C., Fuentes, O., and Villanueva-Rosales, N. 2014. Harnessing the power of big data: Infusing the scientific method with machine learning to transform ecology. Ecosphere \textbf{5}(6): art67. doi:\href{https://doi.org/10.1890/ES13-00359.1}{10.1890/ES13-00359.1}.

\leavevmode\hypertarget{ref-petris2009}{}%
Petris, G., Petrone, S., and Campagnoli, P. 2009. Dynamic linear models {With R}. {Springer}, {Dordrecht ; New York}.

\leavevmode\hypertarget{ref-pole1994}{}%
Pole, A., West, M., and Harrison, J. 1994. Applied {Bayesian} forecasting and time series analysis. {Chapman and Hall}, {New York}.

\leavevmode\hypertarget{ref-rcoreteam2020}{}%
R Core Team. 2020. R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. Available from \url{https://www.R-project.org/}.

\leavevmode\hypertarget{ref-ruggerone2018}{}%
Ruggerone, G.T., and Irvine, J.R. 2018. Numbers and {Biomass} of {Natural}- and {Hatchery}-{Origin Pink Salmon}, {Chum Salmon}, and {Sockeye Salmon} in the {North Pacific Ocean}, 1925{}. Marine and Coastal Fisheries \textbf{10}(2): 152--168. doi:\href{https://doi.org/10.1002/mcf2.10023}{10.1002/mcf2.10023}.

\leavevmode\hypertarget{ref-schindler2003}{}%
Schindler, D.E., Scheuerell, M.D., Moore, J.W., Gende, S.M., Francis, T.B., and Palen, W.J. 2003. Pacific salmon and the ecology of coastal ecosystems. Frontiers in Ecology and the Environment \textbf{1}(1): 31--37. doi:\href{https://doi.org/10.1890/1540-9295(2003)001\%5B0031:PSATEO\%5D2.0.CO;2}{10.1890/1540-9295(2003)001{[}0031:PSATEO{]}2.0.CO;2}.

\leavevmode\hypertarget{ref-steiner2011}{}%
Steiner, E.M., Criddle, K.R., and Adkison, M.D. 2011. Balancing {Biological Sustainability} with the {Economic Needs} of {Alaska}'s {Sockeye Salmon Fisheries}. North American Journal of Fisheries Management \textbf{31}(3): 431--444. doi:\href{https://doi.org/10.1080/02755947.2011.588917}{10.1080/02755947.2011.588917}.

\leavevmode\hypertarget{ref-sugihara1994}{}%
Sugihara, G., Grenfell, B.T., May, R.M., and Tong, H. 1994. Nonlinear forecasting for the classification of natural time series. Philosophical Transactions of the Royal Society of London. Series A: Physical and Engineering Sciences \textbf{348}(1688): 477--495. {Royal Society}. doi:\href{https://doi.org/10.1098/rsta.1994.0106}{10.1098/rsta.1994.0106}.

\leavevmode\hypertarget{ref-sugihara1990}{}%
Sugihara, G., and May, R.M. 1990. Nonlinear forecasting as a way of distinguishing chaos from measurement error in time series. Nature \textbf{344}(6268): 734--741. {Nature Publishing Group}. doi:\href{https://doi.org/10.1038/344734a0}{10.1038/344734a0}.

\leavevmode\hypertarget{ref-sugihara2012}{}%
Sugihara, G., May, R., Ye, H., Hsieh, C., Deyle, E., Fogarty, M., and Munch, S. 2012. Detecting {Causality} in {Complex Ecosystems}. Science \textbf{338}(6106): 496--500. doi:\href{https://doi.org/10.1126/science.1227079}{10.1126/science.1227079}.

\leavevmode\hypertarget{ref-takens1981}{}%
Takens, F. 1981. Detecting strange attractors in turbulence. \emph{In} Dynamical {Systems} and {Turbulence}, {Warwick} 1980. \emph{Edited by} D. Rand and L.-S. Young. {Springer}, {Berlin, Heidelberg}. pp. 366--381. doi:\href{https://doi.org/10.1007/BFb0091924}{10.1007/BFb0091924}.

\leavevmode\hypertarget{ref-ward2014}{}%
Ward, E.J., Holmes, E.E., Thorson, J.T., and Collen, B. 2014. Complexity is costly: A meta-analysis of parametric and non-parametric methods for short-term population forecasting. Oikos \textbf{123}(6): 652--661. doi:\href{https://doi.org/10.1111/j.1600-0706.2014.00916.x}{10.1111/j.1600-0706.2014.00916.x}.

\leavevmode\hypertarget{ref-wright2017}{}%
Wright, M.N., and Ziegler, A. 2017. Ranger: {A Fast Implementation} of {Random Forests} for {High Dimensional Data} in {C}++ and {R}. Journal of Statistical Software \textbf{77}(1): 1--17. doi:\href{https://doi.org/10.18637/jss.v077.i01}{10.18637/jss.v077.i01}.

\leavevmode\hypertarget{ref-ye2015}{}%
Ye, H., Beamish, R.J., Glaser, S.M., Grant, S.C.H., Hsieh, C., Richards, L.J., Schnute, J.T., and Sugihara, G. 2015. Equation-free mechanistic ecosystem forecasting using empirical dynamic modeling. Proceedings of the National Academy of Sciences \textbf{112}(13): E1569--E1576. doi:\href{https://doi.org/10.1073/pnas.1417063112}{10.1073/pnas.1417063112}.

\leavevmode\hypertarget{ref-ye2020}{}%
Ye, H., Clark, A., Deyle, E., and Munch, S. 2020. rEDM: Applications of empirical dynamic modeling from time series.

\leavevmode\hypertarget{ref-ye2016}{}%
Ye, H., and Sugihara, G. 2016. Information leverage in interconnected ecosystems: {Overcoming} the curse of dimensionality. Science. {American Association for the Advancement of Science}.

\end{CSLReferences}

\end{document}
