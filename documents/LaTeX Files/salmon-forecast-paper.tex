% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Identifying Frontiers in Ecological Forecasting with Modern Computational Tools},
  pdfauthor={Daniel Ovando*; Curry Cunningham; Peter Kuriyama; Chris Boatright; Ray Hilborn},
  colorlinks=true,
  linkcolor=blue,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=Blue,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{setspace}\doublespacing
\usepackage{lineno}\linenumbers
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{Identifying Frontiers in Ecological Forecasting with Modern Computational Tools}
\author{Daniel Ovando* \and Curry Cunningham \and Peter Kuriyama \and Chris Boatright \and Ray Hilborn}
\date{2021-01-15}

\begin{document}
\maketitle

\newpage

\hypertarget{title-page}{%
\section*{Title Page}\label{title-page}}
\addcontentsline{toc}{section}{Title Page}

\hypertarget{running-head}{%
\subsection*{Running Head}\label{running-head}}
\addcontentsline{toc}{subsection}{Running Head}

Finding Frontiers in Ecological Forecasting

\hypertarget{title}{%
\subsection*{Title}\label{title}}
\addcontentsline{toc}{subsection}{Title}

Identifying Frontiers in Ecological Forecasting with Modern Computational Tools

\hypertarget{list-of-authors}{%
\subsection*{List of Authors}\label{list-of-authors}}
\addcontentsline{toc}{subsection}{List of Authors}

Daniel Ovando\textsuperscript{a}*, Curry Cunningham\textsuperscript{b},Peter Kuriyama\textsuperscript{c},Christopher Boatright\textsuperscript{a}, Ray Hilborn \textsuperscript{a}

\textsuperscript{a}School of Aquatic and Fishery Sciences University of Washington 1122 NE Boat St, Box 355020 Seattle, WA 98195-5020

\textsuperscript{b}College of Fisheries and Ocean Sciences University of Alaska Fairbanks 17101 Point Lena Loop Road Juneau, AK 99801

\textsuperscript{c}NOAA Fisheries Southwest Fisheries Science Center 8901 La Jolla Shores Dr, La Jolla, CA 92037

\hypertarget{corresponding-author}{%
\subsection*{Corresponding Author}\label{corresponding-author}}
\addcontentsline{toc}{subsection}{Corresponding Author}

*Correspondence should be addressed to Daniel Ovando at \href{mailto:danovan@uw.edu}{\nolinkurl{danovan@uw.edu}}

\newpage

\hypertarget{abstract}{%
\subsection*{Abstract}\label{abstract}}
\addcontentsline{toc}{subsection}{Abstract}

Modern computational tools such as machine learning have transformed predictive fields from advertising to weather forecasting. However, these methods are not yet heavily utilized for managing ecological systems. Salmon are a natural, cultural, and economic keystone of Alaska, and accurate pre-season forecasts of the numbers of sockeye salmon (\emph{Oncorhynchus nerka}), that will return to the river systems of Bristol Bay play an important role in management and harvesting decisions. These predictions are challenging though, given the complex set of dynamic factors that affect salmon. We use data from the salmon populations of Bristol Bay, Alaska, together with a suite of modern forecasting tools, to identify the frontiers in forecast accuracy possible given currently available data. By leveraging dynamic environmental information and correlations between salmon populations, we were able to reduce forecast error by on average 21\% relative to a simple null model, and by 16\% relative to a benchmark model used in the system. Our results demonstrate both the utility and limitations of modern computational tools for applied management of natural resources, even when confronted with the short time series and observation error common in ecological systems.

\hypertarget{keywords}{%
\subsection*{Keywords}\label{keywords}}
\addcontentsline{toc}{subsection}{Keywords}

Alaska, Salmon,Machine learning,Empirical Dynamic Modeling, Dynamic Linear Models, Predictive Modeling, Ecological Forecasting

\newpage

\hypertarget{introduction}{%
\section*{Introduction}\label{introduction}}
\addcontentsline{toc}{section}{Introduction}

Animal populations exhibit complex dynamics driven by interactions with many aspects of their ecosystem. Predicting the outcomes of these dynamics is a critical task of natural resource management; Forecasts of future abundance are often used to set fisheries regulations, vessel operators may make decisions about alternative fisheries based on predicted abundance, and industries and communities use forecasts to inform long-term and short-term investment plans in staffing and production capacity. However, the methods used to make these ecological predictions are often decades old and generally do not go beyond forward projection from age-structured models.

The past two decades have seen explosive progress in the ability of modern ``computer age'' tools to improve predictive models (Efron and Hastie 2016), revolutionizing fields such as financial modeling, weather forecasting, and medicine. However, these methods remain relatively unused in ecological forecasting, particularly in an applied setting (Peters et al. 2014). We use the ecologically and economically critical sockeye salmon (\emph{Oncorhynchus nerka}) populations of Bristol Bay, Alaska to demonstrate the use of modern computation tools in applied predictive modeling, and show how they can be used to identify frontiers in forecast accuracy given currently available data.

The commercial salmon fishery in Bristol Bay, Alaska is the single largest sockeye salmon fishery in the world (Steiner et al. 2011). The estimated wholesale value of the Bristol Bay commercial sockeye harvest was \$390 million USD in 2010, providing approximately one-sixth of the total value of all United States seafood exports (Knapp et al. 2013), reaching a value of \$508 million by 2017 (McDowell Group 2018). Salmon returning to Bristol Bay also provide vital food security for subsistence-dependent Alaskan communities, and are critical vectors of marine-derived nutrients that support vibrant freshwater habitats (Naiman et al. 2002, Schindler et al. 2003). Sustainable management of the Bristol Bay salmon fishery depends in part on the accuracy of preseason forecasts for salmon abundance, which inform development and implementation of inseason harvest strategies and successful operation of subsistence and commercial fisheries. Preseason forecasts are also important for planning by the processing industry, as a basis for identifying the appropriate level of supplies, equipment, and personnel necessary to process the annual harvest. As such, the accuracy of salmon forecasts have a direct influence on the profitability and efficiency of the salmon industry as a whole.

Sockeye salmon are born in freshwater, where they spend the first one or more years of their lives. Eventually, these fish migrate to the ocean, where they live the remainder of their lives until returning to their natal river systems to spawn and then die. Sockeye salmon can spend a range of years in these freshwater and oceanic phases, denoted as ``age groups.'' Following conventions in the salmon literature, we denote age groups here by the format ``years spent in freshwater.years spent in the ocean.'' For example, a fish in the 1.2 age group spent one winter post-hatching in freshwater and migrating to sea two years after it was spawned, and 2 winters in the ocean before returning to freshwater to spawn. The Bristol Bay sockeye salmon fishery is primarily made up of salmon from seven different river systems, each of which is managed as a separate stock (Fig.\ref{fig:returns}).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/returns-1.pdf}
\caption{\label{fig:returns}Annual total abundance of returning sockeye salmon (\emph{Oncorhynchus nerka}) to Bristol Bay, Alaska (A), by river system (B), and by age group (C). Numbers in millions of salmon. Age group is formatted by `years spent in freshwater.'`years spent in ocean'. Map adapted from Cunningham et al. (2019).}
\end{figure}

Why might we expect modern computational tools to be well-suited to the task of salmon forecasting? Methods such as machine learning excel at identifying and exploiting potentially complex correlations between variables in a system. Conversely, ``traditional'' statistical methods often restrict themselves to simplified (e.g.~linear) and often non-dynamic representations of natural systems, both for analytical tractability and to facilitate understanding of underlying processes. Typically, these traditional statistical methods are concerned with explicitly estimating and interpreting model parameters rather than solely forecasting responses, such as population size (Beyan and Browman 2020, Malde et al. 2020). We would expect modern computational tools to show substantial improvement in predictive power when the ``true'' underlying system linking observed variables and outcomes differs dramatically from more simplistic representations of the system approximated by conventional statistical approaches. In the case of salmon, we know that inter-annual variation in run sizes is affected by a wide range of ecosystem variables, including spawning success, river conditions, oceanic predator and prey abundance, and competition with other salmonids (Connors et al. 2020).

Rather than incorporate these factors directly, salmon forecasting has traditionally relied on cohort or ``sibling'' regression methods, in which the return abundance of an older age class is predicted by the abundance of younger age classes returning in prior years but originating from the same river system and brood year. For example, the return abundance of four-year old fish are predicted by the returns of three-year old fish observed in the previous season. There are good reasons for this practice: trends in sibling abundance internalize many factors affecting salmon returns. If a particular cohort suffers from poor environmental conditions and large amount of competition with other predators, the impacts of that will be reflected in the return abundance of younger age classes from the same cohort (i.e.~originating from the same brood year) that experienced similar environmental conditions and resource availability, and by extension survival, as juveniles. However, this sibling regression method does have shortcomings, most notably the underlying assumption of consistency in the relationship between the abundance of age classes and stability in the maturation schedule (i.e.~the probability of salmon maturing and returning to freshwater to spawn after a given number of years in the ocean). For example, if environmental conditions cause members of a cohort of salmon to spend more time at sea than in previous years, a sibling regression might under-predict the number of future returns. In addition, sibling regression requires accurate observations of the return abundance for younger sibling age classes, limiting the performance of these models in predicting returns of younger salmon for which few or no siblings (i.e.~returning younger age classes) have yet been observed.

We hypothesize that directly incorporating data on candidate potentially time-varying factors influencing and correlated with salmon return size, rather than relying on sibling returns alone, may help improve forecasting given the intricate dynamics of salmon populations. However, these variables are likely to have complex, non-linear, and non-stationary effects on salmon populations, potentially obscuring their value from conventional parametric statistical approaches, with user-defined parameters, structures, and error distributions. In order to explore this possibility, we use a suite of six methods together with a panel of data on salmon populations and environmental conditions in Bristol Bay, Alaska to explore what if any improvements in forecast skill can be achieved. These models include two machine learning methods, a random forest (rand\_forest), (Breiman 2001, Wright and Ziegler 2017) and a boosted regression tree, boost\_tree, (Chen et al. 2020)), empirical dynamic models (edm) (Sugihara and May 1990, Ye et al. 2020, Munch et al. 2020), and dynamic linear models (dlm)(Pole et al. 1994, Petris et al. 2009). We also include a lag-1 model, (lag\_1), as a performance benchmark, in which the predicted returns for a given age group and river system in a year are equal to the observed returns for that that age group in that river system in the prior year. Our goal here is not to establish whether one type of model performs inherently better than others, but to evaluate how use of different computer age models and data types can collectively improve forecast ability and identify frontiers in forecast ability given available data. While our tested methods made meaningful improvements in forecast accuracy in many cases, no one model type stood out as a clear winner, highlighting the need for multi-model inference in ecological forecasting.

\hypertarget{methods}{%
\section*{Methods}\label{methods}}
\addcontentsline{toc}{section}{Methods}

All code and data needed to fully replicate our results are publicly available at \url{https://github.com/DanOvando/salmon-forecast-paper/}. We describe critical details of each our main methods here.

The general structure of our methods is as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Individual models for each river system and age group were fit to historical data
\item
  Performance of individual models was assessed by comparing against a benchmark ``lag-1'' prediction model in which the forecast for next year is simply the observed returns in the previous year
\item
  Individual models were aggregated into a statistical ensemble model based on their historic performance against the lag\_1 benchmark
\item
  The statistical ensemble model was then compared to a more qualitatively constructed ensemble model, in which researchers manually select individual models from an evolving suite of methods based on recent (20-year) performance. This is the method historically used to generate Bristol Bay salmon forecasts, although the individual prediction models within the selection suite have changed over time. As such this method provides a \emph{status quo} benchmark to which individual models and statistical ensembles may be compared.
\end{enumerate}

\hypertarget{machine-learning-models}{%
\subsection*{Machine Learning Models}\label{machine-learning-models}}
\addcontentsline{toc}{subsection}{Machine Learning Models}

We evaluated two different machine learning models: a random forest (rand\_forest, implemented through the \texttt{ranger} package (Wright and Ziegler 2017) in R (R Core Team 2020)), and boosted regression trees, boost\_tree, through the \texttt{xgboost} package (Chen et al. 2020). A recurrent neural network implemented through \texttt{tensorflow} (Allaire and Tang 2020) through the \texttt{keras} interface (Allaire and Chollet 2020) was also tested but was found to perform poorly relative to the other methods and to be extremely computationally intensive, and as such was not included in the main analysis. Random forests are ensembles of regression trees, which make predictions by selecting nested splits of variables and mapping the mean level of the dependent variable at the terminal nodes of each tree. Boosted regression trees are similar to random forests, but have mechanisms in place that actively update the model to address data points that the model is struggling to fit (Elith et al. 2008). For all machine learning methods, within a model fit the model selects splits/transformations/coefficients in order to minimize the root mean squared error (RMSE) of predictions on data held out from the fitting process by the algorithm.

Each of the machine learning methods had access to a variety of population and environmental data. We fit versions of each model separately for each age group in each major river system. Within that river system, the candidate predictor variables included the sibling returns for the cohort in question in all river systems, the numbers of the cohort that spawned the cohort in question, along with the cumulative mean environmental conditions (sea surface temperature, pacific decadal oscillation, sea surface air pressure, and degree of upwelling) over the years the cohort spent at sea, and the reported numbers of chum and pink salmon throughout the North Pacific reported by Ruggerone and Irvine (2018).

Models were fit at the level of age groups by river system. Data were first split into training and testing sets. We then split each of the training sets (e.g.~all data before the year 2000 if the year 2001 is to be forecasted) into a series of analysis and assessment splits. Given the timeseries nature of the data, we generated these analysis and assessment splits in a rolling manner: for the first split, we used the first 70\% of the training year to fit a model, and the remaining 30\% to evaluate the performance of that model, followed by the first 75\% and 25\%, etc. These analysis and assessment splits were used to tune nuisance parameters common to all machine learning models, for example the minimum node size of fitted trees. We fit each of our assessment splits across a grid of potential parameter values, and selected the set of tuning parameters that minimized the RMSE of the predictions on the assessment splits (see computational environment available at \url{https://github.com/DanOvando/salmon-forecast-paper/} for detailed steps in this process).

Once the set of tuning parameters for each training set were selected, we then fit the final model using all the training data with those tuned parameters, and then used that model to predict the returns in the testing set. All relevant data transformations were prepared only on training / analysis splits (e.g.~means and standard deviations for centering and scaling) and then applied to testing / assessment splits.

\hypertarget{dynamic-linear-models}{%
\subsection*{Dynamic Linear Models}\label{dynamic-linear-models}}
\addcontentsline{toc}{subsection}{Dynamic Linear Models}

Traditional methods for forecasting sockeye salmon abundance in Bristol Bay and throughout Alaska, have relied on the relationship between the abundance of different age classes from the same cohort, or originating from the same brood year, but returning to breed in subsequent years. These ``sibling'' or cohort regression models leverage the fact that salmon spawned in the same brood year and migrating to sea in the same year exhibit similar patterns in survival, based upon their shared exposure to the same physical environmental conditions, prey resource availability, and predator field, as juveniles and at ocean entry.

Foundational to the predictability of sibling relationships is the assumption that the ratio of returns by age class remains stable across time. In a context of a linear model, for example, we can model returns as \(\hat{R^{1.3}_t} = \alpha + \beta{R^{1.2}_{t-1}}\) where \(\hat{R^{1.3}_t}\) is the predicted return abundance of the older age class and \(R^{1.2}_{t-1}\) is the observed abundance of the same cohort returning in the prior year after one few years in the ocean (i.e.~1.2). Under a classic sibling regression the assumption is that the estimated parameters \(\alpha\) and \(\beta\) remain constant across time. However, there are multiple conditions under which both the average return abundance of a particular age class or the ratio of abundances among age classes might change over time. For example, if the average maturation schedule (i.e.~the probability that an individual will mature after 2 vs.~3 years in the ocean) changes in response to natural or anthropogenic selection, the assumption of a stationary parameter is violated. Alternatively, if average marine mortality experienced by salmon changes as a result of large-scale climate, ecosystem, or trophic shifts, this should be reflected by changes in both parameters of the regression model.

To better represent the dynamic nature of sibling or cohort relationships over time and improve predictive performance, we implement dynamic linear models (DLMs). DLMs are a class of regression models where the values of regression coefficients are permitted to evolve over time, rather than remain static (Pole et al. 1994, Petris et al. 2009). DLMs were fit to available data using a single predictor age class (one fewer year in the ocean, returning the prior year), and allowing for evolution of both the slope and intercept parameters over time, as:

\[\hat{R^{1.3}_t} = \alpha_t + \beta_t{R^{1.2}_{t-1}} + \epsilon_t\]

Both regression parameters are described by a random walk (i.e.~\(\alpha_t \sim Normal(\alpha_{t-1},\sigma^2_{\alpha})\) and \(\beta_t \sim Normal(\beta_{t-1},\sigma^2_{\beta})\)), and errors were assumed normally-distributed (\(\epsilon_t \sim Normal(0,\sigma^2_{\epsilon})\)). DLMs were implemented using the Multivariate Autoregressive State-Space Modelling (MARSS) package (version 3.10.12) in R (Holmes et al. 2012, Holmes et al. 2020).

\hypertarget{empirical-dynamic-modeling}{%
\subsection*{Empirical Dynamic Modeling}\label{empirical-dynamic-modeling}}
\addcontentsline{toc}{subsection}{Empirical Dynamic Modeling}

Empirical dynamic modeling (EDM) is a nonparametric approach to characterize ecological dynamics and generate forecasts. The approach is predicated on Takens' theorem, which states that a single time series and a number of lags (dimension; E) are representative of overall system dynamics (Takens 1981, Sugihara and May 1990). Applications of EDM have identified causal relationships in ecological systems (Sugihara et al. 2012) and improved forecast skill in Fraser River sockeye salmon (Ye et al. 2015). See (Munch et al. 2020) and (Chang et al. 2017) for more general overviews of EDM. We used the software package rEDM (Ye et al. 2020) for analysis.

Here, we applied simplex projection (hereafter simplex) and sequentially locally weighted global linear maps (s-map) to the Bristol Bay sockeye data. Both methods require identifying the dimensionality (E) of a time series and constructing an attractor (a time series and its E-lagged coordinates). Leave-one-out prediction identifies the best E of a time series. We used E values ranging from 1 to 10, found the E-nearest neighbors (based on Euclidean distance) from the observation of interest, and calculated a predicted value by averaging the E-nearest neighbors. The best E had the highest correlation between observed and predicted values. S-maps is an extension of simplex that has the addition of a weighting parameter (theta) which modifies the strength of nearest neighbor weighting (theta=0 weights nearest neighbors equally; theta\textgreater0 stronger weighting of nearest neighbors) (Sugihara et al. 1994).

We used s-maps for each of the river, age-class combinations. For example, we predicted Kvichak 1.2 returns. We identified the best E for Kvichak 1.2 and also included information from the the top 6 age classes (based on average returns) for Kvichak. The attractors had a time series and its lagged coordinates and the unlagged coordinates for abundant age classes. The s-map theta values were selected based on the conditioning data set (e.g.~time series up to 2000) to predict one year into the future (2001).

\hypertarget{performance-metrics}{%
\subsection*{Performance Metrics}\label{performance-metrics}}
\addcontentsline{toc}{subsection}{Performance Metrics}

We do not conduct formal statistical tests of model fit or performance. Parameters of conventional statistical models might be assessed in terms of statistical significance, and models compared via some form of information criterion. However, neither the machine learning or the empirical dynamic modeling methods have formal estimates of uncertainty or likelihoods, and as such do not produce measures of statistical significance around individual forecasts, and cannot be compared using information criteria such as AIC (Akaike 1974) scores. Accordingly, we judge model performance by the point estimates of SRMSE produced by each model across the retrospective horizon 1990-2019. SRMSE measures the performance of each model relative to a lag\_1 model, a conventional benchmark model for timeseries modeling (Hyndman and Koehler 2006, Ward et al. 2014)

RMSE is calculated as

\[RMSE_m = \sqrt{\frac{1}{I}\sum\limits_{i = 1}^I(y_{i} - f_{i,m})^2}\]

where \emph{i} represents an observation of numbers of returning salmon \emph{y} and the forecast for those numbers \emph{f} by a given model \emph{m}. In the manner of mean absolute scaled error (MASE, (Hyndman and Koehler 2006)), we scale each models RMSE for a given resolution by the RMSE of a lag\_1 model for the same resolution (for example at the river system level).

\[RMSE_{l1} = \sqrt{\frac{1}{I}\sum\limits_{i = 1}^I(y_{i} - y_{i,l1})^2}\]

and SRMSE for model \emph{m} is then

\[SRMSE_m = \frac{RMSE_m}{RMSE_{l1}}\]

MASE is commonly used to judge the accuracy of predictions derived from time series models, since it compares the error of a given model to the error expected by a simple model in which the predictions in a given time step are equal to the observed values in the last time step (an lag\_1 model). We use SRMSE instead of MASE to reflect the use of the forecast. MASE considers an error of ten to be twice as bad as an error of five. In the context of salmon forecasting, our primary objective is to avoid massively over or under estimating the pre-season forecast. SRMSE penalizes large errors more than small errors, helping select models that avoid the kinds of large errors that are most problematic for the task of managing salmon populations.

A SRMSE of one means that a model has predictive performance equal to that of the lag\_1 model. A SRMSE greater than one indicates that a given model performs worse than the lag\_1 benchmark, a SRMSE less than one that a model performs better than the lag\_1 benchmark (Hyndman and Koehler 2006).

\hypertarget{testing-regime}{%
\subsection*{Testing Regime}\label{testing-regime}}
\addcontentsline{toc}{subsection}{Testing Regime}

All models were compared based upon one-step-ahead forecast skill, defined by SRMSE. Each of the evaluated models generate forecasts at the resolution of age group and river system in a given year. Forecasts for a given year are produced by a model trained on all years after 1963 and prior to the year for which a forecast is desired. This is performed in a rolling fashion, such that for example forecasts for the year 2018 are produced by a model trained on data from 1963 to 2017, the 2019 forecast by a model trained on data from 1963 to 2018, and so on. Each method has its own ways of tuning and validating the model, but all such steps are performed using only the training data: all data for the forecast year are held out until the final prediction.

Predictive performance of candidate models was calculated by generating 1-year ahead forecasts for each target river system by age class combination, as a rolling window from the year 2000 to 2019. This method for quantifying forecast performance is most applicable to the context of this ecological forecasting problem as each candidate model is trained on data up to, but not including, the prediction year. In this way, retrospective forecast performance is evaluated using the data that would have been available to the analyst in each year historically. Even though each model predicts at the resolution of age group and river system, we generally compare model performance at coarser resolutions (for example river system across all age groups). In those cases, we first aggregate the total returns at the resolution in question (e.g.~sum all observed and forecast returns across all age groups for a given river system), and then calculate SRMSE based on those aggregated data.

\hypertarget{ensemble-models}{%
\subsection*{Ensemble Models}\label{ensemble-models}}
\addcontentsline{toc}{subsection}{Ensemble Models}

The testing regime allows us to compare the predictive power, defined by SRMSE, of individual models at a variety of spatial resolutions. However, a substantial body of literature suggests that creating ``ensemble'' models that weigh individual models to create a single composite prediction can outperform any one individual model (Dietterich 2000, Ara'ujo and New 2007, Anderson et al. 2017b). We test this idea here by comparing two different ensemble models: a purely statistical ensemble constructed by a random forest, and a mixed-methods ensemble model published by the Fisheries Research Institute (FRI) forecasts. Both of these ensembles are generate model-of-model-predictions which we can compare to the predictions made by individual models.

Each ensemble model is constructed by evaluating the performance of different models in the past and creating a prediction for the current time step based on the retrospective cross-validation performance of component models (the ensemble members). For the random forest ensemble, we predicted the total returns by river system as a function of the predictions by river system and age group from each individual candidate model. A conventional ensemble might be constructed by taking an AIC weighted mean of forecasts of each of the candidate models for a particular river system. By constructing an explicit model-of-models ensemble a random forest, we allow the choice of model weighting to vary depending on the performance of different models in different river systems and time periods (Anderson et al. 2017b).

The FRI is a mixed-methods manually constructed ensemble model, which has used various methods throughout the years to arrive at pre-season forecasts for each river system based on the recent performance of different candidate models. The FRI forecast for a specific stock by age class combination was traditionally constructed by AIC-weighting across candidate linear sibling models. Candidate linear models predict returns of the target age class using returns of one or two younger age classes seen in prior years as predictors. These candidate predictive models were fit on two alternative time series, 1963 onward and 1980 onward, to account for broad-scale shifts in average Bristol Bay salmon population productivity following the shift in the Pacific Decadal Oscillation (PDO) in the late 1970's. Natural-scale and log-transformed transformations were both fit for all models. Since 2013 the FRI forecast ensemble has been constructed by comparing the performance of the traditional linear and log-linear AIC-weighted sibling models, random forest models, dynamic linear sibling models, boosted regression trees, and simple autoregressive integrated moving average (ARIMA) time series models, and selecting the model with the lowest residual error in predictions for the target stock-age group across the most recent 20-year time horizon.

The FRI ensemble forecast values were pulled from the historic pre-season forecasts as published. For the random forest ensemble, we follow a similar routine to that employed for the individual boosted regression tree model. We compiled the pre-season forecasts by river system and age group for each of the candidate models going back to 1991. The ensemble sought to predict the observed total returns by river system using the returns by river system and age class produced by each of the candidate models. For the years 2000 to 2019, we performed a series rolling model fits, where data before the testing year was held out for training (and analysis and assessment splitting and model tuning), and then used fit the ensemble model, which was then tested on the testing year. The held-out one-year-ahead predictions of the ensemble model in each time step were then compiled to create the historic series of ensemble forecasts at the river system level.

\hypertarget{results}{%
\section*{Results}\label{results}}
\addcontentsline{toc}{section}{Results}

\hypertarget{river-system-forecasts}{%
\subsection*{River System Forecasts}\label{river-system-forecasts}}
\addcontentsline{toc}{subsection}{River System Forecasts}

Management of Bristol Bay sockeye salmon operates at the river system level, and so forecasts at this resolution are critical for management and harvest planning. For each river system, we selected the model with the lowest SRMSE over the years 2000 to 2019 as the model of choice for that river system. On average the best-performing method reduced the SRMSE in pre-season run forecasts at the river system level by 16\%, with a minimum improvement of 6\% and a maximum of 28\%, relative to the performance of the historic published pre-season FRI forecasts. This represents a meaningful improvement in forecast skill for the management of Bristol Bay sockeye salmon.

River systems varied in both the lowest SRMSE achieved and in the model that produced the best performance. At least one model was able to out-perform or equal a simple lag\_1 benchmark model in each of the river systems, with the dlm model achieving a SRMSE of 0.67 at the top end in the Kvichak river system, and the rand\_forest model providing only marginal improvement over a lag\_1 model with a SRMSE of 0.98 in the Nushagak river system. Of all the candidate models explored, only the dlm, boost\_tree, and rand\_forest models were selected as the best performing candidate in at least one river system (Fig.\ref{fig:sys-forecast}).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/sys-forecast-1.pdf}
\caption{\label{fig:sys-forecast}Observed (grey ribbons) and predicted (points) numbers of returning sockeye salmon to primary sockeye-producing river systems in Bristol Bay, Alaska. The color of the points corresponds to the best performing model in terms of scaled root mean squared error (SRMSE), point transparency reflects the SRMSE of the best performing model, noted in the top left corner of each panel.}
\end{figure}

\hypertarget{age-group-forecasts}{%
\subsection*{Age Group Forecasts}\label{age-group-forecasts}}
\addcontentsline{toc}{subsection}{Age Group Forecasts}

The clearest outcome from our results at the river system level is that no one model performed better than all others, and river systems varied greatly in their predictability. Why is it that some models outperform others at the river system level? One explanation is that simply, given a set of roughly equally effective models and a short period of cross-validation (n = 19 years), we would expect different models to perform best in different river systems by chance alone in some cases. The mean difference in SRMSE between the best and second-best models by river system was only 0.07, demonstrating that several models are capable of outperforming a lag\_1 model with roughly equal skill in many cases.

Another explanation could relate to the age group makeup of runs in different river systems. While it is not intuitive as to why one model would perform better than another in a given river system all else being equal, we might expect different models to perform better for different age classes. The dynamic linear model is at its core still a sibling regression, and as such we would expect it to perform better on older age groups for which there is more reliable information on survival from returns of younger age classes. Conversely, while the machine learning and EDM models can use sibling returns, they are more flexible in determining which data are most useful for prediction. As such, predictions for younger age classes can be based more on environmental signals if called for by the data. The boosted regression tree model, which allows for environmental and interspecies effects on salmon returns, performed best for the youngest included age group (1.2 fish) (Fig.\ref{fig:age-forecast}). Turning back to the river systems, returns to Naknek, where boost\_tree performed best, have recently had large proportions of their runs made up of 1.2 fish (the group for which boost\_tree performed best) (Fig.\ref{fig:age-returns}). However, the Wood river system has also seen a massive increase in 1.2 fish, and no model was able to correctly capture the recent returns to that river system.

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/age-forecast-1.pdf}
\caption{\label{fig:age-forecast}Observed (grey ribbons) and predicted (points) numbers of sockeye salmon within each age group returning to Bristol Bay, Alaska. Age group refers to `years spent in freshwater'\_`years spent in ocean.' Color corresponds to the best performing model in terms of scaled root mean squared error (SRMSE), transparency reflects the SRMSE of the best performing model, noted in the top left corner of each panel.}
\end{figure}

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/age-returns-1.pdf}
\caption{\label{fig:age-returns}Observed sockeye salmon return abundance by age group (color) to major river systems in Bristol Bay (panels) over time.}
\end{figure}

\hypertarget{ensemble-forecasts}{%
\subsection*{Ensemble Forecasts}\label{ensemble-forecasts}}
\addcontentsline{toc}{subsection}{Ensemble Forecasts}

The result that some models outperform others under specific circumstances (e.g.~particular river systems or age classes) suggests a simple solution: pick the best model for the resolution of prediction required, or better yet create an ensemble model that can leverage the relative strengths of individual models into one improved forecast. We assessed the ability of ensemble models to outperform individual models here by selecting the top performing (in terms of SRMSE) ensemble model (either the FRI or the random forest model-of-models ensemble) for each of the main river systems, and compared the performance of the best-performing ensemble to the best-performing non-ensemble model in that river system. One of the two ensemble methods provide improved forecasts for three out of the seven river systems, relative to the best single non-ensemble model for that river system (Fig.\ref{fig:ensemble-forecast}). In five of the seven river systems the random forest ensemble produced the preferred ensemble, with the FRI forecasts being preferable of the two ensembles in the other two river systems). In many of the river systems however, one of the individual models performed better than the ensemble (Fig.\ref{fig:ensemble-forecast}). We attribute the inability of the the ensemble model to outperform individual models here to the small sample size on which to train the multi-model ensembles

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/ensemble-forecast-1.pdf}
\caption{\label{fig:ensemble-forecast}Performance of candidate ensemble models. Shape of points indicates which ensemble model had the lowest scaled root mean squared error (SRMSE). FRI refers to the published forecasts by the Fisheries Research Institute. The random forest ensemble is an ensemble model constructed by random forest made out of candidate model forecasts. The forecast from the best performing ensemble is plotted and denoted by point shape. Color of points shows the percent improvement of the best-performing ensemble over the best non-ensemble model. Blue colors indicate that the ensemble performed better than the best non-ensemble model, red colors that the best non-ensemble model performed better than the best ensemble model.}
\end{figure}

\hypertarget{frontiers-in-performance}{%
\subsection*{Frontiers in Performance}\label{frontiers-in-performance}}
\addcontentsline{toc}{subsection}{Frontiers in Performance}

The underlying assumption of such an ensemble strategy is that the information needed for an accurate forecast is present in the data, and the key is finding the model that is best able to identify and leverage that information. However, no model can find information that simply is not there, or succeed if it is based upon data that is subject to overwhelming observation error. Examining trends in the annual residuals by model and river system shows clear patterns. In some years and river systems, all models perform similarly well, indicating that the information needed for a good forecast was present and detectable by each of the models (e.g.~Nushagak before 2015). In other years, only particular models performed well, while others struggled, indicating that information needed for a robust forecast was present but only some models were able to accurately identify the underlying relationship, highlighting the value of ensemble methods (e.g.~Naknek between 2005 and 2010). However, in other years and river systems all models struggled, for example the Wood River in 2018 and the Kvichak River in 2014. This provides evidence that the information needed to generate a robust forecast in those years was simply not present in the data that were available at the time (Fig.\ref{fig:resids}).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/resids-1.pdf}
\caption{\label{fig:resids}Centered and scaled annual residuals (forecast returns minus observed returns) by river system and model over time. Grey bands indicate areas more than one standard deviation from the mean residuals for a given system. Years in which all the lines are within a grey band indicate periods where all the models struggled to provide reasonable forecasts.}
\end{figure}

Our residual analysis suggests that in some instances we simply need to collect different data for inclusion in the forecast model if we hope to improve forecasts. For example, none of our models were able to predict the massive spike in returns of the 1.2 age class to the Wood river system in recent years (Fig.\ref{fig:resids}), indicating that the process resulting in an increase in salmon survival was not among the suite of predictors explored. We can use the results of our most recent estimated boost\_tree model to examine the relative importance of different included data streams in forecast skill (Fig.\ref{fig:imp-plot}). While these importance scores cannot be interpreted in the same manner as regression coefficients, they give us a sense of where we might look for new data to inform prediction. Across all river systems, prior returns in that system were an important predictor (and in many systems past returns in other river systems were also a useful predictor).

\begin{figure}
\centering
\includegraphics{salmon-forecast-paper_files/figure-latex/imp-plot-1.pdf}
\caption{\label{fig:imp-plot}Mean variable importance across all river systems of variables with importance scores greater than 0.05.}
\end{figure}

\hypertarget{discussion}{%
\section*{Discussion}\label{discussion}}
\addcontentsline{toc}{section}{Discussion}

Modern computational tools can improve our ability to forecast annual Bristol Bay sockeye salmon returns, substantially in some cases. Individual models used here improved age group specific forecasts by an average of 14\% (measured as reduction in RMSE) and river system specific forecasts by 18\%. Ensembles of these individual models, both formal (random forest) and informal (FRI) in nature, allowed for further improvement in predictive performance for some salmon stocks. However, no one modeling method emerged as a clear winner. Using multiple types of highly flexible modern computational tools can provide insight into whether historic limits to forecast skill were likely due to limitations in the information content of the available data, or from simply not finding the best model to apply to the data at hand. While we were able to improve forecast skill of Bristol Bay sockeye salmon substantially in some instances, in other years and systems, all models performed poorly. Such widespread low predictive skill may result from not including a relevant data set that strongly affects salmon dynamics. However, this may be less likely given that there are specific years in which models perform poorly, followed by years with improved forecasts. It seems more likely that there are years with anomalous environmental relationships and system dynamics. In these situations assuming the future will be similar to the past may not be justified, and future studies might focus on modeling outlier events similar in the manner of Anderson et al. (2017a).

The annual return of sockeye salmon to the river systems of Bristol Bay Alaska is an economic and ecological marvel, providing critical nutrients and value to Alaska's ecosystems, economy, and people. Efficient and sustainable use of this critical natural and cultural resource depends in part on the ability to accurately forecast the number of salmon that will return each year, prior to the fishing season. As such, accurate and precise forecasts for future salmon abundance are vitally important to the biological and economic sustainability of this important fishery. Allowing environmental and cross-stock correlations to dynamically inform the predictions of sockeye salmon through modern predictive models produced meaningful improvements in our ability to forecast annual returns of these iconic fish.

That forecasts for individual river systems can be improved by treating historic returns in other river systems as predictors, as evidenced by the machine learning models is an important finding given that traditional salmon forecast methods that have largely focused on single river systems in isolation. While perhaps not surprising given the juvenile salmon from multiple river systems enter the same area of the eastern Bering Sea during approximately the same season and likely experience similar survival conditions at ocean entry, this result suggests that sharing age-specific return abundance information among salmon stocks and river systems within Bristol Bay can inform and improve predictive performance.

In addition to the return abundance of salmon from the home and neighboring river systems, we found that oceanographic variables including mean sea surface temperature and sea surface air pressure throughout the spatial and temporal range of the oceanic phase of these salmon were informative predictors for some river systems. In addition, as reported by Connors et al. (2020), in some instances the abundance of other salmon species (chum salmon, \emph{Oncorhynchus keta}, in western Kamchatka and northern British Columbia, pink salmon, \emph{Oncorhynchus gorbuscha}, in Prince William sound) proved important predictors of Bristol Bay salmon return abundance (Fig.\ref{fig:imp-plot}). Improved data on at-sea conditions and interspecies competitors may facilitate improved forecasts in the future.

Traditional forecast methods employed by the Fisheries Research Institute involved evaluation of a suite of alternative forecast models in each year, and selection of a preferred model and data time series on which to train the model (i.e.~1963 onwards or after the observed shift in the Pacific Decadal Oscillation in 1980), for each salmon stock by age class combination based on forecast bias and precision over the recent 20-year period. While the FRI forecast has always been primarily based on the relationship between the abundance of age classes from the same cohort among successive years, the suite of forecast models explored as part of the FRI forecast has evolved over time. In recent years new methods have been added to the forecast model suite including autoregressive integrated moving average (ARIMA) models, boosted regression trees, Bayesian indicator variable methods, and dynamic linear models. The manual model selection process at the heart of the FRI ensemble approach has proven effective over time at identifying candidate models for forecast groups (stock-by-age) that best leverage patterns within individual time series (i.e.~ARIMA, DLM), weighting candidate predictor age classes (i.e.~Bayesian indicator variable methods), and non-linear relationships between the return abundance of age classes for a stock in prior years (i.e.~boosted regression trees). However, despite the observed value in comparing performance of alternative forecast model types inherent in the traditional FRI forecasting approach, significant forecast errors have occurred. The range of models explored only leveraged data for sibling age classes of the same stock, and the potential for human error in the manual model selection process cannot be overlooked and present opportunity for improvement.

We demonstrate here how modern computationally intensive approaches can provide improvements in ecological forecasting. Ward et al. (2014) also explored the use of models similar to those used here in the context of ecological forecasting of time-series data from natural populations. They however found that the sorts of modern computational tools explored here generally performed worse than simple autoregressive models, while being substantially more computationally intensive. In contrast we found that our lag\_1 benchmark model was always outperformed or equaled by one or more of our models across every resolution we evaluated. What might explain this discrepancy? Ward et al. (2014) constrained themselves to making predictions of future population size solely based on historic population size, while the forecast methods we explore here were informed by the abundance of multiple salmon age classes or stocks, and in some cases by environmental conditions and the abundance of other salmon species. In this way, the methods evaluated by Ward et al. (2014) are most similar to the EDM models explored here, which provided the least improvement over our lagged benchmark models. We note however, that identification and inclusion of environmental relationships may improve EDM forecasts but was beyond the scope of this analysis.

We would only expect computer age methods to provide an improvement over simpler methods if there are substantial complexities in the relationship between past and future abundance that simpler models miss (i.e.~the simpler models are misspecified). The results of Ward et al. (2014) and the performance of the EDM models as used here (without environmental covariates or cross-stock predictions) relative to our benchmark models suggest simpler models may indeed be preferable when only historic timeseries of individual stocks are available as a data source, and additional informative predictors (such as environmental data or nearby related systems) are not available.

In contrast the DLM and machine learning methods both have access to additional information that may account for their ability to outperform simpler models. The DLM model, while still relying solely on historic return data of individual river systems, provides structure that autoregressive style models might miss. In particular, the DLM model leverages our ability to track cohorts over time and use these data as predictors in a model while explicitly accounting changes in average salmon population productivity, survival, and maturation schedule over time. The machine learning methods explored here have access to much more data than the historic returns alone, including environmental conditions and abundance of other salmonids. In addition, the machine learning methods used here are able to leverage correlations in returns across multiple age groups and river systems (Fig.\ref{fig:imp-plot}). While we have access to over 50 years of data, longer than some of the series reported in Ward et al. (2014), our sample sizes are still minute compared to the sample sizes in most applications of machine learning methods, indicating that these methods can still be used with the relatively small sample sizes often encountered in forecasting the population dynamics of harvested species. The results of Ward et al. (2014) suggest that more complex models may provide little benefit when the only data available are historic trends in the population being forecasted. We find though that modern computational forecasting tools can provide meaningful improvements when given additional covariates and/or structure.

\hypertarget{conclusions}{%
\section*{Conclusions}\label{conclusions}}
\addcontentsline{toc}{section}{Conclusions}

The field of ecology is generally concerned with developing theories and evidence for why ecosystems are structured and behave the ways they do. This pursuit of heuristic understanding can lead to construction of interpretable models that provide insight about system dynamics, but limited predictive power. We designed and optimized our models solely around predictive power, and while some methods such as empirical dynamic modeling and dynamic linear models can provide both insight and predictive skill, the machine learning methods tested here (boosted regression tree and random forests) are focused on prediction alone, with limited scope to improve ecological insight. In the case of natural resources management that often depends on making decisions today based on predictions about the future, prediction-focused methods such as those presented here can present substantial opportunity.

Accurate forecasts are a crucial part of natural resource management, a task made increasingly challenging by climate change. Our gains in forecast accuracy for the economically and ecologically critical Bristol Bay sockeye salmon fishery demonstrate the ability of modern computational tools to make meaningful improvements in short-term predictive ability for the abundance of natural populations faced with a rapidly changing environment. By combining multiple modern computational tools we are able to identify likely frontiers in forecast performance given currently available data. However, even for this relatively robust dataset we were fundamentally unable to predict the returns of particular river systems and age classes in certain years. The collective failure of multiple methods in specific time steps and locations helps clarify instances in which the only likely path to meaningful forecast improvement is collection of additional data, while also highlighting the potentially irreducible impact of observation error on the limits of forecast performance. It is critical that we allocate resources to both the advancement of predictive modeling methods in ecology, and to the hard work of collecting the data from the natural world that are the foundation of any successful forecasting efforts.

\hypertarget{acknowledgements}{%
\section*{Acknowledgements}\label{acknowledgements}}
\addcontentsline{toc}{section}{Acknowledgements}

Funding for this study was provided by the Bristol Bay Regional Seafood Development Association, by the Bristol Bay Seafood Processors, and by Douglas and Joyce McCallum.

\hypertarget{data-availability}{%
\section*{Data Availability}\label{data-availability}}
\addcontentsline{toc}{section}{Data Availability}

All data, code, and package dependencies needed to fully reproduce our results are publicly available at www.github.com/danovando/salmon-forecast-paper.

\hypertarget{literature-cited}{%
\section*{Literature Cited}\label{literature-cited}}
\addcontentsline{toc}{section}{Literature Cited}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-akaike1974}{}%
Akaike, H. 1974. A new look at the statistical model identification. IEEE Transactions on Automatic Control 19:716--723.

\leavevmode\hypertarget{ref-allaire2020a}{}%
Allaire, J., and F. Chollet. 2020. Keras: R interface to 'keras'.

\leavevmode\hypertarget{ref-allaire2020}{}%
Allaire, J., and Y. Tang. 2020. Tensorflow: R interface to 'TensorFlow'.

\leavevmode\hypertarget{ref-anderson2017c}{}%
Anderson, S. C., T. A. Branch, A. B. Cooper, and N. K. Dulvy. 2017a. Black-swan events in animal populations. Proceedings of the National Academy of Sciences 114:3252--3257.

\leavevmode\hypertarget{ref-anderson2017a}{}%
Anderson, S. C., A. B. Cooper, O. P. Jensen, C. Minto, J. T. Thorson, J. C. Walsh, J. Afflerbach, M. Dickey-Collas, K. M. Kleisner, C. Longo, G. C. Osio, D. Ovando, I. Mosqueira, A. A. Rosenberg, and E. R. Selig. 2017b. Improving estimates of population status and trend with superensemble models. Fish and Fisheries 18:732--741.

\leavevmode\hypertarget{ref-araujo2007}{}%
Ara'ujo, M. B., and M. New. 2007. Ensemble forecasting of species distributions. Trends in Ecology \& Evolution 22:42--47.

\leavevmode\hypertarget{ref-beyan2020}{}%
Beyan, C., and H. I. Browman. 2020. Setting the stage for the machine intelligence era in marine science. ICES Journal of Marine Science 77:1267--1273.

\leavevmode\hypertarget{ref-breiman2001}{}%
Breiman, L. 2001. Random {Forests}. Machine Learning 45:5--32.

\leavevmode\hypertarget{ref-breiman2001}{}%
Breiman, L. 2001. Random {Forests}. Machine Learning 45:5--32.

\leavevmode\hypertarget{ref-chang2017}{}%
Chang, C.-W., M. Ushio, and C. Hsieh. 2017. Empirical dynamic modeling for beginners. Ecological Research 32:785--796.

\leavevmode\hypertarget{ref-chen2020}{}%
Chen, T., T. He, M. Benesty, V. Khotilovich, Y. Tang, H. Cho, K. Chen, R. Mitchell, I. Cano, T. Zhou, M. Li, J. Xie, M. Lin, Y. Geng, and Y. Li. 2020. Xgboost: Extreme gradient boosting.

\leavevmode\hypertarget{ref-chen2020}{}%
Chen, T., T. He, M. Benesty, V. Khotilovich, Y. Tang, H. Cho, K. Chen, R. Mitchell, I. Cano, T. Zhou, M. Li, J. Xie, M. Lin, Y. Geng, and Y. Li. 2020. Xgboost: Extreme gradient boosting.

\leavevmode\hypertarget{ref-connors2020}{}%
Connors, B., M. J. Malick, G. T. Ruggerone, P. Rand, M. Adkison, J. R. Irvine, R. Campbell, and K. Gorman. 2020. Climate and competition influence sockeye salmon population dynamics across the {Northeast Pacific Ocean}. Canadian Journal of Fisheries and Aquatic Sciences.

\leavevmode\hypertarget{ref-cunningham2019}{}%
Cunningham, C. J., C. M. Anderson, J. Y.-L. Wang, M. Link, and R. Hilborn. 2019. A management strategy evaluation of the commercial sockeye salmon fishery in {Bristol Bay}, {Alaska}. Canadian Journal of Fisheries and Aquatic Sciences 76:1669--1683.

\leavevmode\hypertarget{ref-Dietterich2000}{}%
Dietterich, T. G. 2000. Ensemble {Methods} in {Machine Learning}. Pages 1--15 Multiple {Classifier Systems}. {Springer, Berlin, Heidelberg}.

\leavevmode\hypertarget{ref-efron2016}{}%
Efron, B., and T. Hastie. 2016. Computer age statistical inference: Algorithms, evidence, and data science. {Cambridge University Press}, {New York, NY}.

\leavevmode\hypertarget{ref-elith2008}{}%
Elith, J., J. R. Leathwick, and T. Hastie. 2008. A working guide to boosted regression trees. Journal of Animal Ecology 77:802--813.

\leavevmode\hypertarget{ref-holmes2012}{}%
Holmes, E. E., E. J. Ward, and K. Wills. 2012. MARSS: Multivariate autoregressive state-space models for analyzing time-series data. The R Journal 4:30.

\leavevmode\hypertarget{ref-holmes2020}{}%
Holmes, E., E. Ward, M. Scheuerell, and K. Wills. 2020. MARSS: Multivariate autoregressive state-space modeling.

\leavevmode\hypertarget{ref-hyndman2006}{}%
Hyndman, R. J., and A. B. Koehler. 2006. Another look at measures of forecast accuracy. International Journal of Forecasting 22:679--688.

\leavevmode\hypertarget{ref-knapp2013}{}%
Knapp, G., G. Mouhcine, and S. Goldsmith. 2013. The {Economic Importance} of {theBristol Bay Salmon Industry}. {Institute of Social and Economic Research}, {University of Alaska Anchorage}.

\leavevmode\hypertarget{ref-malde2020}{}%
Malde, K., N. O. Handegard, L. Eikvil, and A.-B. Salberg. 2020. Machine intelligence and the data-driven future of marine science. ICES Journal of Marine Science 77:1274--1285.

\leavevmode\hypertarget{ref-mcdowellgroup2018}{}%
McDowell Group. 2018. Bristol {Bay Sockeye Market Report}.

\leavevmode\hypertarget{ref-munch2020}{}%
Munch, S. B., A. Brias, G. Sugihara, and T. L. Rogers. 2020. Frequently asked questions about nonlinear dynamics and empirical dynamic modelling. ICES Journal of Marine Science 77:1463--1479.

\leavevmode\hypertarget{ref-naiman2002}{}%
Naiman, R. J., R. E. Bilby, D. E. Schindler, and J. M. Helfield. 2002. Pacific {Salmon}, {Nutrients}, and the {Dynamics} of {Freshwater} and {Riparian Ecosystems}. Ecosystems 5:399--417.

\leavevmode\hypertarget{ref-peters2014}{}%
Peters, D. P. C., K. M. Havstad, J. Cushing, C. Tweedie, O. Fuentes, and N. Villanueva-Rosales. 2014. Harnessing the power of big data: Infusing the scientific method with machine learning to transform ecology. Ecosphere 5:art67.

\leavevmode\hypertarget{ref-petris2009}{}%
Petris, G., S. Petrone, and P. Campagnoli. 2009. Dynamic linear models {With R}. {Springer}, {Dordrecht ; New York}.

\leavevmode\hypertarget{ref-pole1994}{}%
Pole, A., M. West, and J. Harrison. 1994. Applied {Bayesian} forecasting and time series analysis. {Chapman and Hall}, {New York}.

\leavevmode\hypertarget{ref-rcoreteam2020}{}%
R Core Team. 2020. R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria.

\leavevmode\hypertarget{ref-ruggerone2018}{}%
Ruggerone, G. T., and J. R. Irvine. 2018. Numbers and {Biomass} of {Natural}- and {Hatchery}-{Origin Pink Salmon}, {Chum Salmon}, and {Sockeye Salmon} in the {North Pacific Ocean}, 1925{}. Marine and Coastal Fisheries 10:152--168.

\leavevmode\hypertarget{ref-schindler2003}{}%
Schindler, D. E., M. D. Scheuerell, J. W. Moore, S. M. Gende, T. B. Francis, and W. J. Palen. 2003. Pacific salmon and the ecology of coastal ecosystems. Frontiers in Ecology and the Environment 1:31--37.

\leavevmode\hypertarget{ref-steiner2011}{}%
Steiner, E. M., K. R. Criddle, and M. D. Adkison. 2011. Balancing {Biological Sustainability} with the {Economic Needs} of {Alaska}'s {Sockeye Salmon Fisheries}. North American Journal of Fisheries Management 31:431--444.

\leavevmode\hypertarget{ref-sugihara1994}{}%
Sugihara, G., B. T. Grenfell, R. M. May, and H. Tong. 1994. Nonlinear forecasting for the classification of natural time series. Philosophical Transactions of the Royal Society of London. Series A: Physical and Engineering Sciences 348:477--495.

\leavevmode\hypertarget{ref-sugihara1990}{}%
Sugihara, G., and R. M. May. 1990. Nonlinear forecasting as a way of distinguishing chaos from measurement error in time series. Nature 344:734--741.

\leavevmode\hypertarget{ref-sugihara2012}{}%
Sugihara, G., R. May, H. Ye, C. Hsieh, E. Deyle, M. Fogarty, and S. Munch. 2012. Detecting {Causality} in {Complex Ecosystems}. Science 338:496--500.

\leavevmode\hypertarget{ref-takens1981}{}%
Takens, F. 1981. Detecting strange attractors in turbulence. Pages 366--381 \emph{in} D. Rand and L.-S. Young, editors. Dynamical {Systems} and {Turbulence}, {Warwick} 1980. {Springer}, {Berlin, Heidelberg}.

\leavevmode\hypertarget{ref-ward2014}{}%
Ward, E. J., E. E. Holmes, J. T. Thorson, and B. Collen. 2014. Complexity is costly: A meta-analysis of parametric and non-parametric methods for short-term population forecasting. Oikos 123:652--661.

\leavevmode\hypertarget{ref-wright2017}{}%
Wright, M. N., and A. Ziegler. 2017. Ranger: {A Fast Implementation} of {Random Forests} for {High Dimensional Data} in {C}++ and {R}. Journal of Statistical Software 77:1--17.

\leavevmode\hypertarget{ref-wright2017}{}%
Wright, M. N., and A. Ziegler. 2017. Ranger: {A Fast Implementation} of {Random Forests} for {High Dimensional Data} in {C}++ and {R}. Journal of Statistical Software 77:1--17.

\leavevmode\hypertarget{ref-ye2015}{}%
Ye, H., R. J. Beamish, S. M. Glaser, S. C. H. Grant, C. Hsieh, L. J. Richards, J. T. Schnute, and G. Sugihara. 2015. Equation-free mechanistic ecosystem forecasting using empirical dynamic modeling. Proceedings of the National Academy of Sciences 112:E1569--E1576.

\leavevmode\hypertarget{ref-ye2020}{}%
Ye, H., A. Clark, E. Deyle, and S. Munch. 2020. rEDM: Applications of empirical dynamic modeling from time series.

\end{CSLReferences}

\end{document}
