---
output: 
  bookdown::pdf_document2:
    keep_tex: true
  bookdown::word_document2:
    reference_docx: template.docx
bibliography: "../references.bib"
csl: canadian-journal-of-fisheries-and-aquatic-sciences.csl
params: 
  results_name: ["v1.0.1.9000"]
linkcolor: blue
toc: false
header-includes:
  # - \RequirePackage{totcount,xpatch}
  # - \usepackage{totcount}
  - \usepackage{setspace}\doublespacing
  - \usepackage{lineno}\linenumbers
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,  dev = "cairo_pdf", message = FALSE, warning = FALSE)
library(tidyverse)
library(patchwork)
library(cowplot)
library(magick)
library(hrbrthemes)
library(ggplot2)
library(Cairo)
library(extrafont)
library(here)
library(scales)
extrafont::loadfonts()

results_dir <- here("results", params$results_name)

pub_theme <-
  hrbrthemes::theme_ipsum(base_size = 10, axis_text_size = 8, axis_title_size = 12) +
  theme(
    panel.spacing = unit(0.5, "lines"),
    plot.margin = unit(rep(10, 4), units = "points")
  )

theme_set(pub_theme)


# load plots

load(file = file.path(results_dir, "plots.RData"))

load(file = file.path(results_dir, "performance.RData"))

load(file = file.path(results_dir, "forecasts.RData"))

 system_importance_table <-  read_rds(file.path(results_dir,"system_importance_table.rds"))


```

```{r models}

benchmarks <- system_performance %>% 
  filter(model == "fri" | model == "lag") %>% 
  select(model, system, rmse) %>% 
  pivot_wider(names_from = model, values_from = "rmse")

age_benchmarks <- age_performance %>% 
  filter(model == "fri" | model == "lag") %>% 
  select(model, age_group, rmse) %>% 
  pivot_wider(names_from = model, values_from = "rmse")


sys_performers <- system_performance %>% 
  filter(!model %in% c("fri"), !str_detect(model,"ensemble"), !str_detect(model,"lag")) %>% 
  group_by(system) %>% 
  filter(srmse == min(srmse))

ens_sys_perfomers <- system_performance %>% 
  filter(str_detect(model,"ensemble")) %>% 
  group_by(system) %>% 
  filter(srmse == min(srmse))


comp_ens_sys_improvement <- ens_sys_perfomers %>% 
  select(model, system, rmse) %>% 
  left_join(benchmarks, by = "system") %>% 
  ungroup() %>% 
  summarise(imp_on_fri = -mean(rmse / fri - 1),
            min_imp_on_fri = min(-(rmse / fri - 1)),
            max_imp_on_fri = max(-(rmse / fri - 1)),
            imp_on_lag =  -mean(rmse / lag - 1),
            n_improv = sum(rmse < fri),
            improv_amnt = -mean((rmse / fri - 1)[rmse < fri]),
            worse_amnt = -mean((rmse / fri - 1)[rmse > fri]))

comp_sys_improvement <- sys_performers %>% 
  select(model, system, rmse) %>% 
  left_join(benchmarks, by = "system") %>% 
  ungroup() %>% 
  summarise(imp_on_fri = -mean(rmse / fri - 1),
            min_imp_on_fri = min(-(rmse / fri - 1)),
            max_imp_on_fri = max(-(rmse / fri - 1)),
            imp_on_lag =  -mean(rmse / lag - 1))

tmp <- sys_performers %>% 
  select(model, system, rmse) %>% 
  left_join(benchmarks, by = "system") %>% 
  ungroup() %>% 
  mutate(imp_on_fri = -(rmse / fri - 1),
            min_imp_on_fri = (-(rmse / fri - 1)),
            max_imp_on_fri = (-(rmse / fri - 1)),
            imp_on_lag =  -(rmse / lag - 1))

age_performers <- age_performance %>% 
  filter(!model %in% c("fri", "boost_tree_ensemble")) %>% 
  group_by(age_group) %>% 
  filter(srmse == min(srmse))

tmp2 <- age_performers %>% 
  select(model, age_group, rmse) %>% 
  left_join(age_benchmarks, by = "age_group") %>% 
  ungroup() %>% 
  mutate(imp_on_fri = -(rmse / fri - 1),
            min_imp_on_fri = (-(rmse / fri - 1)),
            max_imp_on_fri = (-(rmse / fri - 1)),
            imp_on_lag =  -(rmse / lag - 1))

a = tmp %>%
  ggplot(aes(reorder(system, -imp_on_fri), imp_on_fri, fill = model)) +
  geom_hline(aes(yintercept = 0)) +
  geom_col(color = "black") +
  scale_y_percent(name = "% Improvement on FRI") +
  scale_x_discrete(name = '')+
  fishualize::scale_fill_fish_d(name = 'Best Model', option = "Trimma_lantana") + 
  theme(axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 14)) 

ggsave( "rep_fig_1.pdf",a, device = cairo_pdf, width = 6, height = 4)

b = tmp2 %>%
  mutate(age_group = str_replace_all(age_group,"_",".")) %>% 
  ggplot(aes(reorder(age_group, -imp_on_fri), imp_on_fri, fill = model)) +
  geom_hline(aes(yintercept = 0)) +
  geom_col(color = "black") +
  scale_y_percent(name = "% Improvement on FRI") +
  scale_x_discrete(name = '')+
  fishualize::scale_fill_fish_d(name = 'Best Model', option = "Trimma_lantana") + 
  theme(axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 14)) 

ggsave( "rep_fig_2.pdf",b, device = cairo_pdf, width = 6, height = 4)



d <- total_forecast %>%
  filter(model %in% c("boost_tree", "fri")) %>%
  group_by(year) %>%
  mutate(observed = mean(observed)) %>%
  pivot_wider(names_from = "model", values_from = "forecast") %>%
  ggplot() +
  geom_hline(aes(yintercept = 0)) +
  geom_area(aes(year, observed),fill = "lightgrey") +
  geom_point(aes(year, boost_tree, fill = "boost_tree"), shape = 21, size = 4,alpha = 0.9) +
  geom_point(aes(year, fri, fill = "UW-FRI"), shape = 21, size = 4,alpha =0.9) + 
  fishualize::scale_fill_fish_d(name = '', option = "Trimma_lantana") + 
  scale_y_continuous(name = "Total Returns") + 
  scale_x_continuous(name = 'Year') + 
    theme(axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 14)) 


ggsave( "rep_fig_3.pdf",d, device = cairo_pdf, width = 6, height = 4)

fri_system_mape <- system_forecast %>% 
  filter(model == "fri") %>%
  group_by(model) %>% 
  summarise(mape = yardstick::mape_vec(observed, forecast))

fri_age_mape <- age_forecast %>% 
  filter(model == "fri") %>%
  group_by(model, age_group) %>% 
  summarise(mape = yardstick::mape_vec(observed, forecast))

# system_forecast %>% 
#   ggplot(aes(observed, forecast)) + 
#   geom_point() + 
#   geom_abline(aes(slope = 1, intercept = 0)) +
#   facet_wrap(~model)


mean_srmse_delta <- system_performance %>% 
    filter(!model %in% c("fri", "boost_tree_ensemble")) %>% 
  group_by(system) %>% 
  mutate(rmse_rank = rank(rmse)) %>% 
  filter(rmse_rank <= 2) %>% 
  arrange(system) %>% 
  group_by(system) %>% 
  summarise(delta  = srmse[rmse_rank == 2] - srmse[rmse_rank == 1]) %>% 
  ungroup() %>% 
  summarise(mmd = mean(delta))

comp_sys_improvement <- sys_performers %>% 
  select(model, system, rmse) %>% 
  left_join(benchmarks, by = "system") %>% 
  ungroup() %>% 
  summarise(imp_on_fri = -mean(rmse / fri - 1),
            min_imp_on_fri = min(-(rmse / fri - 1)),
            max_imp_on_fri = max(-(rmse / fri - 1)),
            imp_on_lag =  -mean(rmse / lag - 1))


sys_improv <- system_performance %>% 
  select(model, system, srmse) %>% 
  pivot_wider(names_from = model, values_from = srmse) %>% 
  pivot_longer(-c(system, fri), names_to = "model", values_to = "srmse") %>% 
  group_by(system) %>% 
  filter(srmse == min(srmse)) %>% 
  ungroup() %>% 
  summarise(srmse_improv = mean((srmse - fri) / fri))

age_improv <- age_performance %>% 
  select(model, age_group, srmse) %>% 
  pivot_wider(names_from = model, values_from = srmse) %>% 
  pivot_longer(-c(age_group, fri), names_to = "model", values_to = "srmse") %>% 
  group_by(age_group) %>% 
  filter(srmse == min(srmse)) %>% 
  ungroup() %>% 
  summarise(srmse_improv = mean((srmse - fri) / fri))


```

<!-- Assemble the parts of the manuscript in this order: title page, abstract (or introduction) on a new page, key words, text, acknowledgments, literature cited, tables (one table per page), figure legends (on separate page preceding the first figure), figures (one figure per page; label each figure, i.e., Figure 1, Figure 2, etc.), and lastly any Appendices. Please note that if your manuscript is accepted, the appendices would only be published online. -->


<!-- Frame the lag-1 model as null hypothesis, steve munch, averages variance around every estimate has a lower prediction. ONe sentence thing saying that colinearity  -->

<!-- Make clearer that the lag 1 is to find which model works best individually, and then from there how do we make an ensemble. Statistical comparison of lag 1 vs practical performance  -->

<!-- Now let's focus in on the ensemble  -->

<!-- Add a recipe to the methods section for what's happening here -->

<!-- Add in comparison to FRI -->

<!-- Add in the usual caveats about overfitting our purpose is  -->

<!-- . At the same time there is a risk of overfitting, especially with the more modern methods, that is not addressed. What tools are available to extract insights of the fit from the more advanced method? You write some on that later in the paper, but perhaps hint on that already here?  -->


<!-- Data table? SI -->

<!-- Make clearer that the FRI has had a mix of models over that time period and that makes the comparison  -->

<!-- even then things fall on their face. the message isn't this is the best. make clearer that this isn't a horserace  -->

<!-- we've seen change in age structure, and point out that some of these models having done better at this.  -->

<!-- take a crack at the climate thing  -->


<!-- Modern computational tools such as dynamic linear modeling, machine learning and empirical dynamical modeling have fundamentally transformed many aspects of our society by providing previously impossible levels of predictive accuracy to tasks from digital advertising to weather forecasting. However, these methods are underutilized for predicting and managing natural resources and ecological systems. Forecasts of fish populations are an integral part of many management systems, and are often used by the fishing and processing sectors to make business plans. Almost all fish forecasts are currently based on population dynamics using estimates of birth rates and survival from recent years. Salmon are an ecological, cultural, and economic keystone of Alaska, and forecasts of salmon runs are used by fish processors to inform staffing and supply decisions, and even to determine whether to operate for the fishing fleets. These forecast are also used by harvesters to inform spatial effort allocation decisions and determine crew size. Although valuable, these predictions are challenging given the complex set of dynamic factors that affect numbers of returning salmon, from egg production to predation to the environmental drivers of salmon survival in marine and freshwater habitats. We utilize data from the salmon populations of Bristol Bay, Alaska, together with a suite of modern forecasting tools, to attempt to identify the frontiers in forecast accuracy possible given currently available data. By leveraging environmental data and correlations between distinct salmon populations, combinations of modern computational tools were able to reduce out-of-sample error by on average 12% for age-specific forecasts, and 19% for river-specific forecasts. Yet, there were some observations that were not accurately predicted by any method. Given the flexible nature and varying assumptions of our evaluated models, these isolated collective forecast failures help identify when forecast performance is limited by model specification versus the constraints imposed by the nature and quality of available data. Our results demonstrate the utility and limitations of modern computational tools for applied management of natural resources, even when confronted with the short time series and observation error common in ecological systems.  -->

<!-- signal to noise in model selection -->

\newpage

# Title Page {.unnumbered}

## Title   {.unnumbered}

Improving Forecasts of Sockeye Salmon (*Oncorhynchus nerka*) with Modern Computational Tools. 

## Author List {.unnumbered}

Daniel Ovando^a^\*, Curry Cunningham^b^,Peter Kuriyama^c^,Christopher Boatright^a^, Ray Hilborn ^a,d^

^a^ School of Aquatic and Fishery Sciences, University of Washington Box 355030 Seattle WA 98195

^b^College of Fisheries and Ocean Sciences University of Alaska Fairbanks 17101 Point Lena Loop Road Juneau, AK 99801

^c^NOAA Fisheries Southwest Fisheries Science Center 8901 La Jolla Shores Dr, La Jolla, CA 92037

^d^Center for Sustaining Seafood, University of Washington Box 355030 Seattle WA 98195

## Corresponding Author {.unnumbered}

\*Correspondence should be addressed to Daniel Ovando at [danovan\@uw.edu](mailto:danovan@uw.edu){.email}


\newpage

## Abstract {.unnumbered}

Accurate forecasts of sockeye salmon (*Oncorhynchus nerka*) in Bristol Bay, Alaska, play an important role in management and harvesting decisions for this culturally and ecologically vital species. We used a suite of modern computational tools to assess the frontiers in forecast accuracy of Bristol Bay sockeye salmon possible given currently-available data. In retrospective performance testing individual models were capable of reducing pre-season forecast error at the river system level by on average `r percent(comp_sys_improvement$imp_on_fri)` relative to a benchmark model. We utilized an ensemble modeling approach to produce pre-season forecasts based on historic performance of individual models. This ensemble model reduced river system level forecast error by `r percent(comp_ens_sys_improvement$improv_amnt)` on average in `r comp_ens_sys_improvement$n_improv` of the `r n_distinct(system_forecast$system)` evaluated river systems, though it increased forecast error by `r percent(-comp_ens_sys_improvement$worse_amnt)` on average in the remaining `r n_distinct(system_forecast$system) - comp_ens_sys_improvement$n_improv` systems. We found potential for modest improvements in forecast accuracy across a variety of scales. However all tested models failed to accurately predict certain periods in the abundance timeseries, indicating that further forecast improvements depend on novel data rather than more flexible models.

<!-- Our results demonstrate both the utility and limitations of modern computational tools for applied management of natural resources, even when confronted with the short time series and observation error common in ecological systems. -->

<!-- A persistent question is whether pre-season forecast accuracy is primarily limited by the information content of the available data, or the degree of misspecification of the models applied to the data.  -->

## Keywords {.unnumbered}

Alaska, Salmon,Machine learning,Empirical Dynamic Modeling, Dynamic Linear Models, Predictive Modeling, Ecological Forecasting

\newpage

<!-- ## Significance Statement {.unnumbered} -->

<!-- The sockeye salmon (*Oncorhynchus nerka*) populations of Bristol Bay, Alaska are economic and ecological marvels, playing key roles in the ecosystems of Alaska and supporting the largest commercial salmon fishery in the world. Pre-season forecasts of the annual returns of these fish are important to both managers and fishing fleets. Computational tools such as machine learning have transformed predictive fields from advertising to weather forecasting. However, these methods are underutilized for managing ecological systems. Using modern computational tools we were able to substantially increase the accuracy of pre-season forecasts for the Bristol Bay sockeye salmon fishery. Our results demonstrate the utility and limitations of modern computational tools for applied management of natural resources, even when confronted with the short time series and observation error common in ecological systems. -->

# Introduction {.unnumbered}

Animal populations exhibit complex dynamics driven by interactions with many aspects of their ecosystem. Predicting the outcomes of these dynamics is a critical task of natural resource management; Forecasts of future abundance are often used to set fisheries regulations, vessel operators may make decisions about alternative fisheries based on predicted abundance, and industries and communities use forecasts to inform long-term and short-term investment plans in staffing and production capacity. The past two decades have seen explosive progress in the ability of modern "computer age" [@efron2016] tools to improve prediction, revolutionizing fields such as financial modeling, weather forecasting, and medicine. However, these methods remain relatively unused in ecological forecasting, particularly in an applied setting [@peters2014]. We use the ecologically and economically critical sockeye salmon (*Oncorhynchus nerka*) populations of Bristol Bay, Alaska to demonstrate the use of modern computation tools in applied predictive modeling, and show how they can be used to identify frontiers in forecast accuracy given currently available data.

<!-- However, the methods used to make these ecological predictions are often decades old and generally do not go beyond forward projection from age-structured models. -->



The commercial salmon fishery in Bristol Bay, Alaska is the single largest sockeye salmon fishery in the world [@steiner2011]. The estimated wholesale value of the Bristol Bay commercial sockeye harvest was \$390 million USD in 2010, providing approximately one-sixth of the total value of all United States seafood exports [@knapp2013]. The value of the Bristol Bay fishery has continued to grow, reaching \$508 million in 2017 [@mcdowellgroup2018]. Salmon returning to Bristol Bay also provide vital food security for subsistence-dependent Alaskan communities, and are critical vectors of marine-derived nutrients that support vibrant freshwater habitats [@naiman2002; @schindler2003]. Sustainable management of the Bristol Bay salmon fishery depends in part on the accuracy of preseason forecasts for salmon abundance, which inform development and implementation of inseason harvest strategies and successful operation of subsistence and commercial fisheries. Preseason forecasts are also important for planning by the processing industry, as a basis for identifying the appropriate level of supplies, equipment, and personnel necessary to process the annual harvest. As such, the accuracy of salmon forecasts have a direct influence on the profitability and efficiency of the salmon industry as a whole.

The Fisheries Research Institute (FRI) at the University of Washington and the Alaska Department of Fish and Game (ADFG) have been providing preseason forecasts for the annual abundance of sockeye salmon returning to the major river systems and fishing districts of Bristol Bay since at least 1967 (Cunningham pers. comm.). While the exact statistical methods used for FRI and ADFG forecasts have evolved over time, throughout their history they have primarily been based on the relationship between the abundance of successive age classes of salmon returning in different years. While these traditional forecast methods have been useful in guiding decisions by fishers, processors, and managers alike, improvements in the accuracy and precision of preseason forecasts would represent a valuable advance.

Sockeye salmon are semelparous,  born in freshwater where they spend the first one or more years of their lives. Eventually, these fish migrate to the ocean, where they live the remainder of their lives until returning to their natal river systems to spawn and then die. Sockeye salmon exhibit life history variation in the number of years they spend in these freshwater and oceanic phases, representing distinct “age groups”. Following conventions in the salmon literature, we denote age groups here by the format “years spent in freshwater.years spent in the ocean.” For example, a fish in the 1.2 age group spent one winter post-hatching in freshwater and migrating to sea two years after it was spawned, and two winters in the ocean before returning to freshwater to spawn. The Bristol Bay sockeye salmon fishery is primarily made up of salmon from seven different river systems, each of which is managed as a separate stock (Fig.\@ref(fig:returns)).

```{r returns, fig.cap = "Annual total abundance of returning sockeye salmon (*Oncorhynchus nerka*) to Bristol Bay, Alaska (A), by river system (B), and by age group (C). Numbers in millions of salmon. Age group is formatted by ‘years spent in freshwater’.‘years spent in ocean’. Map adapted from @cunningham2019.", fig.width=7, fig.asp=.8}
return_plot
```

Why might we expect modern computational tools to be well-suited to the task of salmon forecasting? Methods such as machine learning excel at identifying and exploiting potentially complex correlations between variables in a system. Conversely, "traditional" parametric statistical methods often restrict themselves to simplified (e.g. linear) and often non-dynamic representations of natural systems, both for analytical tractability and to facilitate heuristic understanding of underlying processes. Typically, these parametric statistical methods are concerned with explicitly estimating and interpreting model parameters rather than solely forecasting responses, such as population size [@beyan2020; @malde2020]. We would expect modern computational tools to show substantial improvement in predictive power when the "true" underlying system linking observed variables and outcomes differs dramatically from the simplified representations of the system approximated by conventional statistical approaches. In the case of salmon, we know that inter-annual variation in run sizes is affected by a wide range of ecosystem variables, including spawning success, river conditions, oceanic predator and prey abundance, and competition with other salmonids [@connors2020]. By reducing the potential for predictive model misspecification, modern computation tools that essentially seek to “learn” the best model structure for the sole purpose of maximizing out-of-sample predictive performance can provide a test of the predictive information content of the available data themselves.

Rather than incorporate factors such as environmental drivers directly, salmon forecasting has traditionally relied on cohort or “sibling” regression methods, in which the return abundance of an older age class is predicted by the abundance of younger age classes, returning in prior years but originating from the same river system and brood year. For example, the return abundance of four-year old fish are predicted by the returns of three-year old fish observed in the previous season. There are good reasons for this practice: trends in sibling abundance integrate across many environmental factors affecting salmon survival and returns. If a particular cohort suffers from poor environmental conditions, increased competition with conspecifics,  or a greater abundance of predators, the demographic impacts of these changes will be reflected in the return abundance of younger age classes from the same cohort (i.e. originating from the same brood year) that experienced similar environmental conditions or resource availability, and by extension survival, as juveniles. However, the sibling regression method does have shortcomings, most notably the underlying assumption of consistency in the relationship between the abundance of different age classes and stability in the maturation schedule (i.e. the probability of salmon maturing and returning to freshwater to spawn after a given number of years in the ocean). For example, if environmental conditions cause members of a cohort of salmon to spend more time at sea than in previous years, a sibling regression might under-predict the number of future returns. In addition, sibling regression requires accurate observations of the return abundance for younger sibling age classes, limiting the performance of these models in predicting returns of younger salmon for which few or no siblings (i.e. returning younger age classes) have yet been observed.

We hypothesize that directly incorporating data on candidate potentially time-varying factors influencing and correlated with salmon return size, rather than relying on sibling returns alone, may help improve forecast performance given the intricate dynamics of salmon populations. However, these variables are likely to have complex, non-linear, and non-stationary effects on salmon populations, potentially obscuring their value from conventional parametric statistical approaches, with user-defined parameters, structures, and error distributions. In order to explore this possibility, we used a suite of six methods together with a panel of data on salmon populations and environmental conditions in Bristol Bay, Alaska to explore what if any improvements in forecast skill could be achieved. These models included two machine learning methods, a random forest (rand\_forest), [@breiman2001; @wright2017] and a boosted regression tree, boost\_tree, [@chen2020], empirical dynamic models (edm) [@sugihara1990; @munch2020; @ye2020], and dynamic linear models (dlm)[ @petris2009; @pole1994]. We also included a lag-1 model, as a performance benchmark, in which the predicted returns for a given age group and river system in a year are equal to the observed returns for that that age group in that river system in the prior year. Our goal here was not to establish whether one type of model performs inherently better than others, but to evaluate how use of different computer age models and data types can collectively improve forecast ability and identify frontiers in forecast ability given available data. We also evaluated the performance of a model ensemble which weights predictions from individual ensemble members (alternative predictive model types) based on recent performance, and compare this with observed performance from the Fisheries Research Institute (FRI) forecast, a benchmark forecast that utilizes a qualitative ensemble approach based on evaluation of recent performance for alternative models within the ensemble. 



# Materials and methods {.unnumbered}

All code and data needed to fully replicate our results are publicly available at <https://github.com/DanOvando/salmon-forecast-paper/>. We describe critical details of each our main methods here. 

The general structure of our methods are as follows: 

1. Individual models for each river system and age group were fit to historical data 

2. Retrospective performance of individual model was assessed using 1-step ahead predictions (e.g. model fit to data through 1999 and used to predict return abundance in 2000) over the period 2000-2019 

3. Comparison of performance from individual models types against a benchmark  “lag-1” prediction model in which the forecast for next year is simply the observed returns in the previous year

3. Individual models were aggregated into a statistical ensemble model based on their historic performance against the lag-1 benchmark

4. The statistical ensemble model was then compared to a more qualitatively constructed ensemble model, in which researchers manually select individual models from an evolving suite of methods based on recent (20-year) performance. This is the method historically used to generate Bristol Bay salmon forecasts, although the individual prediction models within the selection suite have changed over time. As such this method provides a *status quo* benchmark to which individual models and statistical ensembles may be compared. 


## Machine Learning Models {.unnumbered}

We evaluated two different machine learning models: a random forest (rand\_forest, implemented through the `ranger` package [@wright2017] in R [@rcoreteam2020]), and boosted regression trees, boost\_tree, through the `xgboost` package [@chen2020]. A recurrent neural network implemented through `tensorflow` [@allaire2020] through the `keras` interface [@allaire2020a] was also tested but was found to perform poorly relative to the other methods and to be extremely computationally intensive, and as such was not included in the main analysis. Random forests are ensembles of regression trees, which make predictions by selecting nested splits of variables and mapping the mean level of the dependent variable at the terminal nodes of each tree. Boosted regression trees are similar to random forests, but have mechanisms in place that actively update the model to address data points that the model is struggling to fit [@elith2008]. For all machine learning methods, within a model fit the model selects splits/transformations/coefficients to minimize the root mean squared error (RMSE) of predictions for data withheld from the fitting process by the algorithm.

Each of the machine learning methods had access to a variety of population and environmental data. We fit versions of each model separately for each age group in each major river system. Environmental datasets were queried from the NOAA ERDDAP portal using the rerddap package in R [@chamberlain2019]. Included environmental variables include sea surface temperature, sea level pressure, wind stress, and the Pacific Decadal Oscillation index. For each environmental variable, we use mean or median values within the Bristol Bay region across the months of May to August during the year in which the cohort being forecasted entered the ocean. We also included as candidate covariates natural origin returns of pink (*Oncorhynchus gorbuscha*) and chum (*Oncorhynchus keta*) across a range of North Pacific stocks, pulled from @ruggerone2018 (Table.\@ref(tab:dat)). 

When fitting models at the level of age groups by river system, data were first split into training and testing sets. We then split each of the training sets for performance testing (e.g. all data before the year 2000 if the year 2001 is to be forecasted) into a series of analysis and assessment splits for tuning purposes. Given the timeseries nature of the data, we generated these analysis and assessment splits in a rolling manner: for the first split, we used the first 70% of the training year to fit a model, and the remaining 30% to evaluate the performance of that model, followed by the first 75% and 25%, etc. These analysis and assessment splits were used to tune nuisance parameters common to all machine learning models, for example the minimum node size of fitted trees. We fit each of our assessment splits across a grid of potential parameter values, and selected the set of tuning parameters that minimized the RMSE of the predictions on the assessment splits (see computational environment available at <https://github.com/DanOvando/salmon-forecast-paper/> for detailed steps in this process).

Once the optimal set of tuning parameters for each training set were selected, we then fit the final model using all the training data with those tuned parameters, and used that model to predict the returns in the testing set. All relevant data transformations were prepared only on training / analysis splits (e.g. means and standard deviations for centering and scaling) and then applied to testing / assessment splits.


```{r dat, results="asis"}

tmp <-  system_importance_table %>% ungroup() %>% select(name, Description, Source) %>% rename(Name = name) %>% unique() %>% filter(
    !Name %in% c("Return Year", "Spawner Numbers"),
    !str_detect(Name, "Past")
  ) %>% arrange(Name) %>% 
  filter(!str_detect(Name,":")) %>% 
  as.data.frame()

salmonind_stuff <- tribble(~Name, ~Description, ~Source,
                           "Pink and chum abundance","Natural origin returns of pink and chum salmon",
                           "Ruggerone and Irvine (2018)")

tmp <- tmp %>% 
  bind_rows(salmonind_stuff)

knitr::kable(tmp,
             digits = 2,
             caption = "Environmental and salmonid datasets available to machine learning models.",
             booktabs = TRUE,
             format = "latex") %>%
  kableExtra::kable_styling(full_width = TRUE)


```






## Dynamic Linear Models {.unnumbered}

To date methods for forecasting sockeye salmon abundance in Bristol Bay and throughout Alaska, have relied on the relationship between the abundance of different age classes from the same cohort, or originating from the same brood year, but returning to breed in subsequent years at different ocean ages. These “sibling” or cohort regression models leverage the fact that salmon spawned in the same brood year and migrating to sea in the same year exhibit similar patterns in survival, based upon their shared exposure to the same physical environmental conditions, prey resource availability, and predator field, as juveniles and at ocean entry. As such, if members of a cohort returning after 2 years in the ocean are observed in higher-than-average abundance, then we may also expect above-average abundance of their 3-ocean “siblings” (other members of the cohort) to return the next year. 

Foundational to the predictability of sibling relationships is the assumption that the ratio of returns by age class remains stable across time. In a context of a linear model, for example, we can model returns as $\hat{R^{1.3}_t} = \alpha + \beta{R^{1.2}_{t-1}}$ where $\hat{R^{1.3}_t}$ is the predicted return abundance of the older (1.3) age class and $R^{1.2}_{t-1}$ is the observed abundance of the same cohort returning in the prior year after one fewer years in the ocean (i.e. age group 1.2). Under a classic sibling regression the assumption is that the estimated parameters $\alpha$ and $\beta$ remain constant across time. However, there are multiple conditions under which both the average return abundance of a particular age class or the ratio of abundances among age classes might change over time. For example, if the average maturation schedule (i.e. the probability that an individual will mature after 2 vs. 3 years in the ocean) changes in response to natural or anthropogenic selection, the assumption of a stationary parameter is violated. Alternatively, if average marine mortality experienced by salmon changes as a result of large-scale climate, ecosystem, or trophic shifts, this should be reflected by changes in both parameters of the regression model.

To better represent the dynamic nature of sibling or cohort relationships over time and improve predictive performance, we implement dynamic linear models (DLMs). DLMs are a class of regression models where the values of regression coefficients are permitted to evolve over time, rather than remain static [@petris2009; @pole1994]. DLMs were fit to available data using a single predictor age class (one fewer year in the ocean, returning the prior year), and allowing for evolution of both the slope and intercept parameters over time, as:

$$\hat{R^{1.3}_t} = \alpha_t + \beta_t{R^{1.2}_{t-1}} + \epsilon_t$$

Both regression parameters are described by a random walk (i.e. $\alpha_t \sim Normal(\alpha_{t-1},\sigma^2_{\alpha})$ and $\beta_t \sim Normal(\beta_{t-1},\sigma^2_{\beta})$), and errors were assumed normally-distributed ($\epsilon_t \sim Normal(0,\sigma^2_{\epsilon})$). DLMs were implemented using the Multivariate Autoregressive State-Space Modelling (MARSS) package (version 3.10.12) in R [@holmes2012; @holmes2020]. The full timeseries (brood year 1963 forward) of age and river system specific abundances reconstructed by @cunningham2019  were for model fitting. For example, to predict the abundance of the 1.2 age class returning to the Wood River system in 2010, the DLM model was fit to available data 1963-2009, with the 1.1 age class in prior years assumed a priori to be most informative the predictor sibling 

## Empirical Dynamic Modeling {.unnumbered}

Empirical dynamic modeling (EDM) is a nonparametric approach to characterize ecological dynamics and generate forecasts. The approach is predicated on Takens' theorem, which states that a single time series and a number of lags (dimension; E) are representative of overall system dynamics [@sugihara1990; @takens1981]. Applications of EDM have identified causal relationships in ecological systems [@sugihara2012] and improved forecast skill in Fraser River sockeye salmon [@ye2015]. See @munch2020 and @chang2017 for more general overviews of EDM. We used the software package rEDM [@park2020] for analysis.


We focused on multiview embedding [@ye2016] to predict Bristol Bay sockeye returns. We predicted out-of-sample river and age-class-specific returns for 2000-2019. The idea behind multiview embedding is that there are potentially many valid reconstructions of system dynamics, and evaluating possible different combinations may improve performance. The top Multiview embedding was identified with river-specific data with a maximum E=2. Multiview embedding selects models based on the within-sample fits. So to predict say Kvichak 2.2 returns in the year 2000, we subset data through 1999 for Kvicahk 1.2, 1.3, 2.3, and 2.2, then selected the multiview embedding that had the highest within-sample predictive skill. We evaluated embeddings with maximum dimensions up to E=4, although this increase did not consistently result in improved within-sample predictive skill, perhaps due to noise in the data. 

We present results from multiview embedding but we also evaluated additional EDM approaches. These included multivariate simplex, multivariate sequentially locally weighted global linear maps (s-map), and composite libraries for prediction to the salmon return data. These methods require identifying the dimensionality (E) of a time series and constructing an attractor (a time series and its E-lagged coordinates). Leave-one-out prediction identifies the best E of a time series. We used E values ranging from 1 to 10, found the E-nearest neighbors (based on Euclidean distance) from the observation of interest, and calculated a predicted value by averaging the E-nearest neighbors. The best E had the highest correlation between observed and predicted values. S-maps is an extension of simplex that has the addition of a weighting parameter (theta) which modifies the strength of nearest neighbor weighting (theta=0 weights nearest neighbors equally; theta>0 stronger weighting of nearest neighbors) [@sugihara1994]. 

## Performance Metrics {.unnumbered}

We do not conduct formal statistical tests of model fit or performance. Parameters of conventional statistical models might be assessed in terms of statistical significance, and models compared via some form of information criterion. However, neither the machine learning or the empirical dynamic modeling methods have formal estimates of uncertainty or likelihoods, and as such do not produce measures of statistical significance around individual forecasts, and cannot be compared using information criteria such as AIC [@akaike1974] scores. Accordingly, we judge model performance by the point estimates of SRMSE produced by each model across the retrospective horizon 1990-2019. SRMSE measures the performance of each model relative to a lag-1 model, a conventional benchmark model for timeseries modeling [@hyndman2006;@ward2014]

RMSE is calculated as

$$RMSE_m = \sqrt{\frac{1}{I}\sum\limits_{i = 1}^I(y_{i} - f_{i,m})^2}$$

where *i* represents an observation of numbers of returning salmon *y* and the forecast for those numbers *f* by a given model *m*. In the manner of mean absolute scaled error (MASE, [@hyndman2006]), we scale each models RMSE for a given resolution by the RMSE of a lag-1 model for the same resolution (for example at the river system level).

$$RMSE_{l1} = \sqrt{\frac{1}{I}\sum\limits_{i = 1}^I(y_{i} - y_{i,l1})^2}$$

and SRMSE for model *m* is then

$$SRMSE_m = \frac{RMSE_m}{RMSE_{l1}}$$

MASE is commonly used to judge the accuracy of predictions derived from time series models, since it compares the error of a given model to the error expected by a simple model in which the predictions in a given time step are equal to the observed values in the last time step (a lag-1 model). We use SRMSE instead of MASE to reflect the use of the forecast. MASE considers an error of ten to be twice as bad as an error of five. In the context of salmon forecasting, our primary objective is to avoid massively over or under estimating the pre-season forecast. SRMSE penalizes large errors more than small errors, helping select models that avoid the kinds of large errors that are most problematic for the task of managing salmon populations.

A SRMSE of one means that a model has predictive performance equal to that of the lag-1 model. A SRMSE greater than one indicates that a given model performs worse than the lag-1 benchmark, a SRMSE less than one that a model performs better than the lag-1 benchmark [@hyndman2006]. 

<!-- Forecasts for a given year are produced by a model trained on data from all preceding years. This type of sliding-window cross-validation permitted the most realistic evaluation of retrospective model performance. -->

## Testing Regime {.unnumbered}

All models were compared based upon one-step-ahead forecast skill, defined by SRMSE. Each of the evaluated models generate forecasts at the resolution of age group and river system in a given year. Forecasts for a given year are produced by a model trained on all years after 1963 and prior to the year for which a forecast is desired. This is performed in a rolling fashion, such that for example forecasts for the year 2018 are produced by a model trained on data from 1963 to 2017, the 2019 forecast by a model trained on data from 1963 to 2018, and so on. One-step-ahead performance skill was preferred over simple leave-one-out cross validation because it better aligns with the context of preseason forecasting (i.e. data in hand through the current year are used to predict the next), and should be expected to more appropriately reflect true forecast uncertainty in the presence of periodic regime shifts in salmon production and the potential for unmodeled autocorrelation. Each method has its own ways of tuning and validating the model, but all such steps are performed using only the training data: all data for the forecast year are held out until the final prediction.

Predictive performance of candidate models was calculated by generating 1-year ahead forecasts for each target river system by age class combination, as a rolling window from the year 2000 to 2019. This method for quantifying forecast performance is most applicable to the context of this ecological forecasting problem as each candidate model is trained on data up to, but not including, the prediction year. Even though each model predicts at the resolution of age group and river system, we generally compare model performance at coarser resolutions (for example river system across all age groups). In those cases, we first aggregate the total returns at the resolution in question (e.g. sum all observed and forecast returns across all age groups for a given river system), and then calculate SRMSE based on those aggregated data.


## Ensemble Models {.unnumbered}

The chosen testing regime allowed us to compare the retrospective predictive power, defined by SRMSE, of individual models at a variety of spatial resolutions. However, scientists must make a decision each year as to which models to use for particular forecasts, and there is no guarantee that past model performance will predict future model performance. A substantial body of literature suggests that creating "ensemble" models that weigh individual models to create a single composite prediction can outperform any one individual model  [@anderson2017a; @araujo2007; @Dietterich2000]. To assess the ability of this idea to assist in annual model selection and weighting we compared two different ensemble models: a purely statistical ensemble constructed by a random forest, and a mixed-methods ensemble model published as the Fisheries Research Institute (FRI) forecasts. 

<!-- Both of these ensembles generate model-of-model-predictions which we can compare to the predictions made by individual models.  -->

The random forest ensemble model was updated each year by evaluating the performance of different models in the past and creating a prediction for the current time step based on the performance of component models (the ensemble members) in the prior time steps. For the random forest ensemble, we predicted the total returns by river system as a function of the predictions by river system and age group from each individual candidate model type. A conventional ensemble might be constructed by taking an AIC weighted mean of forecasts of each of the candidate models for a particular river system. By constructing an explicit "model-of-models" ensemble through a random forest, we allow the choice of model weighting to vary depending on the performance of different models in different river systems and time periods [@anderson2017a].

The FRI forecast is a mixed-methods manually constructed ensemble model, which has used various methods throughout the years to arrive at pre-season forecasts for each river system based on the recent performance of different candidate models. The FRI forecast for a specific stock by age class combination was traditionally constructed by AIC-weighting across candidate linear sibling models. Candidate linear models predict returns of the target age class using returns of one or two younger age classes seen in prior years as predictors. These candidate predictive models were fit on two alternative time series, 1963 onward and 1980 onward, to account for broad-scale shifts in average Bristol Bay salmon population productivity following the shift in the Pacific Decadal Oscillation (PDO) in the late 1970's. Natural-scale and log-transformed transformations were both fit for all models. Since 2013 the FRI forecast ensemble has been constructed by comparing the performance of the linear and log-linear AIC-weighted sibling models, random forest models, dynamic linear sibling models, boosted regression trees, and simple autoregressive integrated moving average (ARIMA) time series models, and selecting the model with the lowest residual error in predictions for the target stock-age group across the most recent 20-year time horizon.

The FRI forecast is a mixed-methods manually constructed ensemble model, which has used various methods throughout the years to arrive at pre-season forecasts for each river system based on the recent performance of different candidate models. The FRI forecast for a specific river by age  class combination was traditionally constructed by AIC-weighting across candidate linear sibling regression models. Candidate linear models predict returns of the target age class using returns of one or two younger age classes seen in prior years as predictors, but unlike the DLM model explored here, assume regression coefficients are time-invariant. These candidate predictive models were fit on two alternative time series, 1963 onward and 1980 onward, to account for broad-scale shifts in average Bristol Bay salmon population productivity following the shift in the Pacific Decadal Oscillation (PDO) in the late 1970’s. Natural-scale and log-transformed transformations were both fit for all models. Since 2013 the FRI forecast ensemble has been constructed by comparing the performance of the linear and log-linear AIC-weighted sibling models, random forest models, dynamic linear sibling models, boosted regression trees, and simple autoregressive integrated moving average (ARIMA) time series models, and selecting the model with the lowest residual error in predictions for the target stock-age group across the most recent 20-year time horizon. All models in the historical FRI ensemble used only data from within a single river system, but across multiple age classes, to generate predictions (i.e. age-specific timeseries of Nushagak River returns were never used to forecast Wood River returns despite their spatial proximity).

The FRI ensemble forecast values were pulled from the historic pre-season forecasts as published. For the random forest ensemble, we follow a similar routine to that employed for the individual (i.e. river- and age-specific) boosted regression tree model. We compiled the pre-season forecasts by river system and age group for each of the candidate models going back to 1991. The ensemble sought to predict the observed total returns by river system using the returns by river system and age class produced by each of the candidate models (BRT, RF, DLM, EDM). For the years 2000 to 2019, we performed a series of rolling model fits, where individual forecasts and observed returns before the testing year was held out for training (and analysis and assessment splitting and model tuning), and then used fit the ensemble model, which was then evaluated on the testing year. The held-out one-year-ahead predictions of the ensemble model in each time step were then compiled to create the historic series of ensemble forecasts at the river system level.


# Results {.unnumbered}



<!-- XX Need a brief table of each of the methods describing them and their acronyms in the intro or start of the results XX -->

## Individual Model Forecasts {.unnumbered}


### River System Forecasts {.unnumbered}

Management of Bristol Bay sockeye salmon operates at the river system level, with inseason fishery managers regulating allowable fishing effort on a daily basis to meet annual escapement goals for each river [@cunningham2019;@fried1988]. For each river system, we selected the individual model with the lowest SRMSE over the years 2000 to 2019 as the model of choice for that river system. On average the best-performing method reduced the SRMSE in pre-season run forecasts at the river system level by `r percent(comp_sys_improvement$imp_on_fri)`, with a minimum improvement of `r percent(comp_sys_improvement$min_imp_on_fri)` and a maximum of `r percent(comp_sys_improvement$max_imp_on_fri)`, relative to the performance of the historic published pre-season FRI forecasts. 

River systems varied in both the lowest SRMSE achieved and in the model that produced the best performance. At least one model was able to out-perform or equal a simple lag-1 benchmark model in each of the river systems except for the Nushagak, with the `r  sys_performers$model[sys_performers$srmse == min(sys_performers$srmse)]` model achieving a SRMSE of `r prettyNum(min(sys_performers$srmse), digits = 2)` at the top end in the `r sys_performers$system[sys_performers$srmse == min(sys_performers$srmse)]` river system, and the `r sys_performers$model[sys_performers$srmse == max(sys_performers$srmse)]` model providing only marginal improvement over a lag-1 model with a SRMSE of `r prettyNum(max(sys_performers$srmse), digits = 2)` in the `r sys_performers$system[sys_performers$srmse == max(sys_performers$srmse)]` river system. The dlm, boost\_tree, and rand\_forest models were selected as the best performing candidate in at least one river system (Fig.\@ref(fig:sys-forecast)).

```{r sys-forecast, fig.cap="Observed (grey ribbons) and predicted (points) numbers of returning sockeye salmon to primary sockeye-producing river systems in Bristol Bay, Alaska. The color of the points corresponds to the best performing model in terms of scaled root mean squared error (SRMSE), point transparency reflects the SRMSE of the best performing model, noted in the top left corner of each panel."}
system_forecast_figure

```

### Age Group Forecasts {.unnumbered}

While total river system returns are the primary metric of interest to the Bristol Bay sockeye fishery, the age composition of the returns are also important given their influence of the average size and therefore price for each salmon harvested, and options for processed product forms.  As such we also examined the ability of our tested models to generate predictions at the age group level. In retrospect different models performed best for each of the four age groups considered, and at least one model was able to improve substantially on a lag-1 model in all age groups (Fig.\@ref(fig:age-forecast)). 

```{r age-forecast, fig.cap="Observed (grey ribbons) and predicted (points) numbers of sockeye salmon within each age group returning to Bristol Bay, Alaska. Age group refers to 'years spent in freshwater'_'years spent in ocean'. Color corresponds to the best performing model in terms of scaled root mean squared error (SRMSE), transparency reflects the SRMSE of the best performing model, noted in the top left corner of each panel."}
age_forecast_figure
```

```{r age-returns, fig.cap = "Observed sockeye salmon return abundance by age group (color) to major river systems in Bristol Bay (panels) over time.", eval=FALSE, include=FALSE}

age_system_return_plot
```

## Ensemble Forecasts {.unnumbered}


<!-- The result that some models outperform others under specific circumstances (e.g. particular river systems or age classes) suggests a simple solution: pick the best model for the resolution of prediction required, or better yet create an ensemble model that can leverage the relative strengths of individual models into one improved forecast.  -->


In theory the individual models tested here were capable of improving pre-season forecast accuracy over the years 2000-2019 when viewed retrospectively. However, scientists must make annual decisions as to which models to use and how to weigh their predictions. To approximate this process we selected the top performing (in terms of SRMSE) rolling ensemble model (either the FRI or the random forest model-of-models ensemble) for each of the main river systems. In `r comp_ens_sys_improvement$n_improv` of the `r n_distinct(system_forecast$system)` evaluated river systems the random forest ensemble produced the preferred ensemble, improving on the FRI forecast by on average `r percent(comp_ens_sys_improvement$improv_amnt)` ,  with the FRI forecasts being preferable of the two ensembles in the remaining `r n_distinct(system_forecast$system) - comp_ens_sys_improvement$n_improv`  river systems, outperforming the random forest ensemble by `r percent(-comp_ens_sys_improvement$worse_amnt)` . 


```{r ensemble-forecast, fig.cap="Performance of candidate ensemble models. Shape of points indicates which ensemble model had the lowest scaled root mean squared error (SRMSE). FRI refers to the published forecasts by the Fisheries Research Institute. The random forest ensemble is an ensemble model constructed by random forest made out of candidate model forecasts. The forecast from the best performing ensemble is plotted and denoted by point shape. Color of points shows the percent improvement of the ensemble model relative to the published FRI forecast."}
system_ensemble_forecast_figure
```

## Frontiers in Performance  {.unnumbered}

The underlying assumption of such an ensemble strategy is that the information needed for an accurate forecast is present in the data, and the key is finding the combination of individual models that are best able to identify and leverage that information. However, no model can find information that simply is not present, or succeed if it is based upon data that is subject to overwhelming observation or process error.  Examining trends in the annual residuals by model and river system shows clear patterns. In some years and river systems, all models perform similarly well, indicating that the information needed for a good forecast was present and detectable by each of the models (e.g. Nushagak before 2015). In other years, only particular models performed well, while others struggled, indicating that information needed for a robust forecast was present but only some models were able to accurately identify the underlying relationship, highlighting the value of ensemble methods (e.g. Naknek between 2005 and 2010). However, in other years and river systems all models struggled, for example the Wood River in 2018 and the Kvichak River in 2014. This provides evidence that the information needed to generate a robust forecast in those years was simply not present in the data that were available at the time (Fig.\@ref(fig:resids)).

```{r resids, fig.cap="Centered and scaled annual residuals (forecast returns minus observed returns) by river system and model over time. Grey bands indicate areas more than one standard deviation from the mean residuals for a given system. Years in which all the lines are within a grey band indicate periods where all the models struggled to provide reasonable forecasts."}
yearly_system_resid_struggles_figure
```

Our residual analysis suggests that in some instances we simply may need to collect different data for inclusion in the forecast model if we hope to improve forecasts. For example, none of our models were able to predict the massive spike in returns of the 1.2 age class to the Wood river system in recent years (Fig.\@ref(fig:resids)), indicating that a signal of the process resulting in an increase in salmon survival was not among the suite of predictors explored. We can use the results of our most recent estimated boost\_tree model to examine the relative importance of different included data streams in improving forecast skill (Fig.\@ref(fig:imp-plot)). While these importance scores cannot be interpreted in the same manner as regression coefficients, they give us a sense of where we might look for new data to inform prediction. Across all river systems, prior returns in that system were an important predictor (and in many systems past returns in other river systems were also a useful predictor).

```{r imp-plot, eval = TRUE, fig.cap="Mean variable importance across all river systems of variables with importance scores greater than 0.075."}
system_varimportance_figure
```

<!-- Which variables were most important in our forecasts? XX not sure if /how this can be done for the other models, or if it’s worth it XX. Maybe just do variable importance plots by age group for the tree based methods -->

<!-- * Performance in total returns forecast -->

<!-- * Break down by combinations of age class / system -->

<!-- * Variable importance where available -->

<!-- * Synthesize top performs for different objectives  -->

<!-- * Result of simple ensemble -->

<!-- * Result of models predicting boom / bust years  -->

# Discussion {.unnumbered}

While our tested methods made meaningful improvements in forecast accuracy in many cases, no one model type stood out as a clear winner, highlighting the need for multi-model inference in ecological forecasting.


Viewed in retrospect individual models tested here were able to make substantial improvements in forecast accuracy (Fig.\@ref(fig:sys-forecast)-\@ref(fig:age-forecast)). However, the best retrospective model over the years 2000-2019 varied widely by age group and system, presenting a challenge for decision makers charged with picking which model to use for a particular forecast. Ensemble models such as the random forest ensemble (i.e. a "model-of-models") constructed here can help users separate out the signal from the noise in historic model performance, which in this case resulted in modest improvements in forecast still in the majority of river systems evaluated in this study. 

<!-- The clearest outcome from our results at the river system level is that retrospectively no one model performed better than all others, and river systems varied greatly in their predictability. Why is it that some models outperform others at the river system level? One explanation is that simply, given a set of roughly equally effective models and a short period of cross-validation (n = 19 years), we would expect different models to perform best in different river systems by chance alone in some cases. The mean difference in SRMSE between the best and second-best models by river system was only `r prettyNum(mean_srmse_delta$mmd, digits = 1)`, demonstrating that several models are capable of outperforming a lag-1 model with roughly equal skill in many cases. -->

<!-- Another explanation could relate to the age group makeup of runs in different river systems. While it is not intuitive as to why one model would perform better than another in a given river system all else being equal, we might expect different models to perform better for different age classes. The dynamic linear model is at its core still a sibling regression, and as such we would expect it to perform better on older age groups for which there is more reliable information on survival from returns of younger age classes. Conversely, while the machine learning and EDM models can use sibling returns, they are more flexible in determining which data are most useful for prediction. As such, predictions for younger age classes can be based more on environmental signals if called for by the data. The boosted regression tree model, which allows for environmental and interspecies effects on salmon returns, performed best for the youngest included age group (1.2 fish) (Fig.\@ref(fig:age-forecast)). Turning back to the river systems, returns to Naknek, where boost\_tree performed best, have recently had large proportions of their runs made up of 1.2 fish (the group for which boost\_tree performed best) (Fig.\@ref(fig:age-returns)). However, the Wood river system has also seen a massive increase in 1.2 fish, and no model was able to correctly capture the recent returns to that river system. -->


Using multiple types of highly flexible modern computational tools can provide insight into whether historic limits to forecast skill were likely due to limitations in the information content of the available data, or from simply not finding the best model to apply to the data at hand. While we were able to improve forecast skill of Bristol Bay sockeye salmon in some instances, in particular years and systems all tested models performed poorly. These events may reflect changes in the effect of currently observed data, i.e. a violation of the assumption that the past correlation between a variable and salmon returns will apply in the future, or may be indicative of an effect of the underling effect of an unobserved variable. The former case may be resolved by simply giving the model more years on which to train, or through explicit techniques for modeling outlier events in the manner of @anderson2017c. The later case can only be resolved through the inclusion of new data that contains information on the previously omitted process. 

<!-- annual return of sockeye salmon to the river systems of Bristol Bay Alaska is an economic and ecological marvel, providing critical nutrients and value to Alaska's ecosystems, economy, and people. Efficient and sustainable use of this critical natural and cultural resource depends in part on the ability to accurately forecast the number of salmon that will return each year, prior to the fishing season. As such, accurate and precise forecasts for future salmon abundance are vitally important to the biological and economic sustainability of this important fishery. Allowing environmental and cross-stock correlations to dynamically inform the predictions of sockeye salmon through modern predictive models produced meaningful improvements in our ability to forecast annual returns of these iconic fish. -->

That forecasts for individual river systems can be improved by treating historic returns in other river systems as predictors, as evidenced by the machine learning models is an important finding. The historically used parametric salmon forecast methods have largely focused on relationships among age classes within single river systems in isolation. While perhaps not surprising given the juvenile salmon from multiple river systems enter the same area of the eastern Bering Sea during approximately the same season and likely experience similar survival conditions at ocean entry, this result suggests that sharing age-specific return abundance information among salmon stocks and river systems within Bristol Bay can inform and improve predictive performance.

In addition to the return abundance of salmon from the home and neighboring river systems, we found that oceanographic variables including mean sea surface temperature and sea surface air pressure throughout the spatial and temporal range of the oceanic phase of these salmon were informative predictors for some river systems. In addition, as reported by @connors2020, in some instances the abundance of other salmon species (chum salmon, *Oncorhynchus keta*, in western Kamchatka and northern British Columbia, pink salmon, *Oncorhynchus gorbuscha*, in Prince William sound) proved important predictors of Bristol Bay salmon return abundance (Fig.\@ref(fig:imp-plot)). Improved data on at-sea conditions and interspecies competitors may facilitate improved forecasts in the future.

Traditional preseason forecast methods for sockeye salmon returning to Bristol Bay and throughout Alaska have often assumed that relationships among age classes are static over time. However, there is increasing recognition of time-varying relationships between Alaskan salmon production and sea surface temperature [@litzow2018], and large-scale oceanographic processes including the Pacific Decadal Oscillation [@litzow2020;@litzow2020a]. Given evidence for the dynamic nature of salmon-climate relationships, it should not be surprising that salmon abundance forecast relationships should also exhibit temporal variability. While not informed by environmental data and only leveraging information from a single river system, the DLM approach was found to exhibit superior performance in several river systems and the 2.2 age class. It seems reasonable that the flexible nature of the DLM approach to capture time-varying dynamics in both average abundance and the ratio among age classes permits an indirect accounting for the dynamic salmon-environment processes that are increasingly recognized. 

Forecast methods historically employed by the Fisheries Research Institute involved evaluation of a suite of alternative forecast models in each year, and selection of a preferred model and data time series on which to train the model (i.e. 1963 onward or after the observed shift in the Pacific Decadal Oscillation in 1980), for each salmon stock by age class combination based on forecast bias and precision over the recent 20-year period. While the FRI forecast has always been primarily based on the relationship between the abundance of age classes from the same cohort among successive years, the suite of forecast models explored as part of the FRI forecast has evolved over time. In recent years new methods have been added to the forecast model suite including autoregressive integrated moving average (ARIMA) models, boosted regression trees, Bayesian indicator variable methods, and dynamic linear models. The manual model selection process at the heart of the FRI ensemble approach has proven effective over time at identifying candidate models for forecast groups (stock-by-age) that best leverage patterns within individual time series (i.e. ARIMA, DLM), weighting candidate predictor age classes (i.e. Bayesian indicator variable methods), and non-linear relationships between the return abundance of age classes for a stock in prior years (i.e. boosted regression trees). However, despite the observed value in comparing performance of alternative forecast model types inherent in the FRI forecasting approach, significant forecast errors have occurred. The range of models explored only leveraged data for sibling age classes of the same stock, and the potential for human error in the manual model selection process cannot be overlooked and present opportunity for improvement with automated ensemble approaches such as the Random Forest ensemble explored here.

We demonstrate here how modern computational modeling tools approaches can provide improvements in ecological forecasting. @ward2014 also explored the use of models similar to those used here in the context of ecological forecasting of time-series data from natural populations. They however found that the sorts of modern computational tools explored here generally performed worse than simple autoregressive models, while being substantially more computationally intensive. In contrast we found that our lag-1 benchmark model was always outperformed or equaled by one or more of our models across every resolution we evaluated. What might explain this difference? @ward2014 specifically designed their study around making predictions of future population size solely based on historic population size, while the forecast methods we explore here were informed by the abundance of multiple salmon age classes or stocks, and in some cases by environmental conditions and the abundance of other salmon species. 

<!-- In this way, the methods evaluated by @ward2014 are most similar to the EDM models explored here, which provided the least improvement over our lagged benchmark models. We note however, that identification and inclusion of environmental relationships may improve EDM forecasts but was beyond the scope of this analysis. -->

We would only expect the types of models employed here to provide an improvement over simpler methods if there are substantial complexities in the relationship between past and future abundance that simpler models miss (i.e. the simpler models are misspecified). The results of @ward2014 suggest simpler models may indeed be preferable when only historic timeseries of individual stocks are available as a data source, and additional informative predictors (such as environmental data or nearby related systems) are not available. Similarly, application of computer age methods are often data intensive, and our current application is for the Bristol Bay sockeye salmon system which stands as an outlier in terms of both the quality and duration (1963) of data available on which to base predictions. More limited time series of reconstructed return abundance are often available in other regions and for other salmon species. It is possible that when constrained to forecasting salmon abundance for stocks with limited numbers of annual observations for training, testing and tuning, simpler models may indeed provide more robust prediction.

<!-- In contrast the DLM and machine learning methods both have access to additional information that may account for their ability to outperform simpler models. The DLM model, while still relying solely on historic return data of individual river systems, provides structure that autoregressive style models might miss. In particular, the DLM model leverages our ability to track cohorts over time and use these data as predictors in a model while explicitly accounting changes in average salmon population productivity, survival, and maturation schedule over time.  -->

The machine learning methods explored here have access to much more data than the historic returns alone though, including environmental conditions and abundance of other salmonids. In addition, the machine learning methods used here are able to leverage correlations in returns across multiple age groups and river systems (Fig.\@ref(fig:imp-plot)). While we have access to over 50 years of data, longer than some of the series reported in @ward2014, our sample sizes are still minute compared to the sample sizes in most applications of machine learning methods, indicating that these methods can still be used with the relatively small sample sizes often encountered in forecasting the population dynamics of harvested species. The results of @ward2014 suggest that more complex models may provide little benefit when the only data available are historic trends in the population being forecasted. We find though that modern computational forecasting tools can provide meaningful improvements when given additional covariates and/or structure.

<!-- What other data should we suggest? We don’t include any in-river condition data, do we just not have it? Thoughts on other places we can invest? [g] -->

# Conclusion  {.unnumbered}

The field of ecology is generally concerned with developing theories and evidence for why ecosystems are structured and behave the ways they do. This pursuit of heuristic understanding can lead to construction of interpretable models that provide insight about system dynamics, but limited predictive power. However, for specific application in areas such as preseason salmon abundance forecasts the objective is solely to obtain accurate and precise predictions, one year into the future. We designed and optimized our models solely around predictive power, and while some methods such as empirical dynamic modeling and dynamic linear models can provide both insight and predictive skill, the machine learning methods tested here (boosted regression tree and random forests) are focused on prediction alone, with limited scope to improve ecological insight. In the case of natural resources management that often depends on making decisions today based on predictions about the future, prediction-focused methods such as those presented here can present substantial opportunity. Here we show that incorporating multiple predictive models into a statistical ensemble was able to provide some meaningful improvements in the pre-season forecast accuracy of Bristol Bay sockeye salmon. 

<!-- In particular, leveraging multiple different modeling approaches can help uncover otherwise hidden information in available data. As we demonstrate here though, we cannot simply rely on computer age statistical methods to automatically solve problems of prediction in ecology. Even when groups of statistical methods are unable to provide accurate forecasts, using multiple computer age methods as presented here can help identify when these prediction failures are likely due to model misspecification, and when they are do to a simple lack of sufficiently informative data. Computer-age statistical methods then can both improve forecasts and help identify frontiers in predictability in ecological systems given currently available data. Once these borders are found, we can focus efforts and resources on collecting new data that can push our predictive models to greater heights.  -->

<!-- Given the flexible nature and varying assumptions of our evaluated models, these isolated collective forecast failures help identify when forecast performance is limited by model specification versus the constraints imposed by the nature and quality of available data. Our results demonstrate the utility and limitations of modern computational tools for applied management of natural resources, even when confronted with the short time series and observation error common in ecological systems. -->

Accurate forecasts are a crucial part of natural resource management, a task made increasingly challenging by climate change. Our gains in forecast accuracy for the economically and ecologically critical Bristol Bay sockeye salmon fishery demonstrate the ability of modern computational tools to make meaningful improvements in short-term predictive ability for the abundance of natural populations faced with a rapidly changing environment. By combining multiple modern computational tools we are able to identify likely frontiers in forecast performance given currently available data. However, even for this relatively robust dataset we were fundamentally unable to predict the returns of particular river systems and age classes in certain years. The collective failure of multiple methods in specific time steps and locations helps clarify instances in which the only likely path to meaningful forecast improvement is collection of additional data, while also highlighting the potentially irreducible impact of observation error on the limits of forecast performance. It is critical that we allocate resources to both the advancement of predictive modeling methods in ecology, and to the hard work of collecting the data from the natural world that are the foundation of any successful forecasting efforts.


# Author contribution statement {.unnumbered}

D.O., C.C., and P.K. conducted the analyses. All authors contributed to the development of the manuscript.

# Funding statement {.unnumbered}

Funding for this study was provided by the Bristol Bay Regional Seafood Development Association, by the Bristol Bay Seafood Processors, and by Douglas and Joyce McCallum.

# Data availability statement {.unnumbered}

All data, code, and package dependencies needed to fully reproduce our results are publicly available at www.github.com/danovando/salmon-forecast-paper.

<!-- # Competing Interests -->

<!-- R.H's research program receives funding from environmental NGOs, foundations, fishing industry, governments and international agencies. All of these can be interpreted as a conflict of interest when evaluating fisheries policy. -->

<!-- # Materials & Correspondence. -->

<!-- Materials can be accessed at www.github.com/danovando/salmon-forecast-paper -->

# References {.unnumbered}

::: {#refs}
:::

