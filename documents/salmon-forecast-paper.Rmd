---
title: "Identifying Frontiers in Ecological Forecasting with Computer-Age Statistical Methods"
author:
  - Daniel Ovando
  - Curry Cunningham
  - Peter Kuriyama
  - Chris Boatright
  - Ray Hilborn
date: "`r Sys.Date()`"
output: 
  bookdown::pdf_document2: default
  bookdown::word_document2: default
bibliography: "../references.bib"
csl: nature.csl
params: 
  results_name: ["v0.5.2"]
abstract: |
  Salmon are an ecological and economic keystone of Alaska, providing XX buzzy economic and ecological stats XX. Effective management of these species depends on accurate pre-season forecasts, allowing fishery regulations to be set appropriately and fishing operations to plan their economic activities accordingly.  These predictions are challenging to make though, given the complex set of dynamic factors that affect numbers of returning salmon, from egg production to predation to environmental drivers. Computer-age statistical methods such as Bayesian inference through Hamiltonian Monte Carlo ,  machine learning and empirical dynamical modeling have fundamentally transformed many aspects of our society by providing previously impossible levels of predictive accuracy to tasks from digital advertising to weather forecasting. However, these methods have not been used for practical prediction in population dynamics. We utilize data the ecologically and economically-important salmon populations of Bristol Bay,  Alaska to evaluate the potential for computer-age statistical methods to improve the accuracy of predictions of annual returns. Salmon present an ideal case study due to the presence of long and accurate time series of annual returns, and the ecological and economical  importance of reliable predictions to commercial fisheries and subsistence-dependent communities. We find that machine-learning methods are able to provide some improvements in predictive performance, particularly for younger age classes of salmon, but that these improvements are marginal, and that “conventional” methods perform as well or better in many circumstances. Computer-age methods can help researchers and managers identify when the bottleneck is model design and when more data are needed, but may not be a panacea for improving predictive performance when confronted with time series of short duration, as are often found in analysis of population dynamics and ecological forecasting applications at annual time steps for aquatic and terrestrial species.  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,  dev = "cairo_pdf", message = FALSE, warning = FALSE)
library(tidyverse)
library(patchwork)
library(cowplot)
library(magick)
library(hrbrthemes)
library(ggplot2)
library(Cairo)
library(extrafont)
library(here)
extrafont::loadfonts()

results_dir <- here("results", params$results_name)

pub_theme <-
  hrbrthemes::theme_ipsum(base_size = 12, axis_text_size = 12, axis_title_size = 14) +
  theme(
    panel.spacing = unit(1, "lines"),
    plot.margin = unit(rep(10, 4), units = "points")
  )

theme_set(pub_theme)


# load plots

load(file = file.path(results_dir, "plots.RData"))


```

Summary: Rather than looking for one silver-bullet model, using multiple computer-age statistical models allows for improved forecasting and also highlights situations where you simply need more data. AND SALMON ARE COOL

Target Journal: Scientific Reports/ Ecological Applications / CJFAS / Nature Communications
Abstract: 150 words
Words: If we want to keep our options open let’s keep it under 5,000 words (Nature Communications is unclear whether that is 5,000 + 3000 max for methods, or whether methods section of can’t be more than 3000 of 5000)
Figures: 10
*idea for title from this book https://web.stanford.edu/~hastie/CASI/, since in theory we’re not just exploring machine learning if we’re including EDM, but can discuss if we like it this term or not

Nature Communications: Introduction, Results, Discussion, Methods


* Definitely some similarities with the Ward, Holmes, Thorson, and Collen (2014) paper: Complexity is costly: a meta-analysis of parametric and non-parametric methods for short-term population forecasting. Theirs was squarely focussed on time series models.

Rather than looking for one silver-bullet model, using multiple computer-age statistical models allows for improved forecasting and also highlights situations where you simply need more data. 
# Introduction (1500 words)

Animal populations exhibit complex dynamics driven by interactions with a myriad of aspects of their ecosystem. Predicting the outcomes of these dynamics is a critical task of natural resource management. The past two decades have seen explosive progress in the ability of “computer age” statistical methods to make accurate predictions [@efron2016], revolutionizing fields such as financial modeling, weather forecasting, and medicine [refine this list with concrete examples]. However, these methods remain relatively unused in ecological forecasting, particularly in an applied setting [@peters2014]. We use the ecologically and economically vital sockeye salmon populations of Bristol Bay, Alaska, to demonstrate both the potential and limitations of computer age statistical methods in ecological forecasting, by directly comparing the realized predictive performance of a wide range of applicable statistical forecasting tools. 


The commercial salmon fishery in Bristol Bay, Alaska is the single largest sockeye salmon (*Oncorhynchus nerka*) fishery in the world [@steiner2011], with an estimated wholesale value of the Bristol Bay commercial sockeye harvest was $390 million USD in 2010 and representing approximately one-sixth of the total value of all US seafood exports [@knapp2013]. Salmon returning to Bristol Bay also provide vital food security for subsistence-dependent Alaskan communities, and critical vectors of marine-derived nutrients that support vibrant freshwater habitats [@naiman2002; @schindler2003]. Sustainable management of the Bristol Bay salmon fishery is dependent upon accuracy of preseason forecasts for salmon abundance, which inform development and implementation of inseason harvest strategies and successful prosecution of subsistence and commercial fisheries. Preseason forecasts are also important for preseason planning by the processing industry as a basis for identifying the appropriate level of supplies, equipment, and personnel necessary to process the annual harvest, and directly influence the profitability and efficiency of the salmon industry as a whole. 


```{r returns, fig.cap = "Annual total (A), by river system (B), and by age group (C) returns of sockeye salmon (*Oncorhynchus nerka*) to Bristol Bay, Alaska. Age group is formatted by 'years spent in freshwater'_'years spent in ocean'. Map adapted from @cunningham2019", fig.width=7, fig.asp=.8}
return_plot
```
  
Why might we expect computer-age methods to be well-suited to the task of salmon forecasting? Methods such as machine learning excel at identifying and exploiting complex interactions between variables in a system. Typically, this is done to estimate model parameters rather than directly forecast population size [@beyan2020; @malde2020]. Conversely, “traditional” statistical methods often restrict themselves to simplified linear and often non-dynamic representations of natural systems, both for analytical tractability and to facilitate understanding of underlying processes. In this context, we would expect computer-age methods to show substantial improvement in predictive power then when the true underlying system linking observed variables and outcomes differs dramatically from more simplified representations of the system. In the case of salmon, we know that run sizes are affected by a wide range of ecosystem variables, including spawning success, river conditions, oceanic predator and prey abundance, and competition with other salmonids [@connors2020]. 


Rather than incorporate these factors directly, salmon forecasting has traditionally relied on cohort or “sibling” regression methods, in which returns of for example four year old fish are predicted by the returns of three year old fish observed in the previous season. There are good reasons for this practice: trends in sibling abundance clearly internalize many factors affecting salmon returns: if a particular cohort suffers from poor environmental conditions and large amount of competition with other predators, the impacts of that will be reflected in the return abundance of younger age classes from the same cohort (i.e. originating from the same brood year) that experienced similar environmental conditions and resource availability, and by extension survival, as juveniles. However, this method does have shortcomings, most notably the underlying assumption of consistency in the relationship between the abundance of age classes and stability in the maturation schedule (i.e. the probability of salmon maturing and returning to freshwater to spawn after a given number of years in the ocean). For example, if environmental conditions cause members of a cohort of salmon to spend more time at sea than in previous years, a sibling regression might under predict the number of future returns. In addition, sibling regression requires accurate observations of the return abundance for younger sibling age classes,  limiting the ability of these models to perform as well in predicting returns of younger salmon for which few or no siblings have been observed. To illustrate, mean absolute percent error (MAPE) of pre-season forecasts in Bristol Bay for age XX salmon have been XX, while for the youngest substantially commercially observed age class 1_2 the MAPE was XX. 

We hypothesize that directly incorporating data on potential influencers of salmon return size, rather than relying on sibling returns alone, might help improve forecasting under these conditions. However, these variables are likely to have complex, non-linear, and non-stationary effects on  salmon populations,  potentially obscuring their value from conventional statistical approaches and manually designed models. In order to explore this possibility, we use a suite of computer-age statistical methods together with a panel of data on salmon populations and environmental conditions in Bristol Bay, Alaska to explore what if any improvements in forecast skill can be achieved. We find that while these methods can make meaningful improvements in some cases, no one model stands out as a clear winner, highlighting the need for multi-model inference in ecological forecasting. Beyond improving predictions, multi-model inference can separate bottlenecks in forecast skill are due to model performance or data limitations. 


<!-- Introduction notes -->
<!-- First synthetic review of multiple methods and ensembles for this kind of popdy processes. Answering question of is it data or is it models.  -->


<!-- Ensemble models often presented as a solution to improved forecasting. But, we show here they also serve a secondary and overlooked purpose: separting out poor predictive performance as a function of model misspecification vs. data availability -->


<!-- The strength of these is not really in like doing a better job with univarite time series analysis  its in being able to exploit relationships between multiple datasources that are all biological linked. Broaden the net. Absence of other data, a lag is just fine, as opposed to kind of just throwing the kitchen sink of variables without some kind of subject expertise. Bridgin gap between kitchen sink and just traditional approach. Fruitful middle  -->


<!-- Point out that ICES special issues dedicated to ML in marine science, with not one article looking at the popdy question specifically  -->


<!-- Central tension to highlight: researchers are faced with uncertainty of whether predictive skill is driven by model mispecification or lack of data. This approach can help, focus in on Peter’s point about years places when all models fail as indicator  -->


# Results (1500 words)


We judge the performance of all of our models by mean absolute scaled error (MASE @hyndman2006)

Consider data from times $t=1,...,n$. Forecast error is $e_t=Y_t-F_t$ where $Y_t$ is the observation at time $t$ and $F_t$ is the forecast at time $t$. 


Scaled error is defined as: 
$$q_t=\frac{e_t}{\frac{1}{n-1}\sum\limits_{i=2}^{n}{|Y_i-Y_{i-1}|}}$$

and Mean Absolute Scaled Error (MASE) is 

$$MASE=mean(\mid{q_t}\mid)$$. 

MASE is commonly used to judge the accuracy of predictions derived from time series models, since it compares the error of a given model to the error expected by a simple model in which the predictions in a given time step are equal to the observed values in the last time step (an lag1 model).  A MASE of 1 means that a model exhibits predictive performance equal to that of a lag-1 model. A MASE greater than one indicates that a given model performs worse than the lag-1 benchmark, a MASE less than one that a model performs better than the lag-1 benchmark [@hyndman2006]. Forecasts in a given year are produced by a model trained on data on all preceding years.

<!-- XX Need a brief table of each of the methods describing them and their acronyms in the intro or start of the results XX -->

```{r models}

```

Management of Bristol Bay sockeye salmon is organized at the river-system level. As such forecasts at this resolution are critical for setting management and harvest plans. Historically, across all river systems the MASE of total returns was XX. For each river system, we selected the model with the lowest MASE over the years 2000 to 2019 as the model of choice for that system. The average MASE across all systems was XX, with the lowest value of XX in the XX river system, and the highest of XX in the XX system (Fig.2). Relative to the historic published forecasts, the methods tested here were able to improve MASE by XX% on average. 
  

```{r sys-forecast, fig.cap="Observed (grey ribbons) and predicted (colored points) returns of sockeye salmon to top seven systems by total sockeye salmon returns in Bristol Bay, Alaska. Color corresponds to the best performing model in terms of mean absolute scaled error (MASE), transparency reflects the MASE of the best performing model."}
system_forecast_figure

```

While we are able to produce improvements in forecast skill using these methods, no one method stands out as a clear winner across all systems.  Why would it be that some models would outperform others at the river system level? One explanation is that simply, given a set of roughly equally effective models, and a small sample size per system (n = 19 years),  we might expect different models to perform best in different systems by chance alone. The mean difference in MASE between the best and second best models by system was XX, suggesting that indeed several models are capable of outperforming a lag_1 model with roughly equal skill. 


Another explanation could be the age makeup of runs at different rivers. While it is not intuitive as to why one model would perform better than another in a given river system all else being equal, we might expect different models to perform better for different age classes. The dynamic linear model is at its core still a sibling regression, and as such we would expect it to perform better on older age groups. Conversely, while the machine learning and EDM models can use sibling returns, they are more flexible in determining which data are most useful for prediction. As such, predictions for younger age classes can be based more on environmental signals if called for by the data. 


Indeed, we find that two of our machine learning methods that allow for environmental and interspecies covaraites, boosted regression trees and  random forests, performed  best for the youngest included age group (boosted regression tree for 1_2 fish)  and the younger fish that spend an additional year at sea (1_3, random forest)[b] (Fig.3). Turning back to the systems, returns to both Egegik and Naknek, where boost_tree performed best, have recently had large proportions of their runs made up of 1_2 fish (the group that boost_tree performed best on). Similarly, the random_forest was our best performed for 1_3 fish, and performed best in Nushagak and Ugashik which recently have been dominated by 1_3 fish (Fig.4). 



```{r age-forecast, fig.cap="Observed (grey ribbons) and predicted (colored points) returns of sockeye salmon within each age group returning to Bristol Bay, Alaska. Age group refers to “years spent in freshwater”_”years spent in ocean”. Color corresponds to the best performing model in terms of mean absolute scaled error (MASE), transparency reflects the MASE of the best performing model."}
age_forecast_figure
```


```{r age-returns, fig.cap = "Observed returns of sockeye salmon by age group (color) and system (panels) over time"}
age_system_return_plot
```



That some models outperform others in some circumstances (e.g. particular systems or age classes) suggest a simple solution: pick the best model for the resolution of prediction required, or perhaps better yet create an ensemble model that can leverage the relative strengths of individual models into one improved forecast [@anderson2017a; @araujo2007; @Dietterich2000].We consider two such ensembles here. Each ensemble is constructed by judging the performance of different models in the past and creating a prediction for the current time step based on the historic performance of component models, or ensemble members. We constructed one ensemble model using boosted regression trees, predicting the total returns by system as a function of the predictions by system and age group of each candidate model. The second ensemble model is the historic published FRI forecast. The FRI is a manually constructed ensemble model, which has used various methods throughout the years to arrive at pre-season forecasts for each system based on the recent performance of different candidate models. The FRI forecast for a specific stock by age class combination was traditional constructed by AIC-weighting across candidate linear models of predicting the target age class with 1 or 2 younger age classes as predictors, and selecting the candidate predictive models fitting to two alternative time series (1963+ and 1980+ to accounting for broad-scale shifts in average Bristol Bay salmon population productivity after the shift in the Pacific Decadal Oscillation (PDO) in the late 1970’s) and two data conditions (natural or log-transformed). However, since 2013 the FRI forecast ensemble has been constructed by comparing the performance of the traditional linear and log-linear AIC-weighted sibling models, random forest models, dynamic linear sibling models, boosted regression trees, and simple autoregressive integrated moving average (ARIMA) time series models, and selecting the model with the lowest residual error in predictions for the target stock-age group across a 20-year time horizon.


One of the two ensemble methods provide improved forecasts for five out of the seven systems included here, and in five of the seven systems the boosted regression tree method produced the preferred ensemble (the FRI forecasts being preferable of the two ensembles in the other two systems). In two of the systems (Igushik, FRI ensemble best) and Kvivhak (boosted regression tree ensemble best), one of the individual models performed substantially better than the ensemble (Fig.5). 

```{r ensemble-forecast, fig.cap="Performance of candidate ensemble models. Shape (diamond, circle) indicates which ensemble had the lowest MASE. fri refers to the published forecasts by the Fisheries Research Institute. Boost_tree_ensemble is an ensemble model constructed by a boosted regression tree. Color indicates the percent improvement in MASE between the best ensemble and the best non-ensemble model. Blue colors indicate the ensemble outperformed the best non-ensemble model, red colors that the best non-ensemble model outperformed the ensemble model"}
system_ensemble_forecast_figure
```

The underlying belief of such an ensemble strategy is that the information needed for a good forecast is present in the data, and the key is finding the model that is best able to find that information. However, no model can find information that simply isn’t there, or based upon data that is subject to overwhelming observation error. Examining trends in the annual residuals by model and river system shows clear patterns. In some years and systems, all models perform similarly well (suggesting that the information needed for a good forecast is relatively obvious to each of the models. In other years, only particular models performed well, while others struggle, indicating that information is present but only some models were able to accurately quantify the underlying relationship, highlighting the value of ensemble methods. However, in other years and systems all models struggled (e.g. the Wood River in 2018, and Kvichak River in 2014). This provides evidence that the information needed to perform a good forecast in those years  was simply not present in the data that are currently available (Fig.6). 



```{r resids, fig.cap="Centered and scaled annual residuals (forecast minus observed) by river system and model over time. Red bands indicate areas more than one standard deviation from the mean residuals."}
yearly_system_resid_struggles_figure
```


<!-- Which variables were most important in our forecasts? XX not sure if /how this can be done for the other models, or if it’s worth it XX. Maybe just do variable importance plots by age group for the tree based methods -->


<!-- * Performance in total returns forecast -->
<!-- * Break down by combinations of age class / system -->
<!-- * Variable importance where available -->
<!-- * Synthesize top performs for different objectives  -->
<!-- * Result of simple ensemble -->
<!-- * Result of models predicting boom / bust years  -->




# Discussion (1000 words)


The annual return of sockeye salmon to the river systems of Bristol Bay Alaska is an economic and ecological marvel, providing critical nutrients and value to the Alaskan ecosystems, economice, and people. Effective management of this critical natural and cultural resource depends in part on the ability to accurately forecast the number of salmon that will return each year. As such, accurate and precise forecasts for future salmon abundance are critically important to the biological and economic sustainability of this important fishery. Computer-age statistical methods can improve our forecast ability, substantially in some cases. For example, individual models used here improved age group specific forecasts on average by XX%, and XX% at the system level. Ensembles of these individual methods, both formal and informal in nature, allow for further improvement. 


However, our residual analysis suggests that in some instances we simply need to include different data in the model to if we hope to improve forecasts. For example, none of our models were able to predict the massive spike in returns of the 1.2 age class to the Wood River system in recent years. We can use the results of our most recent estimated boosted regression tree model to examine the relative importance of different included data streams in forecast skill. While these importance scores cannot be interpreted in the same manner as regression coefficients, they give us a sense of where we might look for new data. Across all systems, priors returns in that system were an important predictor (and in many systems past returns in other systems were also a useful predictor). However along with these we found that both oceanographic variables, mean sea surface temperature throughout the range of the oceanic phase of the salmon during the span of their time in the ocean and mean pacific decadal oscillation index (PDO) during their time in the ocean were in some systems important predictors. In addition, as reported by XX[e], we find that in some instances abundance of other salmon species (chum salmon in western Kamchatka northern British Columbia , pink salmon in Prince William sound)(Fig.7). These results suggest that improved data on at-sea conditions and interspecies competitors may facilitate improved forecasts in the future.   [f]


```{r, eval = FALSE}
system_varimportance_figure
```


Figure 7: Mean variable importance across systems of variables with importance greater than 0.05. 


<!-- What other data should we suggest? We don’t include any in-river condition data, do we just not have it? Thoughts on other places we can invest? [g] -->




The field of ecology is generally concerned with developing theories and evidence for why ecosystems are structured and behave the ways they do. Methods such as those described here may not provide this sort of insight. They are instead instruments designed for prediction, often at the expense of interpretability. However, in the case of natural resources management, that often depends on making decisions today based on predictions about the future, methods such as those presented here can present substantial opportunity. In particular, leveraging multiple different modeling approaches can help uncover otherwise hidden information in available data. As we demonstrate here though, we cannot simply rely on computer-age statistical methods to automatically solve problems of prediction in ecology. Instead, we can use such methods to help identify frontiers in predictability. Once these borders are found, we can focus efforts and resources on collecting new data that can push our predictive models to greater heights. It is critical that we allocate resources to both the advancement of predictive modeling methods, and to the hard work of collecting the data from the natural world that are the foundation of any successful forecasting efforts. 


<!-- * Make clear that the point here is that some clever person that’s better at ML than we are might not be able to get slightly better performance in some cases: but that all models fail in similar ways in similar situations suggest that there are only marginal gains to be made in further model tinkering -->
<!-- * Contrast to Ward, Holmes, Thorson, and Collen (2014): basically subtly say that the issue there was trying to use some of these methods “out of the box” i think? -->
<!-- * Discuss potential reasons why different models performed better for different circumstances -->
<!--    * ML for young -->
<!--    * Structural for older -->
<!-- * Put forecast improvements (where they occured) into economic /ecological context: how much is a XX% increase in forecast accuracy worth? -->
<!-- * In the specific case of salmon forecasting, results suggest that we have gone about as far as we can in terms of pre-season forecasting given the available data. Obtaining higher quality forecasts in the future then will require investment in data collection -->
<!--    * Use models to suggest that where that data collection might be targeted -->
<!-- * How much data was needed to make salmon forecasts accurate -->
<!--    * Demonstrate retrospective bias plots showing that ML methods actually perform pretty well 20 years out of sample - you don’t need millions of data points to access these things -->
<!--    * Out of sample performance as a function of amount of training data -->
<!-- * Computer-age methods can help identify “ceilings” in predictability given available data -->
<!--    * Incredibly useful for ecological prediction in general: helps people get a sense for when they might be able to squeeze more insight out of the same data, and when they need to go out and just collect more data -->
<!-- * But also clear role and importance for “traditional” methods and not putting all eggs in one basket -->
<!-- * Fundamental challenge of time series length (n=years) -->
<!--    * ML and EDM methods designed to be conditioned on many more system observations -->
<!-- * Axes across which to compare models -->
<!--    * Predictive capacity (bias/precision) -->
<!--    * Implementation costs (i.e. tuning time, ect) -->
<!--    * Interpretability (i.e. level of black-boxicity, nature of uncertainty) -->
<!--    * Risk of extreme poor year (1/10 years model predicts an extremely unbelievable/unlikely run size) -->
<!-- * Closing statements -->
<!--    * These sorts of methods can be particularly valuable and risky under a changing climate (valuable if they capture changes, risky if they get stuck on the past) -->
<!--    * Salmon are an ideal case study in how to consider these tools given the richness of data and ability to vet results -->
<!--    * These methods may help improve forecasts in a changing climate, but only to a point: eventually you need to collect more data -->




# Methods[h] (2000 words)
<!-- * Applicable details of current FRI forecast methods -->
<!-- * Applicable details of DLM methods -->
<!-- * Applicable details of candidate ML methods -->
<!-- * Applicable details of candidate EDM methods -->
<!-- * Validation procedure (leave-one-out testing from 2000-2018) -->


All code and data needed to fully replicate our results are publicly available at https://github.com/DanOvando/salmon-forecast-paper/. We describe critical details of each our main methods here, readers can refer to the supplementary material for and available code for more specific details. 


## Machine Learning 


<!-- [I think machine learning used a kitchen sink approach where you took all the available data and fed it through the models? That’s the reason why you get the variable importance plots shown in the discussion] -->


We evaluate three different machine learning models: a random forest (implemented through the `ranger` package [@wright2017] in R [@rcoreteam2020]), boosted regression trees through the `xgboost` package [@chen2020] and a recurrent neural network implemented through `tensorflow` [allaire2020] through the `keras` interface [allaire2020a]. Random forests are ensembles of regression trees, which make predictions by selecting nested splits of variables and mapping the mean level of the dependent variable at the terminal nodes of each tree. Boosted regression trees are similar to random forests, but have mechanisms in place that actively update the model to address data points that the model is struggling to fit. Neural networks are built from multiple layers of data transformations (e.g. projecting a vector of 10 covariate values into a vector of 100 values), which are eventually collapsed into a prediction of the dependent variable. For all machine learning methods, within a model fit the model selects splits/transformation/coefficiengts in order to minimize some objective function on held-out data (e.g. minimize the RMSE of predictions on data held out from the fitting process by the algorithm). 


Models are fit at the level of age groups by river system. Data are first split into training and testing sets, which in our case are shared across all of our evaluated methods (the one-step-ahead forecasting previously mentioned). We then split each of the training sets (e.g. all data before the year 2000 if the year 2001 is to be forecasted) into a series of analysis and assessment splits. Given the timeseries nature of the data, we generate these analysis and assessment splits in a rolling manner: for the first split, we use the first 70% of the available year to fit a model, and 30% to evaluate the performance of that model, followed by the first 75% and 25%, etc. These analysis and assessment splits are used to tune nuisance parameters common to all machine learning models, for example the minimum node size of fitted trees. We fit each of our assessment splits across a grid of potential parameter values, and select the set of nuisance parameters that minimize the root-mean squared error (RMSE) of the predictions on the assessment splits. 


Once the set of nuisance parameters for each training set were selected, we then fit the model using all the training data with those tuned parameters, and then used that model to predict the returns in the testing set.  All relevant data transformations were prepared only on training / analysis splits (e.g. means and standard deviations for centering and scaling) and then applied to testing / assessment splits. Detailed methods and tuning parameter values are available in the supplementary materials. 


## Dynamic Linear Models

Traditional methods for forecasting sockeye salmon abundance in Bristol Bay and throughout Alaska, have relied on the relationship between the abundance of different age classes from the same cohort, or originating from the same brood year, but returning to breed in subsequent years. These “sibling” or cohort regression models leverage the fact that salmon spawned in the same brood year and migrating to sea in the same year exhibit similar patterns in survival, based upon their shared exposure to the same physical environmental conditions, prey resource availability, and predator field, as juveniles and at ocean entry.
 
Foundational to the predictability of sibling relationships is the assumption that the ratio of returns by age class remains stable across time. In a context of a linear model, for example, where  the predicted return abundance of the older age class and  is the observed abundance of the younger predictor age class, as: , this is the assumption that the estimated  parameter remains constant across time as does the intercept  which scales the average abundance of the 1.3 age class. However, there are multiple conditions under which both the average return abundance of a particular age class or the ratio of abundances among age classes might change over time. For example, if the average maturation schedule (e.g. the probability that an individual will mature after 2 vs. 3 years in the ocean) changes in response to natural or anthropogenic selection, the assumption of a stationary  parameter is violated. Alternatively, if average marine mortality experienced by salmon changes as a result of large-scale climate, ecosystem, or trophic shifts, this should be reflected by changes in both  and  parameters of the sibling relationship.
 
To better represent the dynamic nature of sibling or cohort relationships over time and improve predictive performance, we implement dynamic linear models (hereafter DLMs). DLMs are a class of regression models where the values of regression coefficients are permitted to evolve over time, rather than remain static [@petris2009; @pole1994]. DLMs were fit to available data using a single predictor age class (one fewer year in the ocean, returning the prior year), and allowing for evolution of both the slope and intercept parameters over time, as: . Both regression parameters are described by a random walk (i.e.  and ), and errors were assumed normally-distributed . DLMs were implemented using the Multivariate Autoregressive State-Space Modelling (MARSS) package (version 3.10.12) in R [@holmes2012; @holmes2020].


## EDM

Empirical dynamic modeling (EDM) is a nonparametric approach to characterize ecological dynamics and generate forecasts. The approach is predicated on Takens’ theorem, which states that a single time series and a number of lags (dimension; E) are representative of overall system dynamics [@sugihara1990; @takens1981]. Applications of EDM have identified causal relationships in ecological systems [@sugihara2012] and improved forecast skill in Fraser River sockeye salmon [@ye2015]. See @munch2020 and [@chang2017] for more general overviews of EDM. Additionally, we used the software package rEDM [@ye2020] for analysis.


Here, we applied simplex projection (hereafter simplex) and sequentially locally weighted global linear maps (s-maps) to the Bristol Bay sockeye data. Both methods require identifying the dimensionality (E) of a time series and constructing an attractor (a time series and its E-lagged coordinates). Leave-one-out prediction identifies the best E of a time series. We used E values ranging from 1 to 10, found the E-nearest neighbors (based on Euclidean distance) from the observation of interest, and calculated a predicted value by averaging the E-nearest neighbors. The best E had the highest correlation between observed and predicted values. S-maps is an extension of simplex that has the addition of a weighting parameter (theta) which modifies the strength of nearest neighbor weighting (theta=0 weights nearest neighbors equally; theta>0 stronger weighting of nearest neighbors) [@Sugihara1994]. 


Here, for each of the river, age-class combinations, we used s-maps. For example, we predicted Kvichak 1.2 returns. We identified the best E for Kvichak 1.2 and also included information from the the top 6 age classes (based on average returns) for Kvichak. The attractors had a time series and its lagged coordinates and the unlagged coordinates for abundant age classes. The s-map theta values were selected based on the conditioning data set (e.g. time series up to 2000) to predict one year into the future (2001). 

<!-- @Takens1981 https://link.springer.com/chapter/10.1007%2FBFb0091924 -->
<!-- @SugiharaMay1990 https://www.nature.com/articles/344734a0 -->
<!-- @Sugiharaetal2012  https://science.sciencemag.org/content/338/6106/496.abstract?casa_token=hXgrYaQUvOMAAAAA:imG5mmwyw0T0TDbbhHf-p3OrwxuHjviBQrP-39X-G00BlUS9u5xOUq2Inslepgr9odSFWOXg9GzgdRw -->
<!-- @Yeetal2015 https://www.pnas.org/content/112/13/E1569.short -->
<!-- @Munchetal2019 https://academic.oup.com/icesjms/article-abstract/doi/10.1093/icesjms/fsz209/5643857 -->
<!-- @Changetal2017 https://link.springer.com/article/10.1007/s11284-017-1469-9 -->
<!-- @Yeredm https://github.com/ha0ye/rEDM -->
<!-- @Sugihara1994 https://royalsocietypublishing.org/doi/abs/10.1098/rsta.1994.0106 -->
<!-- @HyndmanKoehler2006 https://robjhyndman.com/publications/another-look-at-measures-of-forecast-accuracy/ -->


## Model Comparisions

Predictive performance of candidate models was calculated by generating 1-year ahead forecasts for each target river system by age class combination, as a rolling window from 2000 to 2019. This method for quantifying forecast performance is most applicable to the context of this ecological forecasting problem as each candidate model is trained on data up to the year prior to the prediction year, or the data that would have been available to the analyst in each year historically. 


## Benchmark Models


We include two simple benchmark models as well as our computer-age models. These are a simple lag model, where the predicted forecast (numbers by age group and river system) in a given year are simply the numbers by age group and river system observed in the previous years. We also include a running mean model, in which the predicted numbers by age group and river system in a given year are the mean of the the numbers by age group and river system observed over the previous four years. 




<!-- [a]We might also mention that these require both knowledge of the total return by stock (river system) and age composition information to allocate returns back to the correct cohort. These are more data requirements than reasons one could not develop a reliable estimate, and might be too much salmon-specific info. -->
<!-- [b]Make this clearer. Basically saying that ML methods and the covariates they include allow for improvements when fish are young, and have their lives dominated by ocean phase (1_3). Both 2_2 and 2_3 are either older (2_2) and or spend more time in freshwater where we don't have environmental covariates in the model (2_3) -->
<!-- [c]For every system picked best performing ensemble, color coded by % improvement over next best non-ensemble, Red indicates non-ensemble model was better. -->
<!-- [d]Highlight years where there is a consistent difference, unavoidable residuals independent of method -->
<!-- [e]that recent paper that looked at effects of iterspecies competition -->
<!-- [f]add in other ruggerone paper looking at pink as a predictor of bristol bay - predeicting variance -->
<!-- [g]The best predictor to include would be juvenile (smolt) abundance at outmigration, however this has been notoriously difficult to obtain. The early smolt abundance estimates had huge CVs and the more recent and reliable estimates from verical-looking sonar only cover a short portion of the time series. -->


<!-- Other candidate predictors to describe: -->
<!-- - Offshore abundance estimates in fall/winter of outmigration (NOAA BASIS surveys) -->
<!-- - Sockeye size/condition in the brood year. We can tie this in to the maternal effects literature. Big Old Fat Females -->
<!-- - -->
<!-- [h]I think we should be explicit at the beginning of each section which data are used in the model fitting -->


# References
